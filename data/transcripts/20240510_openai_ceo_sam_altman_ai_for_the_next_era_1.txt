Sam Altman: But we I don't think we've yet seen the kind of like people go after the like you know trillion dollar like take on Googles. I think that like a human level chat bot interface that actually works this time around. Like I think like many of these trends that like we all made fun of were just too early. Like the chatbot thing was good. It was just too early. services that are done through that where you get great advice or new education services like this these are gonna be very large companies. I think we'll get multimodal models in not that much longer and that'll open up new things. I think people are doing amazing work with sort of agents that can use computers to do things for you, use programs. And this idea of like a language interface But I think this is gonna be a massive trend and with this as the interface and more generally that like these very powerful models will be one of the genuine new technological platforms which we haven't really had since mobile. large models out there that other people build on. But right now what happens is you know, company makes large language model, API other people build on top of it. And I think there will be a middle layer that becomes really important where those companies will create a lot of enduring value because they will have like a special version of won't they have to have created the base model but they will have created something they can use just for themselves or share with others that has this unique data flywheel going that sort of improves over time and all of that. So I think there will be a lot of value created in that middle layer. I think the biggest systemic mistake in thinking people are making right now is they're like, alright, maybe I was skeptical but this language model thing is really gonna work and sure, like images, video too. But it's not gonna be generating net new knowledge for humanity. It's just going to do what other people have done and, you know, that's still great. That still like brings One is there are these science dedicated products, whatever, like AlphaFold and those are adding huge amounts of value and you're gonna seeing this like The But there's like another thing that's happening which is like tools that just make us all much more productive, And that impact on the net output of one engineer or scientist I think will be the surprising way that AI contributes to science that is outside of the obvious models. But even just seeing now what I think these tools are capable of doing, Copilot as an example, you know, it'd be much cooler stuff than that, That will be a significant like change to the way that technological development, scientific development happens. But then so those are the two that I think are like huge now and lead to like just an acceleration of progress. But then the big thing that I think people are starting to explore is And so can we automate our own jobs as AI developers very first? The very first thing we do. Can that help us solve the really hard alignment problems that we don't know how to solve? That honestly I think is how it's going to happen. you know, editing your own code and changing your optimization algorithm and whatever else. process we do that is like special to humans, teaching AI to do that, I'm very excited to see what that does for the total I'm a big believer that the only real driver of human progress and economic growth over the long term is the the structure, the societal structure that enables scientific progress and then scientific progress itself. And like be really bad if it doesn't do what we want or if it sort of has goals that are The way that I think the self improving systems help us is not necessarily by the nature of self improving but like we have some ideas about how to solve the alignment problem at small scale But we cannot honestly look anyone in the eye and say we see out one hundred years how we're going to solve this problem. I'll start with like the higher certainty things. I think language models are going to go just much much further than people think And we're very excited to see what happens there. that we're going to have a very exciting time. Another thing is I think we will get true multimodal models working. And so not just text and images but every modality you'd like in one model able to easily I think we will have models that continuously learn. So like right now if you use GPT, whatever, it's sort of like stuck in time that it was trained and the more you use it it doesn't get any better and all of that I think will get that changed. So very excited about all of that. And if you just think about what that alone is going to unlock and the sort of applications people will be able to build with that, like a massive step forward and a genuine technological revolution if that were all that happened. But I think we're likely to keep making research progress into new paradigms as well. We've been like pleasantly surprised on the upside about what seems to be happening. And I think all these questions about new knowledge generation, how do we really advance humanity, So a lot of the you know, we were talking about there are all these people saying I'm doing these RL models for fusion or whatever and as far as we can tell, they're all much worse than what you know, smart physicists have figured out. I think it is just an area where people are going to say understand predictably what the scaling laws look like, or already have done the research where we can say, alright, this new thing is going to work and make predictions out from that way. And that's sort of like how we try to run OpenAI I mean I think it is going to just seep in everywhere. My basic model of the next decade is that the cost of intelligence, the marginal cost of intelligence and the marginal cost of energy are going to trend rapidly towards zero, like surprisingly far. And those And I think you have to assume that's going to touch almost everything because these seismic shifts that happen when the whole cost structure of society changes, happened many times before, the temptation is always to underestimate those. So I wouldn't make a high confidence prediction about anything that doesn't change a lot or that doesn't get to be applied. But one of the things that is important is it's not like the thing And so I think it's more like how the metaverse is going to fit into this like new world of AI than AI fitting into the metaverse. But low confidence. TBD. I think the currently available models life sciences researchers have told me. They've all looked at it and they're like, it's a little helpful in some cases. There's been some promising work in genomics but this is one of these areas where there will be these new 100,000,000,000 to trillion dollar companies started. Those areas are rare. But like when you can really change the way that if you can really make like a future of pharma company that is just hundreds of times better than what's out there today, that's going to be really different. As you mentioned, there still will be like the rate limit of like bio has to run at its own thing and human trials take however long they take and that's So I think an interesting cut of this is like, where can you avoid that? Where are the synthetic bio companies that I've seen that have been most interesting are the ones that find a way to make the cycle time super fast. And benefits an AI that's giving you a lot of good ideas but you've still got to test them which is where things are right now. I'm a huge believer for startups that the thing you want is low costs and fast cycle times. And if you have those, you can then compete as a startup against the big incumbents. But you know, using Bio to manufacture something, that sounds great. I think the other thing is the simulators are still so bad. And if I were a of our brain are still going to work the same way. Like, we're still going to have the same drives to kind of create new things and compete for silly status and form families and whatever. I do like all of the ones that are sort of like, you know, we turn our focus to like exploring and understanding the universe as much as we can. optimists are like Well, it's just like I want to merge into the AGI and go off exploring the universe and it's going to be so wonderful and I want total freedom. But I think like all of those I find quite depressing. I think having a lot of kids is great. have as an in house function? I don't think we'll in be doing prompt you will just interface in language and get the computer to do whatever you want. And that will AGI is basically So for me, like that's kind of like AGI. And then superintelligence is one that's smarter than all of humanity put together. Obviously the economic impacts are huge and I think if is as divergent as I think it could be for like some people doing incredibly well and others not, I think society just won't tolerate it this time. And so figuring out when we're going to like disrupt so much of economic activity, and even if it's not all disrupted by twenty or thirty years from now I think it'll clear that it's all going to be. What like what is the new social contract? Like how my guess is that the things that we'll have to figure out are how we think about fairly distributing wealth, access to AGI systems which will be like kind of the commodity of the realm, and governance like how we collectively decide what they can do, what they don't do, things like that. I think figuring out the answer to those questions is going to just be huge. at least in what we're seeing so far, not replacing. It is mostly enhancing. It's replacing in some cases but for the majority of the kind of work that people in these fields want to be doing, it's enhancing. And I think we'll see that trend continue for a long time. Eventually, yeah, it probably is just like, you know, we look at one hundred years. Okay. It can do the whole creative job. I think it's interesting that if you asked people ten years ago Then the very high skill, like really high IQ And it's really gone exactly and it's going exactly the other direction. And I think this there's an interesting reminder in here generally about how hard predictions are but more specifically about, you know, we're not always very aware, maybe even ourselves, of like what skills are hard and easy. Like what uses most of our brain and what doesn't or how difficult bodies are to control or make or whatever. How would the start up differentiate from another? How would one large language model start up differentiate from I think it will be this middle layer. I think in some sense the start ups will train their own models, just not from the beginning. They will take like, you know, base models that are hugely trained with a gigantic amount of compute and data and then they will train on top of those to create the model for each vertical. And that those start ups so in some sense they are training their own models, just not from scratch but they're doing the 1% of training that really matters for whatever this use case is going to be. Those start ups I think, they will be hugely successful and very differentiated start ups there But that'll be about the kind of data flywheel that the startup is able to do, the kind of all of the pieces on top and below. This could include prompt engineering for a while or whatever, the sort of core base model. I think that's just gonna get too complex