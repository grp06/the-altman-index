Sam Altman: almost impossible to overstate how much we were like a research lab with a very strong belief and direction and conviction, specific LLMs as an idea were still very far off. we kind of went through a few different things. We had a few directions that we really wanted to bet on. And at some point in there, one person and then eventually a team got excited about trying to do unsupervised learning and to build language models. And that led to GPT-one and then GPT-two. By the time of GPT-three, we both thought we had something that was kind of cool, but we couldn't figure out what to do with it. And also, we realized we needed a lot more money to keep scaling. We had done GPT-three. We wanted to go to GPT-four. We were heading into the world of billion dollar models. It's hard to do those as a pure science experiment unless you're like a particle accelerator or something. Even then, it's hard. So we started thinking, Okay, we both need to figure out how this can become a business that can sustain the investment that it requires. And also, we have a sense that this is heading towards something actually useful. And we had put GPT-two out as model weights, not that much had happened. companies, products in general, is if you do an API, it usually works somehow on the upside. This was true across many, many YC companies. And also that if you make something much easier to use, there's usually a huge benefit to that. So we're like, well, it's kind of hard to run these models that are getting big. We'll go write some software to do a really good job of running them. And also, we'll then, rather than build a product because we couldn't figure out what to build, we will hope that somebody else finds something to build. And so I forget exactly when, but maybe it was like June 2020 we put out GPT-three in the API. And the world didn't care, but Silicon Valley did. They're like, oh, this is kind of cool. This is pointing at something. And there was this weird thing where we got real businesses with the GPT-three API that I can remember were these company a few companies that did copywriting as a service. That was kind of the only thing GPT-three was over the economic threshold on. But one thing we did notice, which eventually led to ChatGPT, is even though people couldn't build a lot of great businesses with the GPT-three API, people loved to talk to it in the playground. that led us to eventually build ChatGPT. By the time ChatGPT 3.5 came out, there were maybe eight categories instead of one category where you could build a business with the API. especially along with molasses really takes hold. a lot of things relative to the number of people you have. Otherwise, you just have 40 people in every meeting and huge fights over who gets what tiny part of the product. There was this old observation of business that a good executive is a busy executive because you don't people like muddling around. But at our company and many other companies, researchers, engineers, product people, they drive almost all the value. And you want those people to be busy and high impact. So if you're going to grow, you better do a lot more things. Otherwise, you just have a lot of people sitting in a room fighting or meeting or talking about whatever. So we try to have relatively small numbers of people with huge amounts of responsibility, think we really do now have an opportunity to go build one of these important internet platforms. But to do that, if we really are going to be people's personalized AI that they use across many different services over their life and across main categories and all the smaller ones that we need to figure out how to enable, then that's just a lot of stuff to go build. way to use that thing. Some of that will be like what you do inside of ChatGPT. We'll have a couple of other really key parts of that subscription. But mostly, we will hopefully build this smarter and smarter model. We'll have these surfaces like future devices, future things that are sort of similar to operating systems, whatever. And then we have not yet figured out exactly, I think, what the sort of API or SDK or whatever you want to call it is to really be our platform. But we will. It may take us a few tries, but we will. And I hope that that enables No. Mean, I see plenty of OpenAI people in the audience. They can vouch for it. We don't sit there and have I am a big believer that you can do the things in front of you. But if you try to work backwards from we have this crazy complex thing, that doesn't usually work as well. We know that we need tons of AI infrastructure. We know we need to go build out massive amounts of AI factory volume. a great top of the stack consumer product and all the pieces that go into that. But we pride ourselves on being nimble and adjusting tactics as the world adjusts. And so the products that we're going to build next year, we're probably not even thinking about right now. And we believe we can build a set of products that people really, really love, And we have unwavering confidence in that, and we believe we can build great models. I've actually never felt more optimistic about our research roadmap than I do right now. But in terms of the steps I think this basically happens every major tech revolution. There's nothing to me surprising about it. The thing that they're getting wrong is the same thing they always get wrong, which is people get incredibly stuck in their ways. Organizations get incredibly stuck in their ways. If things are changing every quarter or two and you have an information security council that meets once a year to decide what applications are going to allow and what it means to put data into a system. It's so painful to watch what happens here. But this I'd say I feel disappointed but not surprised at the rate that big companies are willing to do this. My prediction would be that there's another couple of years of fighting, pretending like this isn't going to reshape everything. And then there's a capitulation and a last minute scramble, and it's sort of too late. And in general, startups just blow past people doing it the old way. Mean, this happens to people, too. maybe you talk to an average twenty year old and watch how they use ChatGPT, And then you go talk to an average 35 year old and how they use it or some other service. And the difference is unbelievable. It reminds me of when the smartphone came out and every kid was able to use it super well and older people, it just took three years to figure out how to do basic stuff. And then, of course, people integrate. But the generational something where they paste in and out. And it has the full context on every person in their life and what they've talked about. The memory thing has been a real change there. But yeah, I think gross oversimplification, but older people use ChatGPT as a Google replacement. Maybe people in their 20s and 30s use it as a life advisor something, and then people in college use it as an operating system. maybe the thing I could You should be able to sign in with OpenAI to other services. Other services should have an incredible SDK to take over the ChatGPT UI at some point. But to the degree that you are going to have a personalized AI that knows you, that has your information, that knows what you want to share later, and has all this context on you, the future of the internet, where things get federated and broken down into much smaller components, and agents are constantly exposing and using different tools. And authentication, And as we get a better sense for that, again, it'll probably take us like a few iterations toward that to get there. But that's kind of where I would like to see things go. People do that a lot. People put that into people have whatever. They build things where they just put sensor data into an O3 API call or whatever. And for some use cases, it does work super well. So we'll probably bake it in more explicitly at some point, but there's already a lot happening there. I think voice is extremely important. will crack that code eventually. And when we do, I think a lot of people are going to want to use voice interaction a lot more. I am super when we first launched our current voice mode, the thing that was most interesting to me was it was a new stream on top of the touch interface. And you could talk and be clicking around on your phone at the same time. And I continue to think there is something amazing to do about voice plus GUI interaction that we have not cracked. But before that, we'll just make voice really great. And when we do, I think there's a not only is it cool with existing devices, but I sort of think voice will enable a totally new class of devices if you can make it feel like truly human level voice. Right now, you ask ChatGPT a response, you get text back. Maybe you get an image. You would like to get a whole program back. You would like custom rendered code for every response, or at least I would. You would like the ability for these models to go make things happen in the world. And writing code, I think, will be very central to how you actuate the world and call a bunch of APIs or whatever. So I would say coding will be more in a central category. We'll obviously expose it through our API and our platform as well. But ChatGPT should be I mean, that's kind of the each of those things are really hard. And obviously, the highest leverage thing is still big algorithmic breakthroughs. And I think there still probably are some 10x's or 100x's left, not very many, but even one or two is a big deal. There are some projects that require so much coordination that there has to be a little bit of top down quarterbacking. But I think most people try to do way too much of that. I mean, this is like there's probably other ways to run good AI research, or good research labs in general. But when we started OpenAI, we spent a lot of time trying to understand what a well run research lab looks like. And you had to go really far back in the past. In fact, almost everyone that could help advise us on this was dead. It had been a long time since there had been good research labs. And does OpenAI repeatedly innovate, and why do the other AI labs copy, or why do BioLab X not do good work and BioLab Y does do good work, or whatever? And And then everybody says, great, but I'm going to go do the other thing. And we said, that's fine. You came to us for advice. Do what you want. But I find it remarkable how much these few principles that we've tried to run our research lab on, which we did not invent, we shamelessly copied from other good research labs in history, have worked for us. And then people who have had some smart reason about why they were going to do something else that didn't work. Yeah, mean, amazing to see what people are doing there. We do have academic research programs where we partner and do some custom work. But mostly people just say, like, I want access to the model, or maybe I want access to the base model. And I think we're really good at that. One of the cool things about what we do is so much of our incentive structure is pushed towards making the models as smart and cheap and widely accessible as possible, that that serves academics and really the whole world very well. So we do some custom partnerships, but we often find that what researchers or users really want is just for us to make the general model better across the board. And so we try to focus 90% of our thrust vector on that. ideal state is a very tiny reasoning model with a trillion tokens of context that you put your whole life into. The model never retrained. The weights never customized. But that thing can reason across your whole context and do it efficiently. everything you've ever looked at is in there, plus connected to all your data from other sources. And your life just keeps appending to the context, and your company just does the same thing for all your company's data. But I think of kind of like anything else as a compromise off that platonic ideal. And that is how I would eventually, I mean, in some sense, the value will continue to come from really three things, like building out more infrastructure, smarter models, and building the kind of scaffolding to integrate this stuff into society. And if you push on those, I think the rest will sort itself out. A higher level of detail, doing work. AIs discovering new stuff, and maybe we have AIs make some very large scientific discoveries or assist humans in doing that. And I am kind of a believer that most of the real sustainable economic growth in human history comes from once you've spread you perspective will face a lot of adversity in your journey as a founder. And the challenges get harder and higher stakes, but the emotional toll gets easier as you go through more bad things. So it's, in some sense, And I think the hardest thing about the big challenges that come your own psychology through is the sort of fallout after. people focus a lot about how to work in that one moment during the crisis, And the really valuable thing to learn is how you pick up the pieces. There's much less talk about that. Think there's I've never actually found something good to point founders to to go read about, not how you deal with the real crisis on day zero or day one or day two, but on day 60 as you're just trying to rebuild