Sam Altman: And I think the same thing is gonna happen for other AI systems caveated by the fact that if people know what it means to verify or understand what's going on is going to be a little bit different than people think right now. I actually can't look in your brain and look at the 100,000,000,000,000 synapses try to understand what's happening in each one and say, okay, I really understand why he's thinking what he's thinking. You're not a black box to me. But what I can ask you to do is explain to me your reasoning. And I think our AI systems will also be able to do the same thing. They'll be able to explain to us in natural language the steps from conclude from a to b, and we can decide whether we think those are good steps
Unknown: emphasized was that you thought AI can be very friendly, very benign, very empathetic. And I want to hear from you what you think is left for a human being to do if the AI can out analyze a human being, can out calculate a human being, a lot of people then say, well, that means what we will be left with, our core innate humanness, will be our emotional intelligence, our empathy, our ability to care for others. But do you think AI could do that better than us as well? And if so, what's the core competence of human beings? I think there will be a lot of things. Humans
Sam Altman: really care about what other humans think. That seems very deeply wired into us. So chess but we're still, like, very focused on each other. And I think we will do things with better tools. And I admit, it does feel different this time. General purpose cognition feels so close to what we all treasure about humanity that it does feel different. So, of course, you know, there'll be kind of the human roles where you want another human. But even without that, I think like, when I think about my job, I'm certainly not a great AI researcher. And we'll still like make decisions. They may trend more towards curation over time, but we'll make decisions about what should happen in the world.
Unknown: so what Sam seems to be saying is that, you know, it is those emotional teamwork kinds of qualities that become very important.
Unknown: But we all know that there's still this issue out there called hallucinations. And hallucinations is interesting because it's really about those models, they're fun, we're talking to them and then they lie. And we've all had that experience, haven't we? We have to cross that bridge. We have to cross the bridge We all kind of piled in there a couple of months ago. And it was really interesting because it's the first time the technology leaders kind of showed up and every government technology minister from every country was amazing actually. I've never really seen anything like it. But everyone's there because we realized we are at this threshold moment, but we're not totally there yet. We're at a moment. There's no question because we're all using Sam's products and other products and going, wow, we're having this incredible experience with an AI. We really have not quite had this kind of interactivity before, but we don't trust it quite yet. So we have to cross trust. We have to also turn to those regulators and We don't want that in our AI industry. We want to have a good healthy partnership with these moderators and with these regulators. I think that that begins the power of kind of where we're going. And when I talk to our customers about what they want, Julie will tell you that they want more productivity. They want better customer relationships. or are they going to augment their employees? And today the AI is really not at a point where we're replacing human beings. It's really at a point where we're augmenting them. So I would probably not be surprised
Unknown: improve productivity and exactly the question Mark was posing. So you run a vast organization. I mean, you just told me you employed 330,000 people in India alone. What do you have any sense already of how you are implementing AI and what it's doing? wouldn't one way be to use AI to have fewer people do what they do now? In other words, you you have some large department that fills out forms, so you think something like that. The AI would much more efficiently be able to do it, so you need half as many people. What does AI do to your field in general, but particularly are those two revolutions now interacting, the AI revolution and the biotech revolution?
Unknown: The tech revolution is transforming right now what we do. but also the advancements in technology and the collision between the two of them. But they are creating tremendous synergistic effects that will allow us to do things that we're not able to do until now. I truly believe that we are about to enter a scientific renaissance in life sciences because of this coexistence of advancements in technology and biology.
Unknown: these two revolutions interact?
Unknown: Generative AI is something that we were all impressed and but we saw it now, let's say basically last year, right? But AI in different forms exists for many, many years and we are using it very, very intensively in our labs. The best example that I think people already donate, it is the oral pill for COVID. It's called Paxlovid. It was developed in the chemist part of it. It was developed in four months. Usually, it takes four years. This is because the typical process is what we call drug discovery. You really synthesize millions of molecules and then you try to discover within them which one works. With AI now we are moving to drug design instead of drug discovery. So instead of making 3,000,000 molecules, we make 600 and we made by using tremendous computational power and algorithms that help us to design the most likely molecules to be successful. And then we look to find the best among them. For years to four months, millions of lives were saved because of that.
Unknown: Mr. Chancellor, you're a politician. The issue that Sam raised about trust, that Marc Benioff raised about trust, does seem central. How do you get people to trust AI? Should they trust AI? And should government regulate AI so that it is trustworthy? I feel, Albert, that this is an area where regulation is likely to be most people are going be most worried about the issue of trust, which is the combination of AI and medical. And is this, you know, is it safe for me to listen to this doctor, to take this drug? This has all been developed in a computer somewhere.
Unknown: can do great things for the world. And I'm certain right now that the benefits clearly outweighs the risks. But I think we need regulations. is a lot of debate how those regulations will set guardrails. And there are some countries that they are more focused on how to protect against the bad players. There are some countries that they are more focused on how to enable the scientists to do all the great things with this tool that we want enable the world to move on.
Unknown: what would bad people do with this technology? But there are many people who fear this much larger issue of the technology ruling over us, right? You've always taken a benign view of AI or relatively benign view, but people like Elon Musk and sometimes Bill Gates and other very smart people who know a lot about the field Can you technically kind of put guardrails and write a kind of constitution for an AI system? Would that work? If
Sam Altman: I think it's good that people are afraid of the downsides of this technology. I think it's good that we're talking about it. I think it's good that we and others are being held to a high standard. technology has been made to be safe and also how the different stakeholders in society have handled their negotiations about what safe means and what safe enough is. I have a lot of empathy for the the general nervousness and discomfort of the world towards companies like us and, you know, our our the other people doing similar things, which is like, what why is our future in their hands? you know, what what the values of the system are, but what the safety thresholds are and what kind of global coordination we need to ensure that stuff that happens in one country does not super negatively impact another, to show that picture. So I think not having caution, not feeling the gravity of what the potential stakes are would be very bad. So I like that people are nervous about it. We have our own nervousness, but we believe that we can manage through it. And the only way to do that is to put the technology in the hands of people, let society and technology co evolve, and sort of step by step with a very tight feedback loop and course correction, build these systems that deliver tremendous value while meeting the sort of safety requirements.
Unknown: And our imaginations are filled with what happens when we have an AI that's going well and an AI that's going wrong. And we're moving into a fantastical new world. and they got 300 call center operators down there and they're like using our Service Cloud and they want to use Einstein, which is our AI platform that will do a trillion predictive and generative transactions this week. We're partnered with Sam and it's very exciting. It has a trust layer that lets our customers feel comfortable using their product. And I said to them, what do you really want? And I'm not sure what they want. Are they looking to replace people? Are they looking to add people to get some kind of value? now a test that's been going on six, nine months. It's amazing. And something incredible happened. And I walked in and they said, this is amazing what's happened. I said, what happened? Revenue is up 30%. Revenues are up 30%? Yes. How did that happen? Well, these were all just service professionals, but they now have this generative AI and predictive as well. They've all been augmented. They've all been augmented. The service professionals actually, and this is what they told me, are now also sales professionals and marketing professionals. They're selling products, not just servicing them. They're adding value to the customers and it's a miraculous thing. Their morale went way up. They can't believe what they've been able to achieve. They didn't even know what they didn't know about the products. and that then, yes, they got their revenue, they got their margin that they so badly wanted. Even the WAF, this app that you're all using is running on Einstein. So those predictions that you're getting, hey, because you like this AI panel, you should try that AI panel and you may look over here. That is our Einstein platform giving you those ideas. this is a big moment for AI. AI took a huge leap forward in the last year, two years, like exactly what Sam said between one and two and three and then four and then I'm sure five, six and seven are coming. And here's the thing, We've seen technology go really wrong and we saw Hiroshima. And that's why I think these conversations and this governance and getting clear about what our core values are is so important.
Unknown: suing you and claims that the uses New York Times articles as an input that allows it to make the language predictions that it makes. And it does so excessively and properly and without compensating the New York Times. the people who wrote that data, whether it's newspapers or comedians who've written jokes, shouldn't they all get compensated?
Sam Altman: any one particular training source that doesn't move the needle for us that much. We would like to display content, link out, show brands of places like the New York Times or the Wall Street Journal or any other great publication and say, here's what happened, when the user queries not using it to train the model. is these models will be able to take smaller amounts of higher quality data during their training process and think harder about it and learn more. You don't need to read 2,000 biology textbooks to understand And as we as our models begin to work more that way, we won't need the same massive amounts of training data. But what we want in any case is to find new economic models that work for the whole world, including content owners. If we're gonna teach someone else physics using your textbook and and and using your lesson plans, the human feedback,
Unknown: Jeremy, you said in an interview that you thought it was very important that The United States and Britain and countries like that win the AI war versus China? Explain what you mean and why you think it's important. China will regulate medicine in a different way or some of these issues, we've had the issue come up with gene editing, where there was that famous case of a Chinese doctor who decided to try to do gene editing to prevent AIDS and the Chinese government actually jailed him because of a global convention. Could you imagine something like that happening with AI?
Unknown: I don't know what can happen with AI. As Sam said, nobody And I don't know how China eventually will think about those things. What I know it is that in life sciences, China is making tremendous progress. Right now, I think there are even more biotechs in China than exist in The U. S. Or in The U. K. Or in Europe. I think the Chinese government is committed to develop life science. I think in a few years we'll start seeing the first new molecular entities coming from China and not from The U. S.
Sam Altman: And one thing that I've sort of observed for a while is every one step we take closer to very powerful AI, everybody's everybody's character gets, like, plus 10 crazy points. It's a very stressful thing, a higher level of preparation, more resilience, more time spent thinking about all of the strange ways things can go wrong, that's really important. The the the best thing I learned, or how I mentored them or whatever you wanna call it, like, were ready to do it. And that was high functioning and tight organization.
Unknown: as we know it and the other is why can't it drive my car? Where do you think realistically we are with artificial intelligence right now? What is it for
Sam Altman: and its very deep flaws, people are finding ways to use it in it for great productivity gains or other gains and understand the limitations. So of tools more than we often give them credit for. And people have found ways to make ChatGPT super useful to them and understand, current extremely limited capability levels,
Unknown: I'm really okay with the AI doing it, you know, whether it's driving the car, writing the paper, filling out the medical form. And part of that trust, I think, always comes when you understand how it works. And one of the problems AI researchers have, AI engineers have, is figuring out why it does what it does. You know, how the neural network operates, what weights it assigns to various things. Do you think that we will get there or is it getting so inherently complicated that we are at some level just going to have to trust the black box?
Sam Altman: So on the first part of your question, I think humans are caveated by the fact that if people know, if people are accustomed to using a tool and know it may be totally wrong, That's kind of okay. I think, you know, in some sense, the hardest part is when it's right 99.999% But what I can ask you to do is explain to me your reasoning. the steps from conclude from A to B, and we can decide whether we think those are good steps,
Unknown: can out calculate a human being? A lot of people then say, well, that means what we will be left with, our core innate humanness will be our emotional intelligence, our empathy, our ability to care for others. But do you think AI could do that better than us as well? And if so, what's the core competence of human beings?
Sam Altman: really care about what other humans think. That seems very deeply, but we're still, like, very focused on each other. And I think we will do things with better tools. And I admit, it does feel different this time. General purpose cognition feels so close to what we all treasure about humanity that it does feel different. So, of course, I'm certainly not a great AI researcher. We will all have access to a lot more capability, and we'll still like make
Unknown: What what Sam seems to be saying is that, you know, it is those emotional teamwork kinds of qualities that become very important.
Unknown: But we all know that there's still this issue out there called hallucinations. And hallucinations is interesting because it's really about those models, they're fun, we're talking to them and then they lie. We all kind of piled in there a couple of months ago. And it was really interesting because the first time the technology leaders kind of showed up and every government technology But everyone's there because we realize we are at this threshold moment, but we're not totally there yet. We're at a moment. There's no question because we're all using Sam's product and other products and going, wow, we're having this incredible experience with an AI. We really have not quite had this kind of interactivity before, We have to also turn to those regulators and It's pretty bad. We don't want that in our AI industry. We want to have a good healthy partnership with these moderators and with these regulators. I think that that begins the power of kind of where we're going. Julie will tell you that they want more productivity. They want better customer relationships. The Albert is going to want that. or are they going to augment their employees? And today the AI is really not at a point where we're replacing human beings. It's really at a point where we're augmenting them. So I would probably not be surprised if you used AI to kind of get ready for this panel and ask ChatGPT some really good questions. Hey, what's some good questions I could ask Sam Altman on the state of AI? It made you a little better. It augmented you. My radiologist is using AI to help read my CT scan and to my MRI and this type of thing. We're just about to get to that breakthrough where we're going to go, wow,
Unknown: Julie, people talk about AI at a level of abstraction, improve productivity in exactly the question Mark was posing. So you run a vast organization. Mean you just told me you employ 330,000 What do you have any sense already of how you are implementing AI and what it's doing? So if you were to try and improve productivity at Accenture, wouldn't one way be to use AI to have fewer people do what they do now? In other words, you know, you have some large department that fills out forms, so you think something like that. The AI would much more efficiently be able to do it, so you need half as many people. Is that likely? What does AI do to your field in general, but particularly are those two revolutions now interacting, the AI revolution and the biotech revolution?
Unknown: The tech revolution is transforming right now what we do. What is our job is to make breakthroughs that change patients' lives. With AI, I can do it faster and I can do it better. And this is not only because of the advancements in biology as we spoke, synergistic effects that will allow us to do things that we're not able to do until now. I truly believe that we are about to enter a scientific renaissance in life sciences because of this coexistence of advancements in technology and biology.
Unknown: these two revolutions interact?
Unknown: Generative AI is something that we were all impressed and but we saw it now, let's say basically last year, right? But AI in different forms exists for many, many years and we are using it very, very intensively in our labs. The best example that I think people already donate, it is the oral pill for COVID. It's called Paxlovid. It was developed in the chemist part of it. It was developed in four months. Usually, it takes four years. This is because the typical process is what we call drug discovery. You really synthesize millions of molecules and then you try to discover within them which one works. With AI now we are moving to drug design instead of drug discovery. So instead of making 3,000,000 molecules, we make 600 and we made by using tremendous computational power and algorithms that help us to design the most likely molecules of success. And then we look to find the best among them. For years to four months, millions of lives will save because of that.
Unknown: Mr. Chancellor, you're a politician. The issue that Sam raised about trust, that Marc Benioff raised about trust, does seem central. How do you get people to trust AI? Should they trust AI? And should government regulate AI so that it is trustworthy? I feel, Albert, that this is an area where regulation is likely to be most people are going to be most worried about the issue of trust, which is the combination of AI and medical and is this, you know, is it safe for me to listen to this doctor, to take this drug? This has all been developed in a computer somewhere.
Unknown: can do great things for the world. And I'm certain right now that the benefits clearly outweighs the risks. is a lot of debate how those regulations will set guardrails. And there are some countries that they are more focused on how to protect against the bad players. There are some countries that they are more focused on how to enable the scientists to do all the great things with this tool that we want the world to have as in the next pandemic.
Unknown: Sam, when I look at technology, my fear is often what will bad people do with this technology? But there are many people who fear this much larger issue of the technology but people like Elon Musk and sometimes Bill Gates
Sam Altman: technology has been made to be safe and also how the different stakeholders in society have handled their negotiations about what safe means and what safe enough is. you know, what what the values of the system are, but what the safety thresholds are and what kind of global coordination we need to ensure that stuff that happens in one country does not super negatively impact another to show that picture. So I think not having caution, not feeling the gravity of what the potential stakes are would be very bad. So I like that people are nervous about it. We have our own nervousness, but we believe that we can manage through it. And the only way to do that is to put the technology in the hands of people, let society and technology co evolve and sort of step by step with a very tight feedback loop and course correction, build these systems that deliver tremendous value while meeting the sort of safety requirements.
Unknown: our imaginations are filled with what happens when we have an AI that's going well and an AI that's going wrong. hopefully the spirit of what I was saying was correct. So our customers are coming to us all the time and they're saying, hey, we want to use this and our customers, what do our customers want? They want more margin, they want more productivity, they want better customer relationships and they want AI to give that to them. And so I just got back from Milan and I was down with Gucci and they got 300 call center operators down there and they're like using our Service Cloud and they want to use Einstein, which is our AI platform. It will do a trillion predictive and generative transactions this week. We're partnered with Sam and it's very exciting. It has a trust layer that lets our customers feel comfortable using their product. And I said to them, what do you really want? And I'm not sure what they want. Are they looking to replace people? Are they looking to And something incredible happened. you've got to have to it has to get fixed or replaced or whatever. You call these folks and they're talking to you. And I walked in and they said, this is amazing what's happened. I said, what happened? Revenue is up 30%. Revenues are up 30%? Yes. How did that happen? Well, these were all just service professionals, but they now have this generative AI and predictive as well. They've all been augmented. They're selling products, not just servicing them. They're adding value to the customers and it's a miraculous thing. Their morale went way up. They can't believe what they've been able to achieve. They didn't even know what they didn't know about the products. It all was kind of being true tutored and mentored and inspired to them by the AI. And that idea that Einstein could augment them and that then yes, they got their revenue, they got their margin that they so badly wanted. Even the WAF, app that you're all using is running on Einstein. So those predictions that you're getting, hey, because you like this AI panel, you should try that AI panel and you may look over here. That is our Einstein platform giving you those ideas. So So your data is not our product. That's very important. That's core and our core value is also trust. Trust in customer success and innovation and quality sustainability. Our core values have to be represented in how we're building these products for our customers. That is really critical for our teams to understand. big moment for AI. AI took a huge leap forward in the last year or two years, like exactly what Sam said between one and two and three and then four and then I'm sure five, six and seven are coming. And here's the thing, We've seen technology go really wrong and we saw Hiroshima. And that's why I think these conversations and this governance and getting clear about what our core values are is so important.
Unknown: New York Times articles as an input that allows it to make the language predictions that it makes. And it does so excessively and properly and without compensating the New York Times. the people who wrote that data, whether it's newspapers or comedians who've written jokes, shouldn't they all get compensated?
Sam Altman: Many thoughts about that. I'll start with the difference between training and what we display when a user sends a query. any one particular training source, it doesn't move the needle for us that much. What we want to do with content link out, show brands of places like the New York Times or the Wall Street Journal or any other great publication and say, here's what happened, But it's displaying that information You don't need to read 2,000 biology textbooks to understand, But what we want in any case is to find new economic models that work for the whole world, including content owners. the human feedback, I'd
Unknown: Jeremy, you said in an interview that you thought it was very important that The United States and Britain and countries like that win the AI war versus China. Explain what you mean and why you think it's important. Could you imagine something like that happening with AI?
Unknown: I don't know what can happen with AI. As Sam said, nobody knows. And I don't know how China eventually will think about those things. What I know it is that in life sciences China is making tremendous progress. Right now, I think there are even more biotechs in China than exist in The U. S. Or in life science. Think in a few years we'll start seeing the first new molecular entities
Sam Altman: everybody's everybody's And so I think that as I think one lesson is as we get we, the whole world, get closer to very powerful AI, I expect more strange things and having a higher level of preparation, more resilience, but I did also know, such a satisfying thing, both personally about, you know, whatever I had done, but, like, knowing that we had built we, all of us, the whole team, had built this, like unbelievably high functioning and tight organization.