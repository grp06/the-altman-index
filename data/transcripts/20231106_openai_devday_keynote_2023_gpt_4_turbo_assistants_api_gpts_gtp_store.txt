Unknown: This is TWIT news, episode 399 recorded Monday, 11/06/2023. OpenAI Dev Day Keynote Give your team the IT training they want while future proofing your business. Visit go.acilearning.com/twit. TWIT listeners can receive up to 65% coverage of OpenAI's you know, announcements, the you know, like I just said, updates developers. Is it cheaper, faster, easier to build AI apps via OpenAI? That we're, I'm sure, almost certainly gonna learn, you know, something about that. Possibility of a team plan announcement for chat GPT for Teams. So that's a possibility. Integration with Google Drive and Microsoft three sixty five, which I think in general, I'm sure OpenAI, their their, you know, near term road map has to be get this everywhere, Sam or Wally takes the stage, the other thing that I'm looking forward to is possibly a prototype, a new version called Gizmo v eight, which allows you to create your own GPTs.
Sam Altman: which offers enterprise grade security and privacy, higher speed GPT-four access, longer context windows, a lot more. Over 92% of Fortune 500 companies building on our products. But numbers never tell the whole picture on something like this. What's really important is how people use the products, how people are using AI. heard loud and clear that developers need more control over the model's responses and outputs. which ensures that the model will respond with valid JSON. This has been a huge developer request. It'll make calling APIs much easier. The model is also much better at function calling. You can now call many functions at once, You can pass a seed parameter and it'll make the model return consistent outputs. This of course gives you a higher degree of control over model behavior. This rolls out in beta today. GPT four Turbo with Vision, and the new text to speech model are all going into the API today. programmatically generate images and designs. Today, Coke is launching a campaign that lets its customers generate Diwali cards using DALL three. And of course, our safety systems help developers protect their applications against misuse. Those tools are available in the API. classifications, and analysis. For example, Be My Eyes uses this technology to help people who are blind or have low vision with their daily tasks like identifying products in front of them. naturally natural sounding audio from text in the API It features improved performance across many languages, and we think you're really gonna like it. Okay. Number five, customization. Starting today, we're gonna expand that to the 16 k version of the model. we're inviting active fine tuning users to apply for the GPT four fine tuning experimental access program. especially for them and their use case using our tools. This includes modifying every step of the model training process, doing additional domain specific pretraining, a custom r l post training process that's tailored for a specific domain, and whatever else. We So the new pricing is 1¢ per thousand prompt tokens and 3¢ per thousand completion tokens. For most customers, that will lead to a blended rate more than 2.75
Unknown: now called ACI Learning. Today's successful business leaders focus on the future, and IT pro empowers teams by creating content that educates, informs, and entertains. And get this, IT pro's completion rate is 50% higher than the training industry average. IT pros, they want to learn this way. Your enterprise needs cohesive, cutting edge training to keep your team in compliance and ahead of the curve. or you can let IT pro custom design a course to address your specific needs, and you can join the always on tech training solution. Visit go.acilearning.com/ twit today. Twitter listeners can actually receive up to 65% off an IT Pro enterprise solution plan. That discount is based on the size of your team when you fill out their form. We thank ACI Learning, for their support. Now back to the live event in progress with Sam.
Sam Altman: Soon, you will notice g p t four turbo becoming a lot faster. 3.516 k is now cheaper than the previous GPT 3.54 k model. can do more on your behalf. At OpenAI, we really believe that gradual iterative deployment is the best way to address the safety issues, the safety challenges with AI. We think it's especially important to move carefully towards this future of agents. So today, we're taking our first small step that moves us towards this future. You can, in effect, program a GPT with language just by talking to it. It's easy to customize the behavior so that it fits what you want. This makes building them very accessible, Code.org crafted Lesson Planner GPT to help teachers provide a more engaging experience for middle schoolers. If a teacher asks it to explain four loops in a creative way, extensive curriculum and expertise and lets teachers adapt it to their needs quickly and easily. that lets you start designing by describing what you want in natural language. If you say, make a poster for dev a dev date reception this afternoon, this evening, and you give it some details, We've evolved our plugins to be custom actions for GPTs. that that lets you perform actions across 6,000 applications to unlock all kinds of integration possibilities. and it's going to write some detailed instructions for the GPT. And you can see that there's capabilities here that I can enable. I could add custom actions. These are all fine to leave. I'm gonna upload a file. Or you can share your creations publicly with a link for anyone to use. a portion of our revenue. of you have already been building agent like experiences on the API. For example, Shopify Sidekick, which lets you take actions on the platform, Discord's Clyde, lets Discord moderators create custom custom personalities for, and Snaps My AI, a customized chatbot that can be added to group chats and make recommendations. but they have been hard to build, sometimes taking months, teams of dozens of engineers. built in retrieval, code interpreter, a working Python interpreter in a sandbox environment, and, of course, the improved function calling that we talked about earlier.
Unknown: With an astounding 30% of IT Pro learners being MSPs, it is no wonder why IT pro continues to be the preferred choice for training teams. There's practice labs, which are actually the perfect place for MSPs to test and experiment before deploying new apps or updates, all without compromising your live system. So you can assign episodes and courses to upscale your MSP team while tracking your training investment. So that's managing seats, assigning and unassigning specific team members, accessing monthly usage reports, and so much more. And you'll boost morale and fortify your business's future with IT pros courses in the process. Upskill your team today by visiting go.acilearning.com/twit. TWIT listeners can receive up to 65% off an IT pro enterprise solution plan.
Unknown: very excited to improve the developer experience for you all to build assistive agents. So let's dive right in. these illustrations are generated programmatically process here is very simple. For each new user, I will create a new thread. And as these users engage with their assistant, I will add their messages to these threads. Very simple. And then I can simply run the assistant at any time to stream the responses back to the app. And I'd like to highlight one of my favorite features here, function calling. If you have not used it yet, function calling is really powerful. And as Sam mentioned, we're taking it a step further today. It now guarantees the JSON output with no added latency, and you can invoke multiple functions at once for the first time. And here, what's interesting is that the assistant knows about functions, that integration allows our natural language interface to interact fluidly with components and features of our app, and it truly showcases now the harmony you can build between AI and UI where the assistant is actually taking action. But next next, let's talk about retrieval, and retrieval is about giving our assistant more knowledge beyond these immediate user messages. What it's uploading, I can just sneak peek, at it. Very typical United flight ticket. And behind the scene here, what's happening is that retrieval is reading these files and boom, And there's more than retrieval. With every API call, you usually need to resend the entire conversation history, which means, you know, setting up a key value store. That means, like, handling the context window, serializing messages, and so forth. That complexity now completely goes away with this new stateful API. But just because OpenAI is managing this API does not mean it's a black box. Now here, what's happening is that code interpreter noticed that it should write some code to answer this query. So now it's computing, you know, the number of days in Paris, number of friends. It's also doing some exchange rate calculation behind the scene to get this answer for us. Not the most complex math, but you get the picture. Imagine you're building a very complex, like, finance app that's crunching countless numbers, So to recap here, we've just seen how you can quickly create an assistant that manages state for your user conversations, leverages external tools like knowledge and retrieval and code interpreter, and finally invokes your own functions to make things happen. But thanks to function calling, things get even more interesting when the assistant can connect to the Internet and take real actions for users. Hey, assistant. Can you randomly select five Dev Day attendees here and give them $500 in OpenAI credits.
Sam Altman: They'll gradually be able to plan and to perform more complex actions on your behalf. As I mentioned before, we really believe in the importance of gradual iterative deployment. These are our first steps towards AI agents, As intelligence gets integrated everywhere, we will all have superpowers on demand.
Unknown: kinda got to the nuggets. Alright. So we've wrapped up the event, and Jeff and I definitely have thoughts. We're gonna get to that here in a second. But first, let's thank the sponsor of this episode of TWIT News brought to you by our friends at IT Pro TV, now called ACI Learning. 94% of CIOs and CISOs agree that attracting and retaining talent is increasingly critical to their roles. Invest in your workforce. Cisco, and Microsoft to security and cloud fundamentals, your team can master it all with IT pro. Plus, you can check out ACI Learning's new product, CyberSkills. That's the training tool for all members of your organization, not just the IT pros. CyberSkills is cybersecurity awareness training for non IT professionals to secure your business on all fronts. IT pro and ACI Learning are with your team every step of the way, and you can visit go.acilearning.com/twit, to check it out. TWIT listeners can receive up to 65% off an IT Pro enterprise solution plan. That discount, of course, based on the size of your team when you fill out their form. And we thank ACI Learning for their support of TWIT News. Alright. So the event is done. We definitely have thoughts. There were parts of this event that certainly you know, it's a developer conference, so it kinda dives into a language around artificial intelligence that I know very, very lightly, you know, not deeply. That's for sure. But I do think that really the big the big announcement that that most, you know, users of ChatGPT, let's say, are gonna be, you know, really curious about is this, this idea of, like surface level results? You know what I mean? Like, that's that's my my concern is how how how deep does the feedback standpoint, like, there's a lot about AI in the last year. Let's just say the last year because this has been a year where people who never even had AI in their vocabulary are now, you know, turning to these services because it can do all these things and everything, and it's easy to use. All you have to do is write the right things. You write write down the right words, and and it gives you something that's usable and everything. And, what you're talking about tells me that in order to go that next step, does that then require more from us, the user, more of an understanding about AI? And if that's the case, then does it kind of limit the the the magic or the the, kind of the the usability by a wider group of people when suddenly there's syntax or suddenly there's rules and and things like that. And but but I think that's super essential. Right? Like, that's necessary. We communicate in ways and and understand in ways that just looking at words on a paper, you know, there there's certain inferences that those words don't pick up on. And, as we humans look to these systems to give us something that kinda speaks our language and can communicate to us in the level that that we're used to talking to each other, that extra layer of of depth if they're figuring it out, that just kinda tells me, okay, are actually figuring it out or are they making guesses that oftentimes GPTs to a point to where they don't allow something like that. At least I hope so. Yeah. And I mean, they also it shows the need for them to make some sort of commitment to the users around this because, I mean, because they have I mean, at least I believe they have the resources to do it, and they need people to trust that they can use these these systems without risk, without risking themselves that lost me for sure only because, like, when he was talking about pricing, it seemed like it was more I mean, was definitely geared towards the developer cost. And I don't know how it compares to prior They're certainly allowing for more, obviously, for developers. Yeah. I'd be curious to know, like, are are developers satisfied with that, or are they still wanting more? Because, you know, from what he was saying, this is this is a big request. It's like, give us the ability to do more with less. but interesting stuff. As for this, the TWIT news live coverage of this event, you can go to twit.tv/news Subscribe there, and you'll get the event with some around it and and all that. That's what we do here. And,