Unknown: honorable minister, distinguished guests, ladies and gentlemen, welcome to this highly anticipated conversation with Sam Altman. Today, we gathered to embark on a journey into the realm of artificial intelligence, guided by the wisdom and insights of one of the brightest minds in the field, Sam Altman. So I extend my deepest gratitude to OpenAI, GDP Ventures, CORICA for organizing this remarkable event, providing us with a platform, actually, the extraordinary advancement of artificial intelligence. In my capacity as president of CORICA, the collaborative research and industrial innovations in artificial intelligence, also as a principal engineer at the National Research and Innovation Agency, as well as a professor of AI at the University of Shakwala, I stand before you humble and honored. For the past thirty five years, I have dedicated my life to studying and researching AI, starting with the knowledge base to the current state of the art of machine learning. So I am really proud to represent the thriving AI ecosystem in Indonesia. Our esteemed president, Jo Kowi, has emphasized the pivotal role of AI mastery, acknowledging that those who harness the power of AI possess the potential to shape the future. As we witness the global AI race unfolding before our eyes, It is imperative that Indonesia embrace the cutting edge technologies like generative AI, large language model, chat GPT, Dell e, and certainly of your highest interest is the artificial general intelligence. We must face the development of the AGI head on equipped with the right strategies and measures. President Jokowi also underscores the importance of our ability to learn and to adapt to this AI technology as it grants us the power to seize opportunities, as we come together, let us acknowledge that the growth and the prosperity of artificial intelligence ecosystem rely on talent, collaborations, and partnerships. In Indonesia, we have taken significant strides towards nurturing our AI ecosystem, exemplified by our Indonesian national AI strategy. AI toward Indonesia 2045. So I hand you this This comprehensive strategy outlines our visions, objectives, and priority areas of AI development, propelling Indonesia towards becoming a global leader in AI. And by aligning our efforts with this visionary strategy, we create an environment that foster the collaborations and integration of AI technologies across diverse sectors. In partnership with others, we pull together our knowledge, expertise, and resources to harness the full power of AI. An integral component of this effort is Corica. It acts as a platform where individuals, academia, industry, community, and government can collaborate, exchange ideas, and collectively enhance AI ecosystem in Indonesia. This collective endeavor will catalyze job creations and strengthen the economy. And now, it is my great pleasure to have Sam Altman, the visionary leader behind CHET GPT. We are really thrilled to have you and the OpenAI team here. This event, the conversation with some admin, proved to be really popular. The attendees snapped up 1,000 tickets in just thirty minutes. a round of applause to Sam and the a OpenAI team. We truly honor and privilege to have you here, Sam. And we eagerly wait for your invaluable insights. Sam. Pam, I'm just curious. Is this your first time to Indonesia? Because you are wearing batik shirts. This looks really amazing. It got me thinking, wouldn't it be fascinating if we could combine the creative power of gpt4org.
Sam Altman: The idea of you know giving a calculus student a you know a test not letting them like use a calculator as they're going would would seem a bit strange. And if we make people do everything the old fashioned way without using tools like ChatGPT, that'll seem a bit strange also. So I think the you know, we're seeing a whole range of outcomes here. We're seeing teachers who are really resisting this and saying this is like the end of the way we do education and really have a very kind of, you know, rigid to it, which I understand and empathize with. And then we have teachers who are saying like, I'm gonna require my students to use chat GBT for everything they do. And I think that's important. And if we think about what the world is going to look like and as these people go off and create things, do jobs in the world, they're gonna have these tools and not training them to be as effective and as useful and creative as possible seems really wrong. So, you know, we've education I think is an interesting example of what's gonna happen in other sectors going forward. We've seen the full cycle. When ChatGPT first came out in The US, And it did get banned in a lot of schools. But then pretty quickly after that it was teachers themselves that were saying, we made a mistake. We're gonna embrace this. We're not only gonna unban it but we're gonna like build it into our teaching. And that has been super valuable I think for many students. And people surprise us every time on the upside of what they're capable of doing. On the second question about the nonprofit to for profit switch. We started as a nonprofit But our tactics have had to change as we realize just how expensive these systems are. We've raised more than 10,000,000,000 US dollars. We expect to raise way way more over time. And given the shape of the technology and the need to make these extremely large neural networks and the ability to sort of attract and retain super talented people, And so we came up with a new structure where we're still a nonprofit but there's a subsidiary capped profit. So we can use the magic of capitalism, give our investors and employees a certain fixed return. But beyond that have the excess return go to our nonprofit. So that if we really do succeed at our crazy dream and we make this technology that is the most impactful technology human ever to human to have yet created, it still belongs to all of us. We can still act in the interest of doing the best thing for the world and not necessarily profit.
Unknown: Okay. Thanks for responding to Mass Mantri here. So I want to go to the floor actually for the next questions. We are using a multimeter for just listing the top questions. So can we have the the top questions on the screen, please? if organization meet agents that are like humans? For example, with names and answer question like a company system,
Sam Altman: but it's a sort of alien form of intelligence. And it'll be good at things that humans are not always good at. It sometimes won't be good at things that are very easy for humans to do. But it will get better at everything. The number one point that I think is misunderstood about the field is the rate of progress and how long we expect that to continue. And so we'll make these agents But I think what will happen is not this sort of standard standard conception that are all you know being directed by different people doing things for us and contributing to this sort of like society in the same way that all of us do. Like the collective ability of this room and intelligence to do a lot of things together
Unknown: we will have this super assistant that helps the company you know to do all those things. So that's I
Sam Altman: think we will. I think we'll all have like you know the equivalent of many super assistants. And we'll all like if you imagine each person being the CEO of a company with like a thousand people and what they can get done especially if those thousand people coordinate well, I can see a future like that. So each of us just has like much more ability to get things done in the world and things just happen much faster.
Unknown: of the list. What is the one other direction that is most promising for AGI apart from this large language models?
Sam Altman: what is the thing that is most valuable for the world that these large language models cannot do. And there's different opinions to that but the one that I believe is contribute new scientific knowledge to human society. I think the way that things get better is the discovery of new science and new technology. Like that is that is the sustainable improvement in human quality of life. If we can imagine a model that we can say, you know, please cure all disease. Please discover the optimal Please help us figure out better cooperation between nations. Please discover physics that let us you know solve climate change or travel between countries very fast. We can go on and on down the list. But these systems that can discover new ideas and help us make faster scientific progress. I think that is And I think that requires a new research paradigm on top of these LLMs. If we think of an example of something historical, we could say you know Newton spent a long time reading textbooks and talking to professors and colleagues and then reading papers and journals and made all of this progress with his mathematical understanding, his ability to do math. But no amount of reading textbooks was going to help him invent calculus. At some point, he had to go off and like think harder and come up with new ideas that didn't exist already.
Unknown: perhaps you can elaborate on that. How does OpenAI evaluate whether an AI implementations or output is deemed good or bad? I think that is something that's this creative output I mentioned earlier. Is it primarily based on consensus among a group of experts? Or does OpenAI involve a panel of key observers? I know the reinforcement learning with human feedback is certainly involving many of humans. Yes.
Sam Altman: So I think there is this idea of how we align our models. How we decide what they should do and not do, say and never say kind of where the limits are. The first part was could we come up with a technical solution. pretty pretty well. We've shown that we can get it to to which I think is even harder. And that is who decide? Who decides? You know, who decides what values we're gonna align these systems to? Who decides what the outer bounds are of what an AI will do and not do? And also importantly and maybe even more contentiously, who decides what the defaults are gonna be? Within that, within these wide bounds, different countries can have different rules. The AI can read, for example, every law of Indonesia and try to follow it. The AI can read a 10 page document of you know, here's the values and the morals of people in this little subculture and do that. Or the AI can talk to you individually, understand your value system and do that. And so there's a huge degree of customization that we can give people. But now we've got to decide like what the general rules are going to be. And it shouldn't, of course, shouldn't be OpenAI deciding that. Right now, is our human feedback providers that do it. But we want to make this as democratic as possible. We just launched a program to give grants for people with new research ideas about how to collect this data on human preferences in a just way from the entire world. We have some of our own ideas that we're trying to about how we talk to people, understand their values, how they think about different trade offs. Also trying to help educate them. Still let them make the final decision about different perspectives. But that's our plan. Our plan is to try to hand this decision making over democratically to the world and respect different,
Unknown: so as a language model that is reaching diverse global audience, including over this 300,000,000 Bahasa Indonesia speakers, Indonesian language speakers in Indonesia and Southeast Asia, it is crucial to ensure inclusivity and accessibility. So considering the significance of Bazaar Indonesia and the rich linguistic diversity landscape in Indonesia, As you know, we have we are one of the largest country with 472 local languages and dialects. Yeah. And I'm curious to know if OpenAI has any plans or initiative. I think you've you've had these questions many times before, but certainly we want to know how OpenAI would like to enhance the language support and resources for Bahasa Indonesia by expanding the capabilities and resources for Bahasa Indonesia?
Sam Altman: We'd really like to improve on this a lot. Know GPT three was good at English and barely passable at other languages. 3.5 was okay at top languages. Four is very good at say the top 20 languages and passable at maybe the next 80. We would like GPT five to be very good at even smaller languages and dialects. We need help for that. I think if Indonesia can make a data set available and evals for those languages,
Unknown: With 99 foot here, OpenAI has brought the transformer architectures a better architecture will look like and is OpenAI
Sam Altman: We still don't see any limits to how far we can push these models. We may find some at some point. It'd be interesting if we do. But what has happened is we've used up the easy compute overhang. And it's gotten a little bit harder to keep delivering the same levels of gains just with compute. So we do need new paradigms. We need more efficient algorithms, better data sets, all of that. There's many new directions to pursue, but the one that I think is most important by far to get to AGI is the thing that I touched on earlier with being able to generate new ideas. That is still something that our systems are really not good at, you know, contributing new knowledge back into society.
Unknown: what do you think distinguishes this Silicon Valley from the rest of the planet in terms of AI in the field? I think some of the innovation regulators
Sam Altman: professionally, socially, economically, whatever, acceptable to fail hard many times. If people feel like it's okay to totally fail at something, Not good. It always sucks and is painful. But if it's at least tolerated, then people are willing to take bigger swings. And one of the things that we that we noticed at YC that was just always very different about Silicon Valley than the rest of the world is you could like try a very ambitious idea. You could totally fail at it. And like Silicon Valley, the whole machinery would totally tolerate that and let you go on and do your next thing. And in in much of the rest of the world, if you what what I think that does very naturally is push people to more incremental ideas with higher probability of success. And that's perfectly fine. There's good reason for that. But if you want to stay at the forefront of technological progress in a startup ecosystem, then it's not fine. Because by sort of by definition, most times when you're trying to advance the frontier and you don't know what's gonna work, you fail at that. And and so I think this is this is like a pretty important thing. And it's not it's not just like access to capital or jobs. It's gotta be socially acceptable too. It's gotta sound like okay to your friends and your colleagues to say, I'm gonna go try this this very ambitious likely to fail thing. And and you know, I'm gonna work on something that's like uncertain and that it's gonna be misunderstood for a while. And certainly when we started and we said we're gonna work on AGI, that was like very outside of the Overton window and you know kind of you get looked at a little bit funny. But that was fine. Like Silicon Valley has a long history of tolerating that. So I think that's the single biggest difference I've noticed. The talent is distributed super well around the world. Capital is getting better distributed. But this sort of this culture of we're gonna take the big swings and it's okay if they don't work out, I think that has not spread as much. So
Unknown: that that relates to some of the questions that I I I saw you at the Congress Senate hearing. And I see a lot of tough questions coming from the senators about how we regulators should be doing in light of this generative AI and AGI and things like that. That including how to actually nurture the AI ecosystem, right? So in some of the question that they have posed, think I would like to recollect what they have said. One thing is about this, how should we consider the AI regulatory scheme in this case? Because as you know, it's growing exponentially.
Sam Altman: Yeah. I think there's multiple like levels of threats to address and also different time scales. Different countries are gonna have very different regulatory approaches to some of the the short term challenges. You know, how do we think about issues of bias in the systems? How do we think about issues of reliability? How do we think about sort of economic impacts? But one thing that we've been discussing on this trip around the world, this is the twenty first country we've been to in the last month, Is the need for the global community to come together around regulation of AGI. So as these systems become so powerful that they affect the entire world. I think we do need a global response there. The upside is of course tremendous. But the downside gets quite severe as these systems become say as powerful as all of current human society. And there's been a great deal of interest on our trip around how the world comes together to say, okay, what is a licensing framework and what are safety standards for people that are at the very frontier? That's very hard to do of course, but we've done it when we faced global risk before. Nuclear weapons, some parts of biological
Unknown: is something that's very wise. Let's go for the next question for you, Sam. What metrics and indicators you as the CEO keep an eye on on a daily or weekly or monthly
Sam Altman: about OpenAI than any company that I've worked closely with before is fundamentally we're a research company. And you know, we do have to make products and we love making products but that's all well understood. So the metrics for like ChatGPT are standard and what you'd expect from any company. Know, we look at or even our API. You can just look at like active users, you can look at Net Promoter Score, you can look at revenue growth. And that's all like well understood and that's kind of like in the tech company lore. What what's new for us is how to build a company that does great research. And what metrics are you supposed to look company that's trying to produce repeated research breakthroughs? you know, when I I came into OpenAI thinking like, oh this will just be like a software company. We'll set quarterly goals. We'll have like metrics that we look at. And that really didn't work at all. There are some times like when we're training a model and we have an evaluation with a metric and we get to watch it go up and that's very satisfying. Everyone loves that. It's really fun. But if you're trying to figure out a new paradigm, you that kind of like just doesn't that that just doesn't work. There was a researcher that used to work with us named Ken Stanley called greatness cannot be planned. And it really changed like all of my thinking about how we manage research. And now, it's it's like much more about If sort of it fundamentally fits our the parameters of our research taste, Most of the time it doesn't work out. When it does work, it works breathtakingly well. And then you the kind of the art is trying to notice early when something is showing these early signs and you want to put a lot of resources behind
Unknown: recently there's been discourse around existential risk posed by AGI. How much should AI companies prioritize these threats over more immediate threats presented by
Sam Altman: I think both short term risks and long term risks are very important to think about. Our mission as a company is very AGI focused. And so we spend most of our time thinking about these longer term AGI risks. There's many other companies thinking about the shorter term risks. However, we believe in iterative deployment and we think we have to address the risk at each step. So even though our mission is about these longer term risks, we spend a great deal of time trying to mitigate the shorter term risks and that helps us learn along the way. I think that g p t four is the most aligned model ever put out. And there's no existential risk from g p t four. All of the risks there are short term, clear, and present. And it took us about eight months after we finished training it until we released it to address those short term risks. So we think there's a balance, but we differentially, because of our mission, focus our attention on the AGI risk. answer is that the future models have to decide what good data is and what isn't. What they want to train. Like the model should choose what data it wants to train on. And if the data is high quality and interesting and increases the model's capability and understanding, whether it's human generated or generated by previous LLM, that's okay. The model will have to decide, is this accurate? Is this helpful? Do I wanna like believe this and add to my training set? It's the exact same thing we do. You know, when we're presented new information, we use our existing model of the world to decide if we wanna incorporate it or not. And whether a person tells us that or technology tells us that, we still just evaluate the quality and the utility of the information.
Unknown: Indonesia national strategy, right? So Indonesia has set ambitious goals in this AI national strategy. We try to aim and harness the potentials of AI for the economic growth and societal development. And I think OpenAI has been at the forefront of AI research and development driving innovation with all the products and pushing the boundaries of what AI can achieve. So how do you see OpenAI's mission aligning with these goals? Especially for our national strategy, put down four focus area is ethics, regulation and policy, data and infrastructures, talent development as well as research and educations. And on top of that, as the baseline, we have these five priority areas written in that national strategy. One is healthcare, the other one is food security, research and innovations, bureaucracy reform as well as smart cities and smart mobility. And as you know, we are also are planning to have our new capital city, Nusantara, now in the making. And how do you see that OpenAI can support all these sectors?
Sam Altman: And But our kind of plan is to make the best
Unknown: new discovery, new drug discovery based on traditional with the appearance of, larger models on health, on food and other and agriculture. Yes. So let's try to go to the next question on top on the list. Recently, we've seen companies such as Palantir implement large language models for military use? What is your stance regarding this ethical application of of this? Right?
Sam Altman: a particular single sentence because, of course the answer is it's like very nuanced and it depends.
Unknown: Can we have the next question, please? Before I will try to take this time also to invite another one from from the board, but let's just go ahead have mistakenly implicated that students for implicated students for allegedly using GPT in their work. I think that is really you advise universities on moving on moving forward on on this?
Sam Altman: Yeah. So I think there will be ways we can make these detectors better. We can also probably make some watermarking systems that help encode in images and maybe in long versions of text if if something is likely to be generated by an AI. should not get a student in trouble because I don't think we can say with certainty that that's what's happening. We've just adapted the way that we evaluate students. And I think that's the long term solution. But in the short term, we'll have figure out how we're gonna balance these. You know, I think we'll use detectors. We'll use watermarking for some stuff. But we'll understand it's imperfect.
Unknown: we still have some times. And is there still any other question that we we can go ahead and what steps is OpenAI taking to ensure
Sam Altman: the world's ethical values and building a system that can respect those and allow customization in different contexts is super important. So if you're interested in this, I'd really encourage you to apply to our program to help with this. And I also We'd love feedback on what we're thinking about. The things that we're trying, you know, the systems that we're starting to use to collect this. We have a lot of users now. So we can talk to a broad swath of humanity and get and collect this feedback.
Unknown: we emphasize the importance on transparency and accountability in AI system. But we still need to undertake to address these concerns, especially for OpenAI that is rapidly developing the large language models and others. And I think this was also being a disclaimer of by Czech GPT, right? And so can you emphasize the need for how we can respond to inquire more on the specific measures in implementing to tackle bias in AI system and to ensure that the benefits of AI. I think because we are in Indonesia with this 300,000,000 populations coming from different ethics backgrounds, We have layers of ethical principles. And also our ideology, Panchasila, this is the five principles that we adopt to. We need to to
Sam Altman: I think no two people are ever going to agree that one system is unbiased. Like that's probably impossible. Right? There are going to be some things that we have to agree on globally. You know like are these systems ever allowed to go kill people is something we can probably agree on easily. And there will be other things that are very different in different countries. You know, like free speech is handled differently in The US than in other places, for example. And again, we have an incredible new tool, which is these systems are capable of you know, like with any previous technology. And so, I can imagine a world where we have a global tier and we say, Alright. Here is the limits on what a very powerful system just can't do. Because we think it's like, it's not only unsafe but it's so unsafe it affects all of us that you can't use these systems to design like a Like you know, a lot of control within the very wide bounds of their society and the globe, I think is quite important.
Unknown: Okay. So I see that we have reached our time actually. Okay. It went so fast. Right? So probably, I need to give the some time for you to have the closing remarks to all of us here, the Indonesian CI enthusiasts, developers, all the also to the minister, Mas Mantri, Nadim, and all the regulators that are probably here, the ecosystem from community. I think academia, businesses, community, and governments are all here. So please.
Sam Altman: I think this is likely to be the most impactful technological revolution that humanity has yet created. And the importance for all of us to participate in shaping that, the more we work together, the more we talk, the more we really engage with this technology and decide what we want the world of the future to look like, the better it will be. One of the reasons that we deploy these systems as we go is so that we can have this conversation. So that people can get a feel for the technology. Where it's going? What's gonna be possible? What's not? What we want and what we don't want. And unimaginably better in terms of everybody's quality of life than the world today. I think this is like an unstoppable technology but certainly one we shouldn't stop. certainly one of the biggest challenges we've ever faced. But definitely one of the most exciting and the highest potential. And I think the people and the countries that embrace this the fastest will be quite rewarded. And