Unknown: and it's totally amazing. What is like when you're and it's a young boy? Yeah. And what's something that you think is need or what's one thing that is bringing you joy with it? Watching
Sam Altman: the speed with which he learns new things or gains new capabilities is just unbelievable. It's like every day, it's like, oh, man. He just couldn't do that before, and now he's grabbing stuff and passing it between his hands. Getting to watch it day to day is just an amazing rate of change. And then I don't like, again, I realise that everything about babies are very finely tuned over a long period of evolution to make us love them and be fascinated by them, and it's like a neurochemical hack. But I love it, it's great, it's so strong, it's so intense. So it's really almost like a coffee for your heart or something, kind of?
Unknown: Yeah, he's totally turned on now. Really aware, understands things. It's super cool. I have a thought sometimes that this will be one of the last, maybe 40 that we conceive children in the body. Did you have any thoughts about that?
Sam Altman: You know, I think there's another like, another take I have on all of this is that in this world that we're heading to of, like, crazy sci fi technology becoming reality, the the sort of, like, the deeply human things will become the most precious, sacred, valued things,
Unknown: Yeah, what does that look like when you think about that? Yeah, with AI, with so much new information coming online and so much data being collected and information being carpooled, maybe
Sam Altman: twelve years ago, something like that, fourteen years ago, that has really stuck with me. It was like a little baby in a dentist waiting room or something picking up one of those old glossy magazines and going like this. Oh, I remember that. And to that kid, was just like a broken iPad because that kid had just, like, grown up in a world where, like, there were touch screens everywhere. And my kid will never grow up will never ever be smarter than an AI. But also, they'll never they'll never know a world where, like, products and services aren't way smarter than them super capable. They can just do whatever you need. And in that world, I think education is gonna feel very different. I already think college is maybe not working great for most people, but I think fast forward eighteen years, it's gonna look like a very, very different thing. Yeah.
Unknown: Maybe there's a few of these. He's like, Somebody charged this magazine, he's yelling. How would you recommend to a parent right now to prepare their children for an AI future? Are there certain curtails that you would start to put in now? Are there certain adjustments where you get them in a certain training or have them start to watch certain models of things online? What does that
Sam Altman: But if you're like a 50 year old I do have worries about kids and technology. Like, I think this scrolling the kind of, like, you know, short video feed dopamine hit, it feels like it's probably messing with kids' brain development a super deep way. Mhmm. So it's not that I have no worries. I have, like, extremely deep worries about what technology is doing to kids. But in terms of kids' ability to, like, be prepared for the future and use a new technology,
Unknown: they seem really good at that. Always through history. That's a good point, actually. Yeah, it's like if you just grow up with it, it's just like having it just totally normal. It's like having kneecaps or whatever, you're just kind of used to it.
Sam Altman: And the answer is, like, yeah, maybe memorization is less important. But with these new tools, you can think better, come up with new ideas, do new stuff. I'm sure the same thing happened with the calculator before. Yeah. And, you know, now this is like, this is just a new tool that exists in the tool chain. And what about, like, say if there is somebody that's, like, learning history right now, like they just started their second year of Oh,
Unknown: So say there's somebody just, for example, like there's learning history right now, they're in their second year of college, they're taking history, is that Are there some subjects in, like, they're gonna be a historian? Is that still a viable space of work as AI moves forward, do you think, honestly?
Sam Altman: I assume there will be some version of it that is I think it's very hard to predict exactly how something evolves this CEO of an AI company or a podcaster, like, you know, probably would have been things that didn't seem to be the most obvious evolutions of the things people were doing at the time. Yeah, you just seemed almost probably crazy even in trying to explain those to someone. You would. And now, in fact, I heard that the job that young people most want is some version of your job. The job that young people most want is to be, you know, podcast influencer, is is fast, and also trying to predict what they are, I don't know. The thing I say all the time is no one knows what happens next. It's like we're gonna figure this out, it's this weird emergent thing. Does the current job of a historian exist in the same way? I'll bet not quite, but another thing I believe is that humans are obsessed with other people. Like we are so deeply wired to care about other people, to care about stories and history, our own history, is extremely interesting to us. So
Unknown: I take that avenue of thought like, okay, there will still be this historian or somebody else, it'll be some evolution of that, right, that does seem kind of cool to me because there's a level of creativity in there, there's a level of faith and spontaneity in there that I think is kind of exciting.
Sam Altman: for OpenAI? I think that's great. Right.
Unknown: So you could create something that would have your job, but then you could do something else. Totally.
Sam Altman: I think we we we will rely on the fact that people's desire for more stuff, for better experiences, for, you know, a higher social status or whatever, that seems basically limitless. Human creativity seems basically limitless, and human desire to, like, be useful to each other and to connect with each other and do stuff for each other and focus on other people seems pretty limitless too. So I think throughout all of history there have been these predictions like, you know, everybody panicked and said there's gonna be no more jobs. And we figured out new stuff to want. Now here's an interesting thing. Mhmm. If you could go back to that Industrial Revolution time and people before that were, you know, really on the grind Mhmm. Working super hard trying to, like, kind of have enough food to survive, go back to those people. Look at our jobs today. Would those people say we have real jobs? Or would they say you have unbelievable abundance, unbelievable wealth, so much food to eat, incredible luxury, and you guys are just like playing a game to entertain yourselves. Is that a real job or not? And they would probably say, where they sit, what you guys do is not a real job. You guys are, you know, you're too rich, you're wasting your time, you're trying to like think they're working very hard. It'll feel very satisfying, very intense to them. They're really like they'll feel engaged. They'll be making people happy, they'll be creating value for each other. But if we could look forward that one hundred years at those guys, Right. But I think that's beautiful. I think it's great that those people in the past think we have it so easy, I think it's great that we think those people in the future have it so easy. That is the beautiful story of us all contributing to human progress and everybody's lives getting better and better.
Unknown: Say we're able to get to that space, right, like movement that happens with AI and with just technology, which will advance quicker, I think, which is one thing that AI feels like to me is a fast forward button on technology and on possibility because information can be quantified so quick in a lot of more menial tasks, even though they're not really menial in people's lives, but menial hypothetically Like, how do we adjust our structure of, like, if some people own the companies that have the AI and then a lot of people are just using the AIs and the agents created by AIs to do things for them, how will society, like societal members, still be able to financially survive? Will there still be money? What is that?
Sam Altman: I'll say two guesses. One, I think it is possible that we put, you know, GPT seven or whatever in everybody's ChatGPT, everybody gets it for free, and everybody has access to just this, like, crazy thing such that everybody can be more productive, make way more money. It doesn't actually matter that you don't, like, own the cluster itself, but everybody gets to use it, Mhmm. And it turns out even getting to use it is enough that people are, like, getting richer, faster, and more distributed than ever before. That could happen. I think that really is possible. There's another version of this where the most important things that are happening are these systems are discovering new cures for diseases, new kinds of energy, new ways to make spaceships, whatever, and most of that value is accruing to the cluster owners, us, just so that I'm not dodging the question here. And then I think society will very quickly say, okay, we gotta have some new some new economic model where we share that and distribute that to people. I used to be really excited about things like UBI. I still am kind of excited, like universal basic income where just give everybody money. Yeah, you hear that term a lot, yeah, universal basic income. Yeah, heard you and Rogan talk about that too a while back. I still am kind of excited about that, but I think people really need agency, like they really need to feel like they have a voice in governing the future and deciding where things go. And I think if you just, like, say, okay, AI is gonna do everything and then everybody gets, like, a, you know, dividend from that, it's not gonna feel good, and and I don't think it actually would be good for people. So I think we need to find a way where we're not just like if we're in this world, where we're not just distributing money or wealth, like, actually, I I don't just want, like, a check every month. What I would want is, like, an ownership share in whatever AI creates so that I feel like I'm participating in this thing that's gonna compound and get more valuable over time. So I sort of like universal basic wealth better than universal basic income, and I think I don't like basic either. I want, like, universal extreme wealth for everybody. But but even then, like, I think what people really want is the agency to kind of co create the future together. And And in a world where it's like the AI is mostly at least we've got to still have humans invent the new culture and have that be a very distributed thing. 8 quintillion tokens per year, if that's the world actually, let's say the world can generate 20,000,000,000,020 quintillion tokens per year. Tokens of? Like, each word generated by an AI. Okay. Just making up a huge number here. Okay. We'll say, okay. 12 of those go to, you know, the normal capitalistic system. Mhmm. But eight of those, 8 quintillion tokens are gonna get divided up equally among 8,000,000,000 people. So everybody gets 1,000,000,000,000. And that's your kind of universal basic wealth globally, and people can sell those tokens. Like, if I don't need mine, I can sell them to you. We could pool ours together for some, like, new art project we wanna do. But but instead of just, like, getting a check, you're get everybody on Earth is getting, like, a slice of the world's AI capacity, and then we're letting the, like, massively distributed human
Unknown: One of the big fears is purpose, right, like human purpose, like work gives us purpose, And also, think the idea that we are the ones advancing humanity gives us purpose, like we have control over our own destiny maybe gives us this sense of purpose, and it feels like that we would lose a sense of purpose or that purpose would be adjusted if AI is to really continue to advance so quickly. It feels like our sense of purpose would start to really disappear.
Sam Altman: Have you had thoughts about I worry about this a lot. So I think people have worried about this with every big technological revolution, but I agree that this time it feels different. intelligence I think cuts so deeply at the core of whatever we are and how value ourselves. One example we can look at this right now, I think one area where AI is having a big impact, is on how people write software for a living, and AI is really good at that. It's really changed what it means to be a software developer. I haven't heard any of those software developers say that even though their job is different, that they don't have meaning, they still enjoy it. They're operating at a higher level. And I'm hopeful, at least for a long time, you know, a hundred years from now, who knows, but I'm hopeful that that's what it'll feel like with AI is even if we're asking it to solve huge problems for us, even if we ask it to say, like, know, go discover a cure for cancer, that feel valuable to a person. You're still asking the questions, you're still helping guide it, you're still framing it, you're whatever it is, you're still talking to the world about it. And and I think all of human history suggests that we speck in this very huge universe. And so I somehow think, even in a world where AI is doing all of this stuff that humans used to do, we are going to find a way in our own telling of the story to feel like the main characters. And I think, in an important sense, we will be. And that's really good. I also, like, you know, probably already today, there could be a very compelling version of two AIs talking like this, Like, think I I really do feel deeply wired to, like, care about the real person behind it. Think that's deep in the biology. Right.
Unknown: and these fear holes of possibility or Yeah. I that feeling right there, that's the feeling a lot of people kind of have, like, when does it happen? What's gonna happen? to conceptualize until you're further along.
Sam Altman: Totally, I don't think we know quite how that's gonna feel, you just have to approach real problem with this earlier, but it can get much worse, is just what this is gonna mean for users' mental health. There's a lot of people that talk to ChatGPT all day long. There are these sort of new AI companions that people talk to like they would a girlfriend or a boyfriend. And we were talking earlier about how it's probably not been good for kids to grow up on the dopamine hit of scrolling
Unknown: It's some people say it's back. It's not back. It's one of the best things is is it hasn't left. It is it is maintained itself as a viable form of currency. And I'm back in. I'm back invested. And when I need more Bitcoin or Solana or XRP, MoonPay is always the first app I open. Since MoonPay works with Apple Pay, Venmo, PayPal, bank accounts, and credit cards, it's fast and easy to get what I need in a few clicks. And because MoonPay has been around for six years and is used by millions of people, they've also formed pretty cool relationships with other companies in the crypto space. leading to exhaustion, brain fog, digestive issues and more. But here's the thing, you don't have to settle for feeling like garbage 20 fourseven. OMRA colostrum is nature's original health hack. Packed with over 400 bioactive nutrients that fortify gut integrity, strengthen immunity, revitalize hair growth, fuel stamina, elevate focus, and help you function like a human again. I love using it in my smoothies at home. I'll make me a little smoothie. Bang down. or enter the0 to get 15% off your first order. That's tryarmra.com/theo. What legal system does AI have to work by? Is there like a legal Like, we have laws like in the world, right, like in the human world. Does AI have to work by any legal laws?
Sam Altman: So I think we will certainly need a legal or a policy framework for AI. human centric version of that question, people talk about the most personal shit in their lives to chat GPT. Young people especially use it as a therapist, a life coach, having these relationship problems, what should I do? And right now, if you talk to a therapist or a lawyer or a doctor about those problems, there's like legal privilege for it. You know, like it's there's doctor patient confidentiality, there's legal confidentiality, whatever. And we haven't figured that out yet for when you talk to ChatGPT. So if you go talk to ChatGPT about your most sensitive stuff and then there's like a lawsuit or whatever, like we could be required to produce that, and I think that's very screwed up. I think we should have like the same concept of privacy for your conversations with AI that we do with a therapist or whatever. And no one had to think about that even a year ago, and now I think it's this huge issue of how are we going to treat the laws around this. Well, do you think there should be kind of like a
Unknown: slowing things down before we move there kind of? Because, yeah, that is kind of wild. It's one of the reasons I get scared sometimes to use certain AI stuff because To not talk to Chatuchu Biti? No, no, no, to like really want the privacy clarity before you use it a lot. Yeah. Like the legal clarity. Yeah, it's scary. And it's like, well, how long does it take lawmakers to come up with that? And then it feels like it's moving so fast that it's like it doesn't even matter. That sometimes it's like it doesn't even really matter. It's like, are we even waiting for the laws to be put around this? Yoshua do we keep the pool safe, how much water should be in it, the chlorine, they have deception techniques inside of them, like that there were AIs that would rather give you an answer that was possibly pleasing to the user than to give them the factual answer. And then he was also saying that there were AIs that were developing some of their own languages to communicate with each other, which would be languages that we don't even know. Do you guys curtail that? When those types of things come up, what does that even kind of feel like to you guys? Are these just problems that happen in new spaces and you figure it out as you go?
Sam Altman: where you have a group of scientists look at their creation and just say, you know, what have we done? Maybe it's great, maybe it's bad, but what have we done? Like, maybe the most iconic example is thinking about the scientists working on the Manhattan Project in 1945, sitting there watching the Trinity test and just, not human scale kind of power and everyone knew it was gonna reshape the world. And I do think people working on AI have that feeling in a very deep way. We just don't know. We think it's going be great. There's clearly real risks. more than that, but in truth, I think all we know right now is that we have discovered, invented, whatever you want to call it, something extraordinary that is going to reshape the course of human history. Dear God, man. But if you don't know, we don't know. of course. I mean, I think no one can predict the future. Human society is very complex. This is an amazing new technology. Maybe a less dramatic example than the atomic bomb is when they discovered the transistor a few years later. The transistor radio? Transistor part that made computers and radios and everything else. But we discovered this completely new thing that enabled the whole computer revolution, and it's in this microphone and those computers and our iPhones. The world would be so different if people had not discovered that and then over the decades figured out how to make them smaller and more efficient. And now we don't even think about it because the transistors are just in everything. We have all this modern technology from that one scientific discovery. And I do think that's what AI is going be like. We had this one crazy and that is going to change the course of society in all kinds of ways,
Unknown: Was hoping you would, you know? Like, that's what we're because we don't know. a wild wizard, there's a couple different things, but then there's also this part of me that's like, This guy is this hopeful guy who's involved in this crazy space, and he kind of has this whimsical energy about the future, which is in a crazy way a nice energy to have about the future generally, is that something could happen or that things possible. So it just, yeah, it's all kind of like, I don't know, it's definitely fascinating to me. Sam, to kind of pivot a little bit, it feels like there's a race right now in AI, right? Would you say that there's a race between companies and AI? It certainly feels that way. Yeah. And it almost feels like you guys are the new Formula One drivers. Or you guys are like the new, like, it's like Mario Andretti or you guys are the new Bubba Watts and all the It's almost like these are the new race cars that everybody's kind of watching position themselves. What is the race for? Because you hear about AI and then you hear about AGI, and then you hear about superintelligence. What is this race that's going on, how real is it, and what is the race for?
Sam Altman: And it turned out that those gigahertz measurements eventually were not even that helpful. Like, could have one that had a lower number and it was in practice, was faster. And eventually, I think it was Apple that realized they should just stop talking about the clock speed of their computers, You know, I score this on this benchmark and this on that one. And now people are realising that like, okay, the benchmarks are kind of saturated, we went through the equivalent of our MHz race with our benchmark race, and now people kind of don't care about that as much. And now it's like who's using the model, who's getting the value out of it, I do think people still feel like we're heading towards some milestone. What the milestone is, they disagree on, but maybe it's maybe it's a system that's capable of doing its own AI research and its own sort of self improvement. Maybe it's a system that is, like, smarter than all of humans put together, but they feel like there is some finish line to cross. I actually don't quite feel like this, but think a lot of people in the industry that there's some finish line that we're gonna cross. Maybe it's this, like, self improvement moment, maybe you call that super intelligence. And I think there is a sort of there's like a race to get somewhere, but people don't agree on where it's to or something. What I don't think I can articulate anything where I would say, like, this is mission complete. But if had to give, like, a self referential answer there, you know, the moment where we would rather give our research cluster, like our GPUs that we run all of our AI experiments on, the moment where we would rather give that to an AI researcher rather than our brilliant team of human researchers, that does at least seem like some kind of very different new era.
Unknown: the people and go to the computer,
Sam Altman: there's this one thing that the tool's way better than us at, now we've got go solve some other problems, so let's put our brainpower there. I still don't think it'll ever feel like we all just get to push a button and go on vacation. Got it.
Unknown: Yeah, because at a certain point, if something has all the information, right, if something has all the information, it can think and ponder and pontificate and serve multi options of answers,
Sam Altman: GPT-five is the smartest thing. GPT-five is smarter than us in almost every way, you know, and yet here we are. So there's like there's something about the way the world works. There's something about this doesn't mean it's true forever, but there's something about what humans can do today that is so different. There's also something about what humans care about today that is so different than AI, that I don't think the simplistic thing quite
Unknown: who knows? Is part of you want to kind of get there? Like, how do we get where I open the door and I say, excuse me, sir, and it's just my computer in there? You know what I'm saying?
Sam Altman: sort of thought about these technological revolutions that happened one at a time. There was the Agricultural Revolution a long time ago and that freed us up to do these other things, and then there was the Age of Enlightenment and there was the Industrial Revolution and there was the Computer Revolution and all these things happened. And I thought of them as like these distinct things. And now I view it as just this one long compounding exponential where all of these things come together, each piece of technology is built continuously, overlapping on the one that comes before, we're able to just do more and more. And so in some sense, AI is this big, special, unique, different thing, and in some other sense, it is just part of this long arc of human progress. We talked about the transistor earlier, but like, that was way more important in some sense to AI happening than the work we do now. And all this stuff has to like compound, compound. You've to build the Internet, you've got to get all this data, you've to do all these things. And I want that exponential to keep going. There will be things way after AI. We'll invent all sorts of new things, we'll go colonize space, we'll go build neural interfaces, who knows what else we'll do. But I think at some point, AI fades into that arc of history. We don't even think about it, it's like transistors, which we even think about today. It's just another layer in the scaffolding that humans collectively have built up bit by bit over time. And where you sit in our day, you get to open that door, you have this, like, computer that only has one interface. You just it says what do you want? You say whatever you want, it happens. And you figure out amazing new things to build for the next generation and the next and the next. And we just keep going.
Unknown: I can't build any I can build some stuff, but I can't build, like, any technological stuff. of use of myself in the future? No, I think this is Do you think right now if humans, regular average humans, most humans, could vote to keep AI going or to stop AI, what do you think that they would
Sam Altman: which a lot of people know, they would say like, keep it going. And most people who don't would say, it's scary, stop it. What do you think?
Unknown: probably that. I think that in the end. I think there's a general feeling of like, well, if all the trucking jobs disappear, if those become automated and yeah, if everything becomes a robotax, will that feel, where will those people go for jobs? Will everybody just be dancing on TikTok trying to get people to tip them for trends and stuff? There's part of that. I had this dream years ago that it all ends with everybody's driving an Uber and literally holding each other at gunpoint to be each other's passengers, right? Get in my gear because that's how bad Like, somebody's like, I need the fare more than you do. My whole family's in the backseat. Sit, shotgun, we'll get you to where like people are literally holding each other at gunpoint to subscribe to their OnlyFans and stuff. Like it's just that dystopian or whatever. So I guess part of that, but then there's a deeper part where it's like, yeah, what comes out of us if it feels like a lot of the regular stuff that gives us purpose, that we know right now gives us purpose? Is there a new evolution of our purpose? Is there like a blooming inside of us? Is it this utopian place that you almost think of as like a heaven idea where provided for, can take care of themselves? I guess that's it,
Sam Altman: love to be useful to each other, and people love to express their creativity as part of that. Mhmm. And as the long term trend of society getting richer has continued, more people, I think, are able to do get closer to sort of expressing themselves in the best way that they can. May maybe, like, you know, as recently as five or six hundred years ago, not very many people got to be artists. The world wasn't that rich. There were a limited number of patrons that could, like, pay you to create art, but there were more than zero. And before that, there were almost none. And then you got this beautiful Italian Renaissance and all of this amazing art because there was excess capital in the world. And now a lot more people can be artists or a lot more people can start startups, which is another like, for me, that's my expression of creativity. Right. And this idea that people can find whatever way they can to express themselves, their talent, their vision for a kind of collective love of other people and a care for putting their brick in society's progress. But I think it's such a bad bet to assume that either human creativity or human fulfilment from being useful to other people ends. our collective standard of living goes way up, the whole world gets way richer, we all get more, we all expect more. And even over, like, the course I was thinking recently, like, food is so much better than it is when I was a kid. Like, the world has just figured out how to make food better. Like, we've, you know, figured
Unknown: And, like, I think that's great. I don't wanna go back to eating, like, the frozen carrots or whatever. Yeah. I guess that's a good point. But then there's some like I saw this thing the other day. It was like a kit they had like one of those robo kitchens or whatever. You know when you order food from like something Dash or whatever? And then you
Sam Altman: don't like you feel like something's missing, right? You're like, this is fake, I can tell. I get less enjoyment. You would rather get that food from, like, the dude who's been making it and perfecting it on the, that little pizza shop on the corner for the last twenty years. Because that dude
Unknown: Yeah, because I think I start to feel like we're in this universe where it's like you're walking down the street or something and like a Waymo goes by and it's like, eat now, and you're like, but and you already did eat, it's just got a bad reading or something, it's got a bad valve in it or something, and you're like yelling at it, there's nobody in there, and you're like, I already ate. It's like, sit down and eat now, and it just like fucking uses like a t shirt cannon to just like shoot a burrito at yours. And then you're sitting there, you're eating that, you know? And then the GLP car goes by, right? It says I can help you out. Yes. And it's like, obviously, you've overeat, and you're like, I didn't even want to eat. That thing's messed up. Right? You're yelling at a car that has no driver in it, and then it shoots you with three GLP-one darts in the neck, and now
Sam Altman: that's not helping me really accomplish my true goals in life. And I think if AI does that, people will reject it. However, if ChatGPT really helps you to figure out what your true goals in life are and then accomplish those, And I think if AI feels like it is helping you try to accomplish your goals and be your best, that will feel very different than the last generation of technology. Yeah.
Unknown: And you know what? And that's where I'm like and that's where a kid growing up right now, to them that would probably some young people might be like, that makes the most sense. I'm a little older generation, I might be like, oh, that seems a little But that's always how things are a always generation how to generation. Yeah, That's NetSuite by Oracle. Your AI powered business management suite, trusted by over 42,000 businesses. NetSuite is the number one cloud ERP for many reasons. It brings accounting, financial management, inventory, HR into one suite. You have one source of truth giving you the visibility and control you need to make quick decisions. NetSuite helps you know what's stuck, what it's costing you, and how to pivot fast. one of the most trusted companies in the world. It's one system, full control, tame the chaos with NetSuite. If your revenues are at least in the 7 figures, download the free ebook, Navigating Global Trade, three Insights for Leaders at netsuite.com/theo. That's netsuite, netsuite,.com/theo. there were people like lobbying and state legislation against AI.
Sam Altman: There have to be some rules here. There has to be some guidelines. There has to be some sort of regulation at some point. I think it'd be a mistake to let each state do this kind of crazy patchwork of stuff. I think, like, one country wide approach would be much easier for us to be able to innovate and still, like, have some guardrails, but there have to be some guardrails.
Unknown: you guys' data?
Sam Altman: Are they going to stop learning? There's a lot of concerns about that. Is this going to spread fake information? Is this going to influence elections? But we've never had the like, you can't say bad things about the president Trump or whatever. hundreds of millions of people talk to ChatGPT every day, and it probably has like a big impact on what they believe, and so I think society's interest in making sure that we are, you know, a responsible neutral party should be huge. It's about, like, approximately one gigawatt facility. Huge. You know, it'll be the biggest data center ever built by the time it's done. and it's humongous. Yeah. I wish I had, like, more concrete answers for you Mhmm. But, like, we're stumbling through this. We maybe, you know, have a little bit higher confidence than the average person,
Unknown: but there's so much we don't know yet. No. That's the craziest thing about you, Sam, and I think this is a compliment somehow, dear God. And yeah, it is a compliment. It's like You're like, come with me through the universe. And people are like, well, what's it like? And you're like, I don't know exactly, but And then it's like we're all going. It's like, I don't know, you're just somehow the most
Sam Altman: I assumed that there were always some adults in the room. Someone had a plan. Someone knew everything was gonna happen. Someone had it all figured out. And I sort of think why people like conspiracy theories is it's nice to think that someone's got a plan. It's nice to think someone that, and we're working really hard, but, like, you know, we try to always say what we think the possibilities are, sometimes it's in the broader set, and sometimes it goes in a totally different direction than anything we thought. And, you know, we keep trying to make progress, figure out more, we try to tell people, not just tell, we try to show people by, like, deploying these systems and saying, hey, you can go use it. Don't just take our word for it, try it out, see what it can do. Yeah. the world needs a lot more processing power. But if that looks like tiling data centers on Earth, which I think is what it looks like in the short term, in the long term also, or we do go build them in space, I don't know, it sounds cool to try to build them in space, but also really hard. What about the environmental effects of those and stuff? Like, there's
Unknown: some in like Arizona and Iowa that there's been repercussions within the environments here in the communities. you know?
Sam Altman: harm the environment, and power can become abundant and pretty limitless on Earth and Yeah, there'll be some way to watch fusion. It'll be awesome. It'll be, like, loud and bright and theatrical, and it'll be making huge amounts of energy. Even if you can't watch the two atoms hit, you'll watch them collectively produce fireworks. do we need that? I bet we can get there without it, but to provide it at the scale that humanity will demand it, I think we do need it. Because people the the desire to use this stuff, and energy. The ability to, like, have great ideas, come up with plans, and then energy is the ability to, like, make them happen in the world and also to run the intelligence. And I think the story of the next couple of decades is gonna be the demand for these goes up and up and up to crazy heights, and we better find out how produce a lot, otherwise someone's going to feel like they're getting screwed. Yeah.
Unknown: Dang, dude, I can't tell if I'm excited or scared, maybe I'm both and maybe it's all the same You
Sam Altman: they do feel related to me always, but I don't think anyone could honestly look at the trajectory humanity is on and not feel both excited and scared. Yeah. And
Unknown: maybe that's always been the way throughout time. And also then this is where we are. What are you gonna do? This is where we are, and so that's what's going on. I saw where you and Joe Rogan spoke about there possibly being one day like an AI president, where what if you had this one, let's just use the term supercomputer, this agent that was created that knew all the information and knew all of the problems and knew the best ways to solve them. Do you think that something like that is becoming more and more possible one day?
Sam Altman: Like, I think the idea to look at an organisation to make really good decisions there's a lot of things you can imagine that an AI CEO of OpenAI could do that I can't. I can't talk to every person at OpenAI every day. I can't talk to every user of ChatGPT every day. I cannot synthesize all that information even if I could. But an AI CEO could do that, and it would have better information, more context, it could massively parallelize this, and I think that would lead to better decisions in many cases. think it will be able to help us answer questions about the nature of the universe that we currently can't, and I feel very confused and very unsatisfied with our current answers, and there is clearly, to me at least, something going on well beyond our current capability to understand and I would love to know what that is. Do
Unknown: I wonder if God has a ChatGPT or whatever. I just wonder if he has the first one or whatever. But yeah, I'm just so curious, like, how would that work? How does OpenAI make money?
Sam Altman: then we also sell an API, so businesses can use and they like pay us every time they make an API call. Okay.
Unknown: councilmen kind of like, do you think there's bad artists
Sam Altman: don't wake up. I think very few people wake up every morning saying, I'm gonna try to make the world a worse place, or I'm gonna actively try to do evil. Clearly, some do, but I think most of these people running the big tech efforts are not in that category. I think people get blinded by ambition. I think people get blinded by competition. I think people Negative for society as a whole. And by the way, I include us in this. We can totally get caught up in be very well meaning but get caught up in some incentive and it can lead to a bad outcome. So that's kind of what I would say. I think people come in with good intentions, they clearly sometimes do bad stuff.
Unknown: There's a lot of talk about like Palantir and Peter Thiel and their company about being like, you know, they got a deal from Trump about to have this surveillance, or not a surveillance state, but to create a database on most of America. Do you feel like we will need something like that in order for the future?
Sam Altman: You know, do you feel like something like that is included in the future? So I don't know about that specifically. I mean, I think Palantir and Peter do a lot of great stuff, but, again, I can't comment on this specifically. I'll say generally, I am worried that the more AI in the world we have, the more surveillance the world is gonna want because the tool is so powerful. rights to privacy. I don't think those are absolute. I'm, like, totally willing to compromise some privacy for collective safety, but history is that the government takes that way too far, and I'm really nervous about that. the US government bombed Iran recently, I remember waking up that morning and seeing that news or whatever time it was, and I was like, oh, that's what actual power looks like? You know, that we're in like a maybe someday we get there, but it was like a really stark reminder of however important we think this is. It's like there are people that have just like this unimaginable
Unknown: gross displays over there sometimes of inhumanity. Absolutely. It's sad. What do you think a guy Palantir
Sam Altman: caricaturized in the media as this, like, evil mastermind. in fact, I think he's been one of the most important forces, at least in my life, for questioning assumptions about the path that society was on. And maybe I was like, oh, I thought this was all going well, but maybe we are in a tech stagnation, maybe we really do have this huge economic challenge that no one's talking about. So I think these people who are just very is super important to a society. Now, on the other hand, more typical person, he would have just said an immediate yes Right. And then said what else he wanted to say. It took me a while with him to understand that his brain just works differently,
Unknown: thinkers have changed things throughout time, sometimes for the better and sometimes for the worse, sometimes for the indifferent, but novel thinkers have, you've always like,
Sam Altman: I don't know, it's always been part of humanity. I'm probably super different and super weird relative to most people, but maybe I have some ideas as part of that that are valuable to society collectively. And if I had this sort of very standard mindset, wouldn't. That's good point.
Unknown: like in those people are in love shit. The people I know are just barely, they're crying in parking lots or whatever. But their spousal issues or whatever. But anyway, what I'm saying do you think that some of the creators now and some of the tech lords almost have some tech built into them, like almost a
Sam Altman: I you know, to take the kind of, like, harshest look at us collectively,
Unknown: right? Like, lot of these guys are just, you know, they're kind
Sam Altman: of like a little bit of a cyborg in some way in the way that they think, right? You know, look, you are this, like, impossibly charming cool guy and I'm, like, kinda a lot more computery than you. Not much, though. We can still,
Unknown: Yeah. I'm just always, I'm like, God, yeah, these people are able to see things differently and quantify things differently. Do you always feel, because some tech guys, they just have a different understanding of possibility, right? A different understanding of feeling and thing. Do you feel human all the time? I do feel human all the time, but I feel like
Sam Altman: I have noticed that I think extremely differently about the future, about exponential change, about compounding technology than almost anybody else that I kind of come across in regular life. he uses Chechen BT, and he's been using it a lot for a couple years now, and he noticed recently that he started giving it personality tests. He'd upload any personality test he could find to ChenchiPT and say, Based on what you know about me, answer this. And he had never told it here's my personality, he had just learned it from the questions he asked over the years. And on everyone he tried, it got exactly the answer and exactly the outcome he would get. Or maybe we are and AI can just learn it really well. AI can represent these very complex things. One of those two. But that was a real moment for me of like, wow, the merge maybe can happen in a very different way than we thought. Yeah.
Unknown: Just finished the acquisition a hardware company, their hardware company. So clearly have some thoughts or interest in how hardware and AI match up for each other in humanity.
Sam Altman: What was that about? There have been two revolutions in computers in history. There was the keyboard, mouse, and screen, that thing that was invented down the street in, I think, the seventies, where, you know, the people at Xerox PARC figured out what has become the modern computer interface, and then in the early to mid the early two thousands, I guess, Apple figured out this idea of touch on a device. And really, those have been the two big ones. I think now there can be a third. I think AI is so changes the game that you can design a new kind of computer based off of a really smart AI, where you can give a complex instruction to a system, it can go do it, you'll trust that it gets it right, you'll trust it to act on your behalf. It could maybe be aware of everything going on in this room and it could not just be on or off but lightly get our attention if it wants us to know something or maybe more aggressively get our attention. It could really be like following what we're talking about here and remind us both of things later. Current hardware just can't do that. The current kind of computers we have, I don't think are a fair they don't honor what the technology is not really capable of. So I want to make a totally new kind of computer that isn't meant for this world of AI helping you all the time. I'm super excited about it. You are? Yeah. but the idea that an AI can not just answer questions for you, but it can go actually do stuff on your behalf as your agent. It can go do research for you, it can go book something for you, can go buy something for you, it can go, like, you know, change some things in the world for you and think more and use tools. Like, I think most people think of ChatGPT as this app that you can ask anything, but it'll become this thing that can do anything And that'll change how you use computers, it'll change how you do things in your life. Yeah.
Unknown: I was watching the guy do it and it was just kind of fascinating. Was showing like one time he'd went to a website and bought something that he needed, and then now moving forward he could just be like, hey, go to this and make sure to get me these, or go to go here and see go to the restaurants I like and see if there's any table available for 7PM tomorrow. And it was able to book it and do everything. It was like having a secretary right there. Totally.
Sam Altman: When I first started using it, I was like was one of those moments where I could tell that, oh man, doing this the old fashioned way
Unknown: there's this hypothetical that he was kind of poaching guys around town. Did that feel like a mafioso move in the community? What was that like out
Sam Altman: And I just decided that I was gonna learn to love the hard parts. And it kind of needed to work because so many things go wrong in any given day. But I was like thinking about, you know, someday I'll be retired on my ranch, I'll be sitting there watching the plants grow, and I'll be missing the excitement and the drama and the anger and the tension and the whatever. I was just like, Someday you'll miss these moments, you may as well find a way to find the happiness and kind of great gratitude for them in the moment. Yeah.
Unknown: A lot of these guys have bunkers. Zucky has a bunkie, I know that, somewhere out in Hawaii. People have bunkers. Do you have a bunker? I have, like, underground space, or utilities. And then bunker built for protection, often military or emergency related, we ever have instead of so you start to see, say if AI comes over and there's this whole new kind of like, there's been a lot of crackdown because part of me believes that they're having to get everybody documented or online basically recognition everywhere, like I have this idea of that. So yes, this stuff had to happen because in a year or a year and a half, you wouldn't even be able to be outdoors anywhere without a drone or something noticing you or some camera noticing that you're not supposed to be there or you're not there with documentation, right? Whatever people's thoughts are on that. So part of me starts to see like, oh, okay, that's going on. Do you think we could ever then, down the line, have new countries delineated by almost like a new AI landscape?
Sam Altman: I know that what you just said is gonna happen. I know that we're gonna have cameras all over the place and it's gonna make the cities way safer because if you commit a crime they'll have a facial recognition hit on you right away. But man, do I find that dystopic. You do? Of course. Is it a good trade if it means people stop getting murdered in the streets? Yeah, sure, we agree to give up some privacy for that, but it sits so uncomfortably with me. In London or whatever, see those cameras on every street corner but you're just like, oh, it feels like privacy is important.
Unknown: But could there one day you think if we had that then we could have whole new countries kind of that were
Sam Altman: I think there's all kinds of weird ways that can happen, We've got to do something about that. You know, we have this team that figures out what the model's personality should be like and how it should behave and a lot of users like Em dashes, so we added more EmDashes, and now I think we have too many EmDashes.
Unknown: But I don't know why. Maybe that's just my own I think it's attached to my own perceptions of what I think about AI and stuff or the possibilities of technology, like that kind of stuff, like that curmudgeony energy. I think I was probably attaching it to you. And now I feel like I'm more whimsical about it, kind of like, or not whimsical, but like, let's see what can happen. Right?
Sam Altman: do the best work I can, have the most fun, have the most impact and the most interesting stuff?
Unknown: But maybe, yeah, maybe just a down payment somewhere down there. If things get weird, we'll go knock on their door.