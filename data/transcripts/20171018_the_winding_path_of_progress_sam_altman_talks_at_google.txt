Unknown: chat style talk, so we'll take about forty minutes to talk through some questions. And then in the last twenty minutes, we'll open up to the audience to submit questions, sam. And I'd like to thank everyone who has helped out to make this talk possible, including our facilities team and everyone on the PM Speaker Series organizing team. Sam is the president of Y Combinator, which is widely regarded as one of the top startup incubators in Silicon Valley. He went to Stanford and studied computer science and was the founder and CEO of a mobile location based startup called Looped, which was funded by YC as part of its first class of startups in 2005 and acquired by financial services company, Green Dot in 2012. In 2014, he was named president of Y Combinator and since then he's worked on a wide range of initiatives from YC Research, which is a non profit branch of Y Combinator that focuses on doing pure research around moonshot ideas like universal basic income. And he's also worked on OpenAI, which is a non profit AI research company looking into finding ways to create safe, friendly artificial intelligence that can actually And it's great to have you here. Thanks for having me. So just as I mentioned, you're involved in a wide range of things from YC to OpenAI and most recently, you released the United Slate. So I wanted to ask you how you think about prioritizing the projects that you work on.
Sam Altman: I think if you can get to spending like 1% of your time perfectly, that's really good. And so I think this idea of figuring out what to focus on and what not to focus on is both really hard and still significantly under invested in. one is impact maximization slash regret minimization. And I try to think about where I can have the biggest net impact on the world net positive impact on the world. And then also just regret minimization. You get to live once. It's really important that you do what you want to do and that you spend time with the people you'd like to work with and work on the things that you find personally fulfilling. And so if I think I'm going to really regret doing something or regret not doing something, even if I think it's not the best use of my time for a pure sort of net impact on the world, I'm still willing to be like to take that really seriously. And I think that makes me do better at the things I do that do help the world. So the broad things that I've learned that I like to do, one is teach people. Another is create economic growth. I really do believe that And so I think in a democracy, you really want everyone's lives to get better every year. We're basically insensitive to the absolute quality of our lives and extremely sensitive to relative differences year over year to our neighbors. And it's really important that everyone's life is getting better constantly. And I think economic growth is important to do that. I think that AI is And I try to think about things on those two strategies. The other framework besides the sort of impact maximization, regret minimization that I found really useful is spend a little bit of effort trying a lot of things and then relentlessly prune down and focus quickly on the ones that you like and the ones that seem to be working. And this is the hey, guys. This is the thing that I've tried to apply to my life more generally is this idea that I can try a lot of things with a little bit of effort. It's very hard to predict exactly what's going to work and what hasn't. And the last thing I'll say about prioritization is the other hack I have learned is if you can get one really great partner with you on every project,
Unknown: And focusing more specifically on productivity, like what are some life hacks that maybe you apply to make your everyday more productive?
Sam Altman: I think there's a lot of crap written about productivity secrets on the internet. And people sort of get into this thing where they spend more time trying to be productive about their productivity system than actually getting things done. I will say, I think, that well, I'll say two, I think, pieces of advice that aren't obvious. One is I think far more important than any particular system is just figuring out the right things to work on. And so all of the time that people spend with this new productivity app or that or whatever would be better spent really trying to think diligently about, I have the same number of hours as anybody else. What am I going to spend them on? And getting that right is more important than exactly being perfectly productive with those hours. A big part of that is not doing things that waste time. I think if you can just focus on the things that are important and not do the things that waste time, you can be fairly sloppy with productivity otherwise. And you'll still get far more done than most people. It's really hard to do, though. The other thing that I think people don't think about enough is figuring out your own personal rhythms of productivity. And there's huge variance I've noticed between people that figure this out and don't. So for me personally, it turns out that I am most productive if I go to sleep late, wake up late, and then keep the first three or four hours of the day and don't schedule any meetings, work from home, get through my list of stuff then, and then pack all my meetings when I'm kind of less productive at just grinding stuff out or thinking creatively in the afternoon. And it took me some number of years to figure that out because it didn't fit well with the work schedule I was naturally in. But then I was like, all right. If this is the thing that makes me most productive, then I'm going to make my whole schedule work to support that. And that was a really important change for me. So I think figuring out your own personal optimal times to work on what kind of different things, People don't really talk about that much. And at least for me, it had a huge impact. Shifting gears a little bit, but still trying to get your perspective
Unknown: on different things is bias in the workplace and both conscious and unconscious bias. And I wanted to get your perspective on what are some of the strategies that you implement personally, whether in the way you interact with people that you encounter or in how you approach the decision making process in using strategies to minimize your own bias?
Sam Altman: no matter what you believe about biology, no one that I respect does not believe that women and racial minorities and a number of other groups face an absolutely unfair playing field their entire lives. I think people start getting told directly and indirectly from a very young age this is the kind of thing you should do or can do or whatever. And that has an effect, a compelling effect, on anyone. And I think trying to counter that again, I think there are things people can reasonable, well meaning people can disagree on. And I think, unfortunately, we spend all of our time talking about the disagreements. We And don't focus enough on the agreements. And I think almost all smart, reasonable people will agree that the society we grow up in has a hugely unfair playing field. And I think because of that, it is not enough to talk about unconscious bias. I think that is a real problem, to be clear. I think we are all a product of the society we grow up in. And we all have biases that aren't our fault but still a responsibility to counteract. But one thing I don't like about the discussion in Silicon Valley about unconscious bias and how that's the problem that we need to fix is I think it is not nearly sufficient. And it ignores it's a good thing to fix. But it ignores the fact that decades or centuries of society have built up a very uneven playing field. And that is why we do need programs to try to proactively counter that. So I think it's really important we not lose sight of that and that unconscious bias training alone, although currently very fashionable, will not fix that. That said, I do believe unconscious bias is a problem. We try to counteract it, B, I think one of the things that we have done that unfortunately other investors have not done as much is just have a very diverse six female GPs on our team. And that's probably a large part of the And I think I hate to play the kind of like who's the most discriminated stack game. But I think black And I think by having a more diverse team, it helps us have broader networks and also think about our own unconscious bias all the time. And
Unknown: the issue of politics or maybe even bringing these issues up in the workplace is sometimes seen as a taboo. And yet you've been pretty vocal about your views on current political events and also other issues that are coming up in Silicon Valley. So I wanted to ask you how you walk that fine line between expressing your opinions, but also minimizing any repercussions that that could have on the day to day business of YC? Well, now it's not even controversial.
Sam Altman: Now, all the tech CEOs are talking about politics. When I started doing it a couple of years ago, kind of at the beginning of the rise of Trump, it was controversial. Two things were going on. One is I think no one took him seriously. Most people are going, this is a ridiculous thing. It's going to go away. Two is that I think in normal times, it does make sense for business leaders of large organizations to remain apolitical. I think it actually does make that makes a lot of sense. It's a huge distraction. It's hugely time consuming. And it has all of these weird negative effects. Like However, however, these are not normal times. And I think when the future of the republic is at risk, the duty to the country and our values transcends the duty to your particular company and your stock price.
Unknown: are some things that you wish people knew about you that they don't know about you?
Sam Altman: At this point, I would just like to have my own little quiet private life back. I don't feel like
Unknown: are there any qualities in founders that you think are overrated or underrated?
Sam Altman: the level and the frequency of bad stuff that happens to you. And most people that are good in really other ways eventually just get killed. The company gets killed by stuff going wrong. And so much about being a successful entrepreneur is just not giving up. When we have funded people who have a great idea, a great product and still failed, it has usually been that they are insufficiently determined. So I think this is the most important non obvious skill of a founder. Of course, you need a good product and a good market and to be smart. But that's really obvious. The degree to which being like a three or four standard deviation outlier on determination is a required skill of a CEO is not something that was obvious to me when I started. That's also bad because it's really hard to select. It's really hard to identify that. As we have said more publicly how important that is, people applying to YC have gotten better and better at telling us stories from their past life about how they overcame these impossible odds to get through something. And unlike intelligence, which is very difficult to fake in a one hour meeting, you can definitely fake determination in a one hour meeting. So that's one thing that really matters. Another thing that really matters that is non obvious is independent thought. And this, I think, is an even more unusual skill than determination. I think both of these you can make a conscious effort and build up. But I think independent thought is one of the hardest are all speaking of social pressures from birth, we are all pushed to think like other people. And if you think in your own lives about the number of people you spend time with that you would say are true independent thinkers that consistently have new ideas you haven't heard from other people and think about the world in different ways, it's probably a very short list. And they're also not kind of the really big trends of the future. You want startup ideas. If you picture a Venn diagram and here you have is a good idea and here you have sounds like a bad idea, you want that tiny little overlap. And those are the kind of ideas that are the hardest to identify and the ones that, even if you do manage to notice them, most people will talk you out of. So I'd say those are two non obvious skills that we look for. And
Unknown: what's one challenge that YC companies face repeatedly that you've noticed?
Sam Altman: Hiring engineers I think the good thing about that I always try to find the good in any bad situation. And the good thing about this is it means that if a startup does not all the really good startups have really important missions eventually. They figure it out. They may not have it on day one, but they eventually get to this missionary mindset. And it used to be that even if you didn't have that, you could just sort of get a bunch of mercenaries to come work for you. And now you can't because you can't up at Google. And so one positive side effect of this thing has been that the importance now of a startup having a really clear and really important mission on day three has gone up a lot. And I think that's leading to better startups because otherwise you just can't recruit. Another common problem that startups have and this doesn't sound like a great insight but most start ups still don't ever build a product that people want. And it doesn't seem to matter how much we talk about this. It doesn't seem to matter how much anyone talks about this. People still keep trying to do anything but this. And if there's one thing that a startup has to get right, it's build a product that people really want. Not a little. If they wanted a little bit, you won't generate enough momentum. You've got to build something that some people really love. And after failing because of insufficiently determined founders, this is the number two reason that startups that seem really good otherwise fail.
Unknown: Moving on to talking about different technologies, what would you say is the biggest challenge that we're facing in terms of making progress on artificial intelligence right now?
Sam Altman: player Dota players in the world And it was very wild to watch that happen because it was almost purely self training. fact, the final bot that we had that beat all the humans handily, But again, in the same spirit of always trying to figure out the good not the bad, I think that AI has the potential to eliminate nearly all human suffering in the next couple of decades. I think we can have a world of abundance. We can eliminate poverty over time. We can probably cure a whole lot of diseases. People like disaster porn. People are more interested in talking about the end of the world than they are about life getting 10% better every year and having that compound, which gets a lot better. So making all these problems 10% better. And probably no one reads it. Certainly no one shares it. And so I think it's going to go up and down. Like I bought I think the only super compelling proven use case we have seen so far is store value. And as a replacement for gold, I think we are seeing real adoption there and real collective belief that actually makes it have some value. bitcoin should dominate. Biggest network first, biggest brand, most collective belief, whatever. And so I have been surprised by the continual strength in all of the altcoins. potential other truly valuable applications of the blockchain. Filecoin is a YC thing, so I know that one pretty well. And I can see that being big. But I think most of what's going on feels like a complete outside of bitcoin feels like a complete speculative bubble. And I feel bad that a lot of people are going to get burned. is to buy bitcoin and then not think about it for another five years. Is Sure. A lot. AI, as we mentioned, I think people are asleep at the wheel in a really big way on. I think, is within some single digit number of years of working. it's been so bad for so long, people are just kind of burned out and not really taking a new look at new materials and stronger magnets and better computer models that's going to enable this to work. Synthetic biology, again, it's like people talked about it a lot a couple of years ago. It didn't quite work as fast as people were hoping. So we have this hype cycle and then it really falls off. And now we're in the part where I think the interesting work is happening and people aren't paying enough attention. Technology has clearly been quite bad at solving. I won't say it can't. at least in the developed world, where the world keeps getting better and we keep getting unhappier. And there's like a decent amount of data on this. And I think technology is not entirely to blame. But it's certainly not blameless. thirty minutes left, I couldn't even start the conversation. But I think the number of things that technology has done to make us more isolated, feeling relatively worse little bit older, said she never used to be unhappy because she had no idea what she was missing. And now that she has to watch fly around in private jets on Instagram all day, she's jealous. I don't have a solution to that, but I understand why that's a problem. So I think figuring out how to make us happier and nicer to each other in particular, I think one thing that technology does that's really bad is we have some probably longstanding evolutionary like these pack animals. And we have to live with each other and help each other survive. But somehow on Twitter that goes away. And I think I'll saying the most aggressive, snarky things. That's how you get likes and retweets and sort of value out of the platform. But a lot of technology does this. We don't have whatever kind of like the human be nice to each other in person instinct is. And we have these platforms that reward being bad, reward being a jerk.
Unknown: In an interview with Vanity Fair in twenty fifteen, two: you mentioned that you were optimistic about the future. and the situation that we find ourselves in. So would you say that you're still optimistic about Of the future? Course.
Sam Altman: I think if you look back at the last few hundred and then few thousand years, if you zoom out enough that two hundred years ago was very low, the percentage. And as horrible as things are, the fact that we get to stand up How we deal with a world where the natural forces are for wealth to concentrate into the hands of a smaller and smaller number of people. As I mentioned earlier, I think people are more sensitive to relative quality of life than absolute quality of life. And I think technology is naturally a force. It's a giant lever that tends to create way more wealth And Okay, like there is some truth to that. I do think it is cool about the world that the richest person and someone living in absolute poverty carry around the same phone. That is something that would not there was no analogy to that other than maybe if you got a really bad disease. There was no equality like that that point, which is always what Silicon Valley falls back to, I think is maybe not the most tone deaf possible response, And they want to feel like they're not just kind of like given this baseline while they toil in the provinces and Silicon Valley just gets all the money. And I think people who don't see that are just not thinking clearly. And so I think one of the greatest threats, something else I don't think technology can fix on its own, is how we get to a more just world. I really, really fundamentally believe that economic justice is the most important thing you can do for social justice. And if you have all of the resources going to a small set of people, even if everybody else having their absolute quality of life raised very quickly, that's not enough.
Unknown: You recently announced a united slate which puts forth some policy proposals as well as an invitation for candidates.
Sam Altman: five, six candidates in the 2018 cycle on that election on that platform and have two of them win their elections, maybe those issues, although I believe they're important, are not yet ready to convince the public at large. But I think it'll be a good start. And I think over time it would be really good if people on the progressive side built up a kind of long term organization focusing on winning elections and shifting public perception at all levels. The right has done a fabulous job at this. Congratulations to any of you who are on that side. But I would like the left to do a better job at that. I don't think we're putting forward our best game there.
Unknown: In your invitation, you also mentioned that you'd be willing to work with Democrats, independents, and Republicans. Is there any issue in particular that you see anyone, regardless of political ideology, coming together and agreeing on more so than other issues? I
Sam Altman: think there are a lot of issues. Again, I think people agree on way more than they disagree on. So I think as we went around the state and talked to Californians, Republicans, Democrats, San Francisco, LA, Fresno, Shasta County, wherever you go, the price of housing is like the biggest issue for most sort of regular people that are not Google employees. Maybe even for Google employees. It's really, really bad. I mean, is like if you could fix, I think, one thing that would have hugely positive secondary effects, it's like bring the cost of housing down by a factor of 10. It would be transformative for society. not kind of the libertarian anarchist all government regulations are bad. But I do think the sort of no more building, no building taller has been disastrous for the state. And I think it is the worst possible allocation of resources to have people tie up every free penny they can find into the place they live. Like, think about anything else we could spend that on. Think about what it would be like if people could live close to where they work rather than commute an hour and a half to get here each day. And that is something that Democrats, Republicans, independents, almost everybody agrees on. Or at least there are people in all those camps that do. So I think, again, easy to talk about the divisions. It's really good that when you go talk to regular people, is a right to participate in the electoral process. And I think there a duty to do that. And I think doing my thing, building products, making money, and whatever. And I'm going to out someone else's let someone else take care of the rest. One of the kind of disappointing things that I have learned is I've gotten to spend more and more time with increasingly influential people and kind of how the world works is that there is no plan. And there is no group figuring out everything. And it's kind of up to all of us. Everyone hopes. The reason conspiracy theories are so appealing is that everybody That there's all this stuff happening. But someone's got a centralized plan. And it's all going to work out. And I think one of the sad realizations of No one has this master plan. And if we don't participate, that thing can just go off the rails.
Unknown: What do you think are some of the most effective ways for employees at a large tech company like Google to get involved in government and politics?
Sam Altman: Everyone wants an answer other than this one because it would be more convenient. But I think one of the answers is to just run for office. We have this process. And everyone wants some way to hack around the edges of that But I think just taking the problem head on is not enough people try that.
Unknown: other week. And then there's also been rumors about you running for governor. And we've seen tech people run for office in the past. Meg Whitman ran for governor of California in 2010. But she lost by a significant margin to Jerry Brown. So my question is, do you think that it's actually feasible for someone in tech to run for office and win? Or is there too much of this perception of the tech industry as being elitist such that people won't connect with voters?
Sam Altman: in it. And I think it is easy to get But what I am confident about is that people from the technology industry could start winning local school board and city council and I don't have an answer like ready to go in my head. Okay. all the social apps from my phone. And I can still check them on my computer when I want. But I don't have that constant urge to push button for dopamine, hit here. And that's been really good. You know, I think after talking to a bunch of these people about the things that make people happy, there's like the obvious stuff which is like spend time with loved ones that everyone knows even if they don't do. But there's a bunch of things that are like not or less obvious to me that seem to have huge measured effects, like taking time to think about the things that went well as opposed to things you're upset about or like going for a walk outside every day no matter what. And I think as we get to abundance and unlimited resources, this is going to be a more important topic. reading. There's a lot of literature on the subject. No one seems to care about enough to spend time. But I would say start reading it. And hopefully I'll finish my blog post on it soon. we already have a growth fund. It's called YC Continuity. We raised the first one in 2015. It's about halfway invested. And it basically follows on in capital in YC companies. One of the things that I wanted to do after I joined YC was start to fund hard tech companies one of the good things that I realized is that nobody else was funding those companies. And so we could have our pick. One of the bad things that I realized is nobody else was funding those companies. so that was actually the genesis for our growth fund. That there was this class of companies that I think are really important and really valuable. And they weren't getting funded. Since then we've expanded it and we fund lots of other companies. I will certainly say that there is no shortage of growth capital for software companies in Silicon Valley. Like, you know, it may have gotten harder to raise a C or an A round. It probably has somewhat. But if you have things working, like when you want to go raise a B or C round and you have this beautiful exponential growth, you will not be able to keep up with the number of term sheets you're getting. That is the stage that I think just has a huge amount of capital allocated to it. As companies are staying private longer, as public market investors have a harder and harder time finding alpha, they are more and more willing to do stuff like this. So that part of the market
Unknown: has been supporting GiveDirectly's research on UBI in Africa. And you're a proponent here in The US. So what are your thoughts on how, when, and where the universal basic income approach might be most effective? Yeah.
Sam Altman: I don't think universal basic income is a solution to all problems. I think, in fact, of the bigger problem that we were talking about earlier of what makes people happy and fulfilled and feel needed and valued and have meaning in their lives, it is not sufficient to solve that problem. And I don't think it will replace the entire other social safety net. Like the people who are like, eliminate everything else, no health care, no schools, no minimum wage, basic income. I don't believe in that either. But I do think that if we do all of our jobs, if we Silicon Valley do all of our jobs, we will create more wealth than the world has ever seen before and less jobs. And in that world, I think there is a moral obligation to eliminate poverty. I think poverty is an obviously very bad thing. But it is worse even than people realize. If you look at the studies on the long term psychological damage that living in constant poverty does to people and how it means that you never get a chance to really invest in your own future because you're always just trying to survive, I there's just a huge amount of wasted potential. And so there are a lot of arguments about UBI. This was another thing. Like when we started this a couple years ago, I did not predict at all that this was going to ignite into this big national debate. It was like, we're just trying to hire a researcher. Maybe this is a good idea. So I don't think I quite understand why it has become such a national issue so quickly. But I do think that longer term, Think the thing that people well, the piece of advice that people later say they wish they had listened to is that it is very easy to get sucked into a path in life. AI researcher someday. But first, I'm going to go do this other job to make money and gain experience and whatever. And it's so easy to get sucked into a path where you spend your entire life doing something that is not really what you want to do. That's probably the piece of advice that I have given people that they have most often come to me five I don't honestly know how far along China is with AI. And I don't think anybody else honestly really does either. I think it would be bad to get into an arms race with China over AI. And I think there is a real opportunity, although it might we may not have the leaders in place to do it right now to make this a joint kind of like worldwide project rather than another space race or nuclear arms race. capital is allocated really badly. And unfortunately, there are huge efforts. Like if you have this really valuable thing, which is you get access to invest in great startups and most of the world doesn't, then there will obviously be a super return there. And you're going to work really hard to protect that. think expanding access to invest in startups, which is happening but slowly, is a really good thing to do. And I think equity crowdfunding, we're still in the early days of. But it's an important trend. And I think that will change the capital allocation. I think seeing startups in all these different ways go to nontraditional funders. And that's been really good. We first saw that with consumer hardware. We're now seeing that in a lot of other places. I think the other thing that's happening finally is there's just and there's bad to this, too. But there's just a huge amount more capital coming in to fund early stage private companies, mid stage private companies. And I expect that in a world where interest rates stay even close to as low as they are, general model is that the world is this very complex financial system. Capital sloshes around looking for the best return. I wouldn't suggest that they do an ICO. But I do think they can raise $100,000,000 And I don't think they could have three years ago. And I think that's a really positive trend for the world, that this stuff is now happens a lot with super talented people from large tech companies. So since I'm here, I'll mention that one, Which is you are a really great person, really talented, really smart, there's this myth about startups that the idea doesn't matter at all. And I think that's just there's existential proof that that's not true. And I think there is this particular failure mode of people from the big tech companies, which is like, hey, I'm really talented. And I'm like, yes, you are. So I'm going to start a company. And I'll figure out what to do later. And I think that isn't usually what produces the great companies. And so we have learned that it's much, much better if you're otherwise a qualified candidate to have a good idea. And I think that would be the common failure case for people coming out of Google. I do plan to get continually more involved with politics, but I'd like to support others, not run for office myself, at least not anytime soon. I am a big believer in do the things that you think about in the shower in the morning when you can think about anything you want and your kind of mind is just off. And the things I keep coming back to are like, how can I make YC like 100 times bigger? How can I make sure that the arrival of AI goes well? And in the short term, how can I help our political system from going off the rails So I kind of plan to keep working on those things for hopefully I don't agree with that. I think I used to view my job as a capital allocator. And now I view my job as a talent allocator. So most of my day is spent meeting with really smart people and trying to convince them to work on important problems. And I think in 2007 what everyone said is the best minds of our generation used to build spaceships. And now they're moving numbers around on Wall Street. And in 2017 what people say is the best minds of our generation used to build spaceships. Now they get me to click on ads. And there's always some truth to And there's always someone to pick on there. But I think OpenAI has some of the smartest minds in our world of our generation working on having AI go well. I think Healian, which is that fusion company I mentioned, some of the smartest minds of our generation working on nuclear fusion. cancers. I think you can always say there's all these people working on bad stuff or stuff that doesn't matter. But I think Google is still a really great thing for the world. This is why we're here. Yeah. And I think it does matter. And I think it's always easy to pick on people and say, you're not working on a cure for cancer. You're wasting your time. But you're making this thing better that people use every day. And their lives would be a lot worse if it went away. And you're making it better every day. And I think it's really easy to pick on people and say, you know, that person's not spending her time right. And I think it always says more about the person that says that than the person they're pointing to. And if you're doing something useful for the world, if you're doing something you enjoy, if you're sort of like even if you're having a small impact but on a product that a lot of people really use and love, I invite you to come sit in my office for a day and listen to the people coming through and what they're working on. I really don't think that, no. Cool. Thank you. Yeah. Great question. I basically had nearly all of the possible privileges. I had wonderful, loving parents. I grew up in a safe house. I'm a white guy. We had enough money that I was able to pursue the things that I was interested in and go to a great college. And it's never lost on me how if I had been born different skin color, different gender, I wouldn't be where I am now. I view that as an obligation to try to make the world more just going forward. I think anyone who is really successful and doesn't I think anyone should try to do the best they can with whatever hand they're dealt. But if you're dealt four aces and you win, then I think you have an extra obligation to try to sort of make the world a little better. So I try to be really thankful of what everyone's done that has allowed me to do this. I also try to figure out how to pay that forward. think anyone who is really successful or almost anyone who is really successful has In terms of biases in the product, I think this is one of the reasons that diverse teams are most important. The moral question aside, the consumer products, the teams, the companies that I think have done the best job addressing this head on have had a very diverse set of voices around the table. And I think that is always the strategy I recommend because that's the only one I've seen consistently at work. Cool. Thank you. Sure. We're on time now. But if you can do these last three questions quickly, we can get through them. Sure. I think data is important, but there will be a lot of it available. And just my own experience with open AI, to really be at the forefront here, you just need massive amounts of compute. But one that stuck out of memory was a company came to us and said, organized religion had this really important the religion itself, which was this tight knit community. And how do you build that in a world where most people or declining number of people believe in religion and go to church? And so I think there are people thinking about things like that, which are sort of these non obvious attacks on the problem that are interesting. But none that I could yet point to as here's this thing that's really worked well. really excited about how that went. We had never done anything like that before. We often try new things. Usually they don't work. Sometimes they do. That's when we would do again. We would do something more like that. Think there are these really important organizations in the world that can use our help to build better technology teams. One of our software engineers, Kadrin, went there for I think, she went for like eight weeks, almost the whole program. Sat in their offices, helped them. We got a call from them later about how well it went and been able to help them put a expand and supplement their team. And I think that's something we'd like to try again.
Unknown: Musk recently called up for preemptive AI regulation at the National Governors Association.
Sam Altman: insight. I think the government should understand where the edge of capabilities are and how it's evolving. Because I think no one, certainly not the government, knows what the regulation for AI should look like today. But I'd be in favor of starting that education process.