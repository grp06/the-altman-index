Sam Altman: And Singapore is a special stop for us. It's been very cool to see what Singaporean government's been doing with AI, what people here are doing. And it this is really kinda why why we we started the company. We we started technology humans have yet developed. And now, I think we believe it can be developed. We'll see how far it can go. But I think we are at the beginning of something that is going to be quite a profound shift to the world. And so we try to create an effort that can help bring that benefit, share it very widely, and figure out how to mitigate the risks that could come with it. When we started, we worked on systems that played games, and we had this, like, robotic hand that could do a Rubik's cube and bunch of other projects too. And as we sort of stumbled through the wilderness, at some point, we got to this idea of language models. And when we didn't even quite know what we had at the time, but it turns out we've been able to push that very, very far, and we now think that'll be an element of the path that that builds towards AGI. deploy it iteratively to the world to figure out how to make it safe and aligned, share these incredible benefits, And I really think it will lead to a transformation of the whole economy and all of society in a very positive way. Thanks. You know, we we kind of hear the same things again and again from the same people. And I really wanted to just go listen to people with different perspectives. was wrong. Think around the whole world, people not only really care but are doing work at the same level of sophistication as San Francisco. And the policy conversations and thinking about what happens as we build towards AGI and beyond are unbelievably sophisticated and thoughtful. And that has been a it's really like you know, that's that's been a big update for us. The things that people care about are different than what people care about in SF, you'd expect, and that's also been interesting to see. But kind of the the shared global desire to get to get AI right, meaning both that we all get to enjoy, like, the tremendous benefits of what this can deliver and also mitigate the the substantial, like, global risks, that's been a great takeaway. In fact, we've met with, like, many governments around the world. To us, every country, people are interested in coming together and figuring out how we address this very difficult challenge of global governance for these powerful systems. So you on on that note, so you met with the prime minister this morning. I did. You also met with the deputy prime minister. Anything you can share with us? Like, the technical depth that the prime minister immediately went to, like, really, like, impressive questions. The whole team was looking around being like, we gotta think about that one for a second. That's a great question. But talking about the magnitude of what this is going to do to the world, how as these systems get, you know, as smart and smarter than humans, we're going to think about doing that, the challenges of coordinating global policy, but also the tremendous benefits, making sure that Singapore benefits from what can happen here economically, socially, education, health care, all of these different areas, and then kind of the contours of the inputs that these systems need to be very successful. Right. launching the revolution. It's now all of humanity is gonna take it forward, so we'll try to influence it, but it won't be totally up to us as it shouldn't be, of course. increase human individual human will, and I think we're seeing that now. I was never excited about the direction of AI where it was like, there's gonna be this, like, thing, and it's sort of creature like and has all like, it just makes all the decisions, and we hope for the best. And I kind of I sort of, at one point, thought or worried that that was gonna happen. It now looks much more like we can build these tools that just enhance our ability to create, to do things, to generate new knowledge. We just have sort of, like, a lot more AI talent join society and contribute to the sort of infrastructure that we all share that lets us do things. And that is where I hope things go. So it's like the world is on this trajectory that it was gonna be on. It happens faster. Everything gets better. The kinds of things we do will evolve over time, but we're still like the unfolding human story is like the main event. Computer programmers can now maybe be two or three times more efficient than they could before. At some point, they'll be able to be 20 or 30 times more efficient, and then by the time 200 or 300 times more efficient, then it's like a qualitatively different thing. And we'll see this for other industries too. It won't be sort of like spread, you know, the same everywhere. But when these things that have become hard become easier and people can do more, it's not that, like, the expectations go up and also the ability goes up. And it's not like we say, oh, you know, now we only need one three hundredth as many coders. We're seeing that there was just a huge surplus demand in the world for good code to be written. Same thing for education, same thing for science, same thing for writing. People will just do better stuff. This has been the long trajectory of giving humans better tools as the technological revolution has gone on. Think about what we all do today, and think about how much we owe to all of the people that came before us and the technology and the tools they created that built up the tech tree of humanity and where we'd be without that. And think about what happens if that the rate of that just really increases. We'll do better stuff. We'll we'll create more. We will do entirely new things that are are difficult to imagine. You know, when you had to program computers with punch cards, there was like a limit to the sophistication of a program you could do given the time it took and what you could keep in your head. Then we got to, like, lower level languages and higher level languages, and people started doing amazing stuff. We got to sophisticated enough languages and also powerful enough computers that we could make So one version of this, maybe to think about it, is if every person is running a company of a thousand really competent individuals, the equivalent of that, democratize the values that we put into these systems, what we align it to, this is, like, hugely important and getting more important. We've launched some recent grants. We have some of our own ideas, but we really wanna learn, like, you know, how do we like, we really wanna figure out how to learn the collective preferences of humanity, figure out how we wanna agree on where we draw the very broad limits of these systems, where we set the defaults, how much power we give people to configure inside of that, and then also questions like, how are we going to make governance decisions over what these systems can be used for and not used for, how are we going to share access to them democratically. Yeah. I just wanna make sure that everybody's values and everybody's preferences are reflected in these systems. Everybody's culture, history, language, hopes for the future, ability to do things. People will choose to use these in different ways, and there are some places where we have to come to global consensus, some very limited ways. Different countries will have different sort of rules and standards. Different people will certainly too, But it should kinda all be in there. We should all sort of, like, imbue our beliefs We'll certainly have things like images and videos in there by GPT 10. The parameter count, you know, that's like a little bit of an open research question. I sort of think it's the wrong thing to focus on. Like, what we care about is that each time we cut a GPT number, it's dramatically better. It's not, you know, we're not sort of like focused on, by the time of GPT 10, like, that's going to be a wild thing. comfortable with faster change, better at learning new things quickly. And it's not that hard. It's just not something that our education system usually prioritizes, but it's totally doable. I don't know if it's the most interesting application we're building, but I think it is like a necessary one. I am a huge believer that with each new technology, The old the graphical user interface, much better. Most people could do that. Touch Big Step forward again. But natural language, even easier. Kinda everybody knows how to do that. And there's immense power contained in that model. And so it can probably go further. Like, there's probably more now that computers can, like, understand, for lack of a better word, there's probably much more that you can do. But part of why ChatGPT was such a step forward, and we'd had them pretty good models for a long time, but it was the interface. And so startups that are doing more to explore in this space, like it's gonna be a big deal. And the opportunity for startups, think, is every time there's a shift in computing ChatGPT and these kind of models provide, there's, like, an opportunity to build a lot of new stuff. The best startups like tend to cluster the harms are manageable. We want to minimize them as much as possible, but we realize that no matter how much testing and red teaming and auditing and external engagement and safety sort of eval ing we do, people will use things in ways that we didn't think about, and that is the case with any new technology. So it's it's not that the upside justifies the downside even if, you know, even if, like, we think there are, like, orders of magnitude more good than bad, which we do, it doesn't excuse us from having to mitigate the bad. It's that you can't learn everything in a lab. So you make you spend a ton of time making the safest, most aligned, most beneficial model you can. With g p t four, it took us eight months after we finished training before we released it to get that done. And then you put it out and you find that some of the things that you were worried about actually aren't a problem and they're stopping good use cases. And people are misusing it in a way that maybe you didn't predict or maybe you couldn't have predicted because it was like society and the technology co evolved together. And you run a very tight feedback loop. But we we really believe that iterative deployment is the only way to do this because if you don't deploy along the way and you just go build an AGI in secret in a lab and then you drop it on the world all at once, Society doesn't get that time to co evolve, doesn't get the opportunity to say, you know, actually, we have a different vision for where this should go, and where's our voice? Like, the fact that the world is having this conversation now, well before we get to AGI, not confident in this answer. But certainly, for me, the thing that has always worked is being like having very broad knowledge that's very shallow. And then in a couple of areas that I'm particularly interested in, having deep knowledge and then figuring out what I can do at the intersection of that. to Rachel's earlier point, it's probably going to be about the meta skill of learning new things fast. And people always want to predict. don't know. But given how fast things are going, this ability to react quickly seems super important. really keeping a tight loop on what's happening? That seems scary. towards it sort of seeping everywhere. I would say the other is the degree to which people are embracing the upsides of this technology. There you know, with every like, with world leaders, there's always, how are we gonna mitigate the the major risks here? And with people, there's some of that too. But the incredible optimism and creativity around the world, like, I'm going home very optimistic. It's definitely requires some additional work to use these systems in context where you need a lot of rigor and reliability. We're we're still very early in the life cycle here, and this is not their strong point. They're great at being creative. They're not great at being, like, super robust in every instance. But a lot of people are figuring out how to get them to act that way, although it requires, like, hacks on top of hacks. So my advice would be look at what people are doing in similar context. People are generally quite willing to share their approaches. There's a ton of information on the Internet. And then from a regulatory and policy perspective, I would just say like understand the limits of the tech of the technology before trying to set the policy to make sure that what you wanna do is something that's, like, actually possible. on the first point, we don't train on API data at all. Hallucinations, we we will make continual progress there. It'll get better and better. I think by a year or two years from now, it won't be something that we talk about so much. It'll just be like the models will be way, way better at it, we'll be more focused on other problems. And then on cost And we plan to continue to have big cuts in the future. not sure exactly how they'll intersect. I I think, you know, one example I I would give is as as generated content becomes better and better and we need to know what is generated by a human, I can see a world where if you have, like, a high stakes message, you cryptographically sign it and put it on the blockchain and say, hey. This was really me. So I could see something like that. I can see other ways where you really want to verify something at the time that it happens. we wanna figure out how to train on as much It's okay. Diverse content in the world as possible. So we wanna get we wanna get GPT five, six, seven, whatever, really good at every language, every dialect, know everyone's history and culture, and and go learn the the values of everybody. And and not only that, no two people are ever gonna agree that one system is fully unbiased or, like, fully right in whatever sense you want to call is right. And so it's important to go learn this as much as we can and get as global democratic input as we can. But it's also really important to just give users much more control. So two things there. One, I think the music of the future is just going be way better because artists are going have better tools. And I think people are missing that because right now they're like, oh, you know, you can make something that's like as good as Drake or whatever. But that's that's really kind of underselling our potential. The question is, alright, well, And I think that's gonna surprise us all on the upside. What I do think we need is a way for the people who are making these systems better or who other people are inspiring, like, in the style of, in the whatever of, And, also, most alignment techniques or things that we developed to be alignment techniques also greatly improved the capabilities. So RLHF And so the answer to every problem is more deep learning. And thus, there's not a differentiation in the same way that we think. And we've got to just think about the whole system together, capabilities and alignment together. I am not and I think that's the best, safest possible world. So I think that's all good. If we did get to a fast takeoff world, there's many approaches that we could take. Humans seem to really have a great intuition for what other humans want. Humans certainly wanna feel useful and creative and valuable to other people. Humans clearly want to contribute back to society. You know, we were talking earlier that we get to benefit from all of the other things people have built that we get to build on top of, but we also, many of us have a desire to contribute something back to that. Humans also really care about what other humans can do. If we think back know, work was then beginning on the system, I think, that became Deep Blue. Deep Blue was the took a long time, but eventually was the first the first sort of AI program that I think got, like, a great deal of attention in the world for beating a human at at something, at chess. And I went back and read some articles about that once. Everybody was talking about how, Only true general artificial intelligence could do this. And then it happened. We, of course, moved the goalpost like we always did. AI is always the thing that comes in the future. But everybody said, well, chess is over. And, of course, what happened is no one is watching two AIs play chess against each other. No one cares about that. And, like, if people get beaten by an AI, like, it doesn't make them not wanna go do their best against other people. So, like, we tend to be very focused on I think it's going to be all of the above kind of thing. There's going to be, you know, governments around the world will do some things together, some things separately. Companies will set their own standards, both individually and together. So people will say, well, you know, in this place they went too far and they're, like, being punished from an economic growth perspective. In this place, they're, like, having these harms happen. And we'll all get to, like, observe the sort of the regulatory marketplace, and we'll get towards the right answer over time. I think it's still like a pretty open question about the framework that people are gonna decide on. the major governments about what they're gonna do, I I'd hesitate to make like a strong recommendation there. I think there will be some cases where people care and some where they don't. And in cases where people care, there will be a lot of ways because we care that will verify it. You know, we mentioned the cryptographic signature idea earlier. There will be detectors that'll, you know, kinda work. Your intuition will kind of work too. But I think there may be more cases than people realize where you don't care. It'll be fine. We're gonna make models more efficient. We're gonna make way more chips. I I think this is clearly what the world wants and the market will deliver. but if if we have something that can go create net new scientific knowledge for the world, no one can argue that's not tremendously valuable. you know, I can go talk to other people and I can have a very interesting conversation and I don't really wanna be duped by a computer anyway. But I do want, like, more scientific progress. I think that's how the world gets better. So we still have not updated our intuition for, like, just how much we've all just gained in terms of, like, superpowers So it's super, super accessible, maybe more accessible than any technology before. I mean, if you wanna, like, learn how to go train g p t five, that's, like, pretty hard and technical. any other product, I think any product manager can go do that with almost no technical knowledge in a really deep way. Honest. Yeah. Thank you. Hey, Sam We we can do a pretty good job of aligning an AI to behave in any particular way, generative AI, I personally think it's like a dumb term because most of what people use this or a lot of what we use this for is not generative in this it it just means like, it's finally the AI people always wanted. It's like actual general purpose can do some limited new knowledge creation, very limited.