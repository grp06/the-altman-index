Unknown: Wow. What an audience. Yes. Huge amount of people. It's wonderful that we had so many attenders during this conversation. you see, there are a bunch of people, and I'm sure they are going to ask you very in-depth questions in the second part of our meeting because there are going to be about forty minutes for the questions from audience. So please, everybody, prepare your questions, questions. And Okay. I will have some questions about Polish impact in building artificial intelligence. But first, AI, to see it as sci fi movies and books shown us for the last couple of decades. So what we can suspect from AI, like real suspect, and not in long term, not in twenty or thirty years, but in a year or in five years, what AI
Unknown: Yes. So, Christine, I read many of the sci fi books in the past, and actually, often in the past, people thought that AI revolution would first show up in robots. So when I read Assimov's books, he described stories of huge robots that cannot speak that lullaby kids. So definitely, the progress at first is mostly in the digital space. And there is also a large volume of actually data that has been created so far, which allows the models really to perform well. The places where I think that we'll see a lot of progress is definitely education. I also believe that the communication between humans will totally change. It will be the case that models are really incredible with translating between languages. I believe that we'll have very new like the interfaces, text to speech, speech to text, they will be just fantastic. I also believe that we'll see changes in health care.
Unknown: Any other fields that AI is going to revolutionize in a couple of months, maybe?
Unknown: create. But I actually think that in some sense, every aspect of human life in some way will be touched by AI. I believe that in case, for instance, of the legal work, lawyers will be supercharged by being able to read hundreds of pages of work and actually understand what's going on.
Sam Altman: And I agree with Wojciech that this is gonna touch almost all aspects of society. It is very interesting to me too that robotics was so hard. We started off with robotics, and it turned out that cognition is much easier than robots. It was exactly the wrong way from exactly the opposite of what everybody thought. Everybody thought first AI would do physical labor, then some cognitive labor, then the really hard cognitive labor like computer science programming, and then maybe last of all, but maybe never because maybe it's like magical and human was creativity. But I do think it's quite amazing. Like, this is one of the more important developments in human history. It gets predictably better with scale, and we can do something called RLHF, what could happen if this goes really badly. I think with any very powerful technology, there's incredible, tremendous upside, but you've also got to manage the downside of it. We've dealt with this with nuclear energy. There's incredible promise of clean energy, also weapons. With synthetic bio, incredible promise of curing diseases, also synthetic pathogens that can escape from labs and cause global pandemics. So we have to manage things like this that have great pluses and great minuses. This will be one of the most powerful technologies humanity has yet developed, And so we need to figure out globally how we're going to deal with this, how we solve the technical safety problem,
Unknown: a piece of information that you wrote a few days ago, maybe yesterday, that we are likely to need something like the International Atomic Emergency Agency for super alliance efforts. So you see AI as a threat as big as nuclear energy and atomic? Because it sounds very harsh.
Unknown: Also, would say that the fear is the fear of AI of the future, not the AI of today. So we think that if the trajectory that we are on will continue, then in a decade or so, there will be built systems which are as powerful as today corporations. Okay. So long term? Long So term we believe, we particularly believe that when it comes to that there is some threshold on the technology, that above some level, the companies like us, you know, big guys, big fishes, they should be regulated. While actually below some threshold, we believe that the regulations should be way less stringent, and we are quite supportive of open source and so on.
Unknown: disadvantages of AI, and they are very crucial, I mean, in crucial fields. We see how it can help spreading disinformation. in The United States. Aren't you afraid that also your products can be really dangerous for democracy? Because we've already seen what technology can do during the elections.
Sam Altman: disinformation, and the new challenges. One new challenge is that these systems are interactive. it's totally with an AI, and it could be pretty persuasive if you don't know. And so passing laws about use of these systems, making sure people know if they're talking to an AI, making sure that companies like ours have monitoring in place and also systems that refuse to generate certain things, and realizing that open source is unstoppable and shouldn't be stopped. So this stuff is going to be out there, and as a society, we have to adapt. Okay. So right now, you are talking quite a lot about need of those regulations.
Unknown: But why didn't you wait with ChatGDP a little bit longer to prepare those regulations? For example, European Union, we are working on AI Act, and
Sam Altman: it would be a couple of months only needed to to be ready. Well, two things. One, we think it's very important for the world to have time to gradually adapt to these systems, to put them out while they're not that strong so that people can get to know them, the risks, the benefits, and that regulators can get to know them. I think had we not launched ChatGPT, And the people of the world have not had time to give input for what they want, for us to make this decision together, You know, this trip on the road will meet with dozens And so the process to get to the right thing has got to be iterative with society. We test a lot before we release it. Before we release GPT-four, we spent eight months red teaming it, doing external audits, working on safety evals. We're not trying to use the world as guinea pigs here, and we're thankful that people have said such nice things about how aligned the model is. and I expect we'll see that for many other industries. It's it's certainly fair criticism. We feel like we're moving very deliberately. Again, we spent eight months just trying to look at this model, engaging with people around the world. Most of what the world was saying, because it kind of leaked out that we had we're sitting on this, was like,
Unknown: We are in Poland, so I also just have to ask some questions about Poland and about Porsche Input in OpenAI. We've got Wojtek and Shimon. Please tell us a little bit more about your work. And how can also Polish perspective change building AI systems?
Unknown: There is this Polish culture within the company, And I want to say that actually, we got incredible education here, and we learned a lot actually I'm thinking about it maybe similarly to electric current that actually, at the moment, is just all around us. And it feels to me quite important at this stage to embrace AI. So, you know, one potential way how people can go about it is actually we are scared. We don't want it. And, I don't think that that will get the country far. And actually, instead, I would say I believe that implement AI all over the place. It should be implemented in hospitals. It should be implemented And there is a place for proliferation of startups to actually embed AI technology actually in every aspect of life. And that's the investment in the future. There
Unknown: is one more issue that is very important, and this is the question that I get from Mikhail Jaskulski, and I have to just quote him because he's an author of this question. What actions should and could Poland take to ensure that our entire heritage, our literature, history, art, geography will be included in these large
Unknown: actually, when we developed these models, one of the guiding principles are evaluations. So we actually measure performance of the models on the tasks. And then the places where it lacks, we can put more effort to make them better. But actually, often, are even blind. We don't know that the model has some deficiencies, and it would be of a tremendous value getting the hardest possible evaluations to show where the model sucks, what are the places where it cannot perform tasks, and we have even a place to actually submit these evaluations. And then we have something to optimize.
Unknown: So my one last question that I just have to ask because this is a question a little bit about my field. I mean specific work from journalists, from artists, from writers,
Sam Altman: AI. Yeah. So there's like a legal question. I know it best in The US, but we feel comfortable about sort of fair use and how that works and it's important. But you get to benefit from that somehow. Now there's very different opinions of what people want for that, so we're talking to creatives and content owners and journalists about the best model there.