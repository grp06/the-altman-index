Unknown: You've described in another interview, described OpenAI as a combination of four companies, a consumer technology business, a mega scale infrastructure operation, a research lab, and all the new stuff, including planned hardware devices.
Sam Altman: We want to be people's It turns out that to support that, we also have to build out this massive amount of infrastructure,
Unknown: do you think it will end up
Sam Altman: I I think when we say stuff like that, people don't take us seriously or literally. Yeah. But maybe the answer is you should take take us both. How do how do we think about it? I mean, the research enables us to make the great products, and the infrastructure enables us to do the research. So, it is kind of like a vertical stack of things. Like, you can use Chetch BT or some other service to get advice about what you should do running an organisation, but for that to work, it requires great research and requires a lot of infrastructure. So it is kind of just this one this one thing.
Unknown: where that becomes completely horizontal? Or will it stay vertically integrated for the foreseeable future?
Sam Altman: I was always against vertical integration.
Unknown: the story of OpenAI has certainly been towards we have to do more things than we thought to be able to deliver on the mission. Right. You know, although the, you know, the the history of the computing industry is kind of been a story of kind of a back and forth in that, you know, there was the Wang word processor and then the personal computer and the the BlackBerry before the smartphone. So they you know, there has been this kind of vertical integration and then not, but then the iPhone is also
Unknown: Which bets would you say are enablers of AGI versus which are sort of hedges against uncertainty?
Sam Altman: You could say that on the surface, Sora, for example, does not look like it's AGI relevant, but I would bet that if we can build really great world models, that'll be much more important to AGI than people think. There were a lot of people who thought ChatGPT was not a very AGI relevant thing, and it's been very helpful to us, not only in
Unknown: Say more about how Sora fits into your strategy, because there is some hullabaloo on on X around, hey,
Sam Altman: I think if one company of the two of us has I think it's cool to make great products, and people love the new Sora, and I also think it is important to give society a taste of what's coming on this co evolution point. So like, very soon, the world is gonna have to contend with incredible video models that can deepfake anyone or kind of show anything you want, and that will mostly be great. There will be some adjustment that society has to go through. And just like with ChatGPT, we were like, the world kinda needs to understand where this is. I think it's very important the world understands where video is going very quickly because that's gonna be video has much more emotional resonance than text. And very soon, we're gonna be in a world where this is gonna be everywhere. So I think there's something there. As I mentioned, I think this will help our research program and is on the AGI path. Solving the chat thing in like a very narrow sense, is if you're trying to like, you know, have the most basic kind of chat style conversation, it's very good. But what a chat interface can do for you, it's like nowhere near saturated. Because you could ask a chat interface like, please cure cancer. A model certainly can't do that yet. So I think the text interface style can go very far even if for the chitchat use case the model's already very good. But but of course there's better interfaces to have. Actually, it's another thing that think is cool about Sora. Like, you can imagine a world where the interface is just constantly real time rendered video Yeah. And what that would enable, and that's pretty cool. You can imagine new kinds of hardware devices that are sort of always ambiently aware of what's going on and rather than your phone, like, blast you with text message notifications whenever it wants, like, it really understands your context and when to show you what.
Unknown: humanoids?
Sam Altman: I know there's like a quibble on what the Turing test literally is, but but the popular Then all of a sudden, was passed. And everything we see is that that's gonna go much further. So in two years, I think the models will be doing bigger chunks of science and making important discoveries,
Unknown: much into the realm of the negative changes if AI gets extremely smart. said this. Somebody asked him, they said, well, you really think the computer's gonna be smarter than brilliant minds? He said, it doesn't have to be smarter than brilliant minds, just smarter than a mediocre mind like the president of AT and T.
Unknown: We should use more of that too, probably. We we just saw Periodic launch last week, know, OpenAI alums. And, yeah, to to to that point, it's amazing to see both the innovation that you guys are doing, but also the the teams that come out of OpenAI just feels like are are, you know, creating tremendous capable of things. We certainly hope so. Yeah. I wanna ask you about just broader reflections in terms of what sort of about diffusion or development in 2025 has surprised you, or what has sort of updated your worldview since ChatDB came out?
Sam Altman: Sort of thought we had like stumbled on this one giant secret that we had these scouting loss for language models and that felt like such an incredible triumph that And deep learning has been this miracle that keeps on giving and we have kept finding like breakthrough after breakthrough. Again, when we got the the reasoning model breakthrough, like, I also thought that was like we're never gonna get another one like that. And it just seems so improbable that this one technology works so well, but maybe this is always what it feels like when you discover like one of the big, you know, scientific breakthroughs is if it's like really big it's pretty fundamental and it just it keeps working. But the amount of progress, can get far enough that it can do like better research than all of OpenAI put together, maybe that's like good enough.
Unknown: you people have kind of started to complain about, I think South Park did a whole episode on it, is kind of the obsequiousness of of kind of AI and chat GPT in particular.
Sam Altman: the incredibly wide distribution
Unknown: Does that do you end up having to configure the personality then, you think? Is that gonna be the answer? I think so.
Sam Altman: I mean, ideally, like,
Unknown: Very interesting. And actually, so so one thing I wanted to ask you about is
Sam Altman: and so I think I had the mindset of,
Unknown: You've chosen to strike these deals and partnerships with with companies that you collaborate with but could also potentially compete with in in certain areas. How do you decide, you know, when to collaborate versus when when not to, or how do you just think about?
Sam Altman: We have decided that it is time to go make a very aggressive infrastructure bet, and we're like, I've never been more confident in the research roadmap in front of us and also the economic value that will come from using those models. But to make the bet at this scale, we kinda need the whole industry to or a big chunk of the industry
Unknown: it does feel like in your mind,
Sam Altman: There's totally a limit. Like, there's some amount of global GDP. then the economic value that sits there I mean, we would still expand because we can see how much how do you throw the new ones? When there's a constraint, we almost like which happens all the time. We almost always prioritize giving the GPUs to research over supporting the product. There are weird times, you know, like a new feature launches and it's going really viral or whatever where research will temporarily sacrifice some GPUs, but but on the whole, like, we're here to build AGI. Yeah. And research gets the priority.
Unknown: sort of, you know, machine, if you will, that is, you know, constantly the culture of innovation.
Sam Altman: This was one thing that I think was very useful about coming from an investor background. A really good research culture looks much more like running a really good seed stage investing firm and betting on founders and Yeah. Sort of that kind of than it does like running a product company. So I think having that experience was really helpful to the culture we built. Yeah.
Unknown: generally, if you're good at investing, you're not necessarily good at, like, organizational dynamics, conflict resolution, you know, like, just like the deep psychology of, like, all the weird shit and then, you know, how politics get created. There's just, like, all this there there's the detailed work in being an operator or being a CEO is so vast, and it's not as
Sam Altman: evals of benchmark scores are less interesting. Yeah.
Unknown: the culture the culture, Twitter, x, is less AGI pilled than it was a year or so ago when the AI 2027 thing came out. Some people point to, you know, GPT five, them not seeing sort of the obvious Obviously, were a lot of progress that, in some ways, under the surface are not as obvious to what people were expecting, but should people be less AGI pilled, or is this just Twitter vibes and
Sam Altman: Yep. Even even if it's like doing kind of crazy AI research, like, the society will learn faster. But think that AGR was gonna come. You kinda go through that. You need something new to think about. You make peace with that. It turns out like it will be more continuous than we thought. The fact that like, so far the technology has not produced a really scary giant risk doesn't mean it never will. It also, like, there's we're talking about it's kinda weird to have billions of people talking to the same brain. Like, there may be these weird societal skill things that are already happening, we that aren't scary in a big way, but are just sort of different. I expect some really bad stuff to happen because of the technology, which also has happened with previous technologies and Mhmm. Finding. All the way back to fire. Yeah. Yeah.
Unknown: Yeah. What what is your latest thinking on the the right mental models we should have around the the right regulatory frameworks to to think about, or or the ones we shouldn't be thinking about?
Sam Altman: probably has a lot of downside. The one thing I would like is as the models get the thing I would most like is as the models get truly, like, superhuman capable, I think those models and only those models are probably worth some sort of, like, very careful safety testing as as the frontier pushes back. I don't want a big bang either. Mhmm. And you can see a bunch of ways that could go very seriously wrong, but I hope we'll only focus the regulatory burden on that stuff and not all of the wonderful stuff that less capable models can do that you could just have like a European style complete cramped down on, and that would be very bad. Yeah. It seems like the
Unknown: is a super superhuman intelligence that could, you know, do some kind of takeoff light thing. we as an industry kind of confuse the regulators. Yeah. But China's not gonna have that kind of restriction. And and you getting behind in AI, I think, could be very dangerous unfolding? Because you've done some very interesting things with the opt out. And, you know, as you see people selling rights, do you think will they be be bought exclusively?
Sam Altman: got a very different response from rights holders than ImageGen does. Yeah. So, like, you'll see this continue to move, but forced to guess from the position we're in today, I would say that society decides you know, anyone can read like a human author can. Anybody can read a novel and get some inspiration, but you can't reproduce the novel on your own. Right. And you can talk about Harry Potter, but you can't respit my concern is you won't put my character in enough. I can completely see a world where
Unknown: understood about the music business was how, like, it I I would just say it's it's very possible for the industry just because the way those industries are organized or at least the traditional creative industries to do something irrational. I I do wonder how it's gonna shape out. I agree with you that the rational idea is I want to let you use it all you want, and I want you to use it. the interpretation of everything to somebody Yeah. Who may be or may not be influenced heavily by the Chinese government. Yeah. putting out a really good open source model because what we're seeing now is in all the universities, they're all using the Chinese models. Yep. Yeah. Which
Sam Altman: roughly speaking, I I think if you look at history, the best, the highest impact thing to improve people's quality of life has been cheaper and more abundant energy.
Unknown: pinned ourselves into a little bit of a corner on energy by both outlying nuclear for a very long time. That was an incredibly dumb decision. Yeah. And then, you know, like, also a lot of policy restrictions on energy. And, you know, worse so in Europe than in The US, but also dangerous here. And now with AI here, it feels like we're gonna need all the energy from every possible source. And how do you see that developing kind of policy wise and technologically? Like, what are gonna be the big sources and how will those kind of curves cross? And then what's the right policy posture around, you know, drilling, fracking, all these kinds of things?
Sam Altman: I expect in the short term, it will be most of the net new in The US will be natural gas relative to at least baseload energy. In the long term, I expect it'll be a I don't know what the ratio, but the two dominant sources will be solar plus storage and nuclear. I think Advanced nuclear, meaning SMRs fusion the whole the whole stack.
Unknown: And how how fast do you think that's that's coming But we we have to completely legalize it and all that kind of thing. I I think it kinda depends on
Sam Altman: the price. If it is completely, you have these major transitions to a much cheaper source, nuclear gets radically cheap relative to anything else we can do, I'd expect there's a lot of political pressure to get the NRC to move quickly on it, and we'll find a way to build it fast. If it's around the same price as other sources, I expect the kind of anti nuclear sentiment to overwhelm and it to take a really long time. you know, different models that you're excited about? The thing that's top of mind for me, like, right now, just because it just launched and them versus how you think they're gonna use them. Yeah. And people are certainly using Sora the ways we thought they were going to use it, but they're also using it in these ways that are very different. Like, people are generating funny memes of them and their friends and sending them in a group chat, and that will require a very different like, Sora videos are expensive to make. Yeah. you know, the traditional naive thing that it's like 1% of users create content, 10% leave comments, and a 100% view. Maybe a lot more when I create content, but it's just been harder to do. And I think that's a very cool change, but it does mean that we gotta figure out a very different modernization model for this than we were thinking about if people wanna create that much. I assume it's like some version of you have to charge people per generation per generation when when when it's this expensive. Like many other people, I find ads somewhat distasteful, I like Instagram ads. I've never felt that. Like, but
Unknown: you know, fake content that then gets slurped in by the model, and then they recommend the wrong coffee maker because somebody just blasted a thousand great reviews of their So own coffee
Sam Altman: there's all of these things that have changed very quickly for us. Yeah. This is one of those examples that people are doing these crazy things to maybe not even fake reviews, but just paying a bunch of human And now, there's like a real cottage industry that feels like it's sprouted up overnight Yeah. Trying to do this.
Unknown: And, you know, we're trying to kind of figure out problem where, like, the incentive to create content on the Internet used to be, you know, people would come and see my content and they'd read, like, you know, if I write a blog, people will read it and so forth. With ChatGPT, if I'm just asking ChatGPT and I'm not, like, going around the Internet, who's gonna create the content and why? And is there an incentive theory or or or something that you have to kind of not break the covenant of the Internet, which is like I create something and then I'm rewarded for it with like either attention or money or something.
Sam Altman: The theory is much more of that will happen if we make content creation easier and don't break the like kinda fundamental way that you can get some kind of reward for doing so. So for the dumbest example of sores since we've been talking about that, it's much easier to create a funny video than it's ever been before. Yeah. Yeah. Maybe at some point you'll get a rev share for doing so. But
Unknown: Team as strong as ever, shipping incredible products.
Sam Altman: And then we launched SGPT, and everybody was, like, congratulating me. And I was, like, my life is about to get completely ransacked. And, of course, it has. And I think it does get a little bit crazier over time, but I'm, like, more used to it, so it feels about the same. Yeah.
Unknown: Talked a lot about OpenEye, but you also have a few other companies, Retro Biosciences and Longevity, and energy companies like Hellion and Oclo.
Sam Altman: No. I just wanted to use my capital to fund stuff I believed in. I didn't more fun, and more interesting to me, and certainly, like, better return than, like, buying a bunch of art or something. Yeah. My intuition is that, AI will be fascinated by all other things to study and observe and, you know, like.
Unknown: In in closing, I I love this insight you you had where you talked about how, you know, the next open a mistake investors make is pattern matching off previous breakthroughs, and just trying to find, oh, what's the next Facebook, or what's the next OpenAI? And that the next, you know, such a trillion dollar company won't look exactly like OpenAI. It will be built off of the breakthrough that OpenAI has helped, you know, which is, you know, near free AGI at scale in the same way that OpenAI leveraged previous breakthroughs. And so, for founders and investors and people trying to ascertain the future listening to this, how do you think about a world in which there is OpenAI achieves its mission, is near near free AGI. What types of opportunities might emerge for for company building or or investing that you're potentially excited about as you put your investor hat on or company building hat on?
Sam Altman: I think if you try to, like, armchair quarterback it, you sort of say these things that sound smart, but they're pretty much what everybody else is saying, and it's, like, really hard to get the right kind of conviction. The only way I know how to do this is to, like, be deeply in the trenches exploring ideas, like, or saying the obvious things. But I think it's a very important like, if you are an investor or a founder, I think this is the most important question, and you don't you you figure it out by, like, building stuff and playing with technology and talking to people and being out in the world. always You all have done a lot of it, but most firms just kinda chase whatever the current, you know,
Unknown: staying, you know, super close to the smartest people, super close to technology, just identifying opportunities into kind of an organic and incremental way from there.
Sam Altman: I'm not, like, enough of a It's not it's not the