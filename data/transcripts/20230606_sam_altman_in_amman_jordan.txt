Unknown: We have a lot of people from the government. We have his excellency Ahmed Elhanande, who's leading the wave on the digital transformation front in Jordan. We have Doctor. Abdul Esses, who's been a very good close friend and a long term mentor as well. leading a lot of the energy related stuff for a very long time as well. And obviously, we have the bulk of the audience is more towards devs, data scientists, software engineers, data engineers across the board. We kind of made sure that we want to be inclusive about capital allocation. So we have some representation from venture capital, private equity, funds of funds. Obviously, everybody is excited to know how can they leverage a lot of that. We have industry leaders is AI like the big reset. Right? Technology and Internet is actually giving us an equalizer. It's giving fair opportunity across the world. Good founding teams, good products, a little bit of capital can actually build multibillion dollar businesses that touch millions of lives. You certainly have done this through your journey with YC and it's been really something inspirational for all of us, of course. The nice things about AI is it's gotten the cost of shipping something really low. bioinformatics
Sam Altman: certainly the biggest opportunity and leap forward in technology that we've ever seen and also the most equalizing force. It takes some work to make sure that's going to happen. But I think the natural case of this is making something that has been expensive and difficult to access, which is intelligence, super available. And I think we're still underestimating But yeah, I guess anytime the world is going to progress so far forward so quickly this much, that is somewhat of a reset. And these are like the most exciting times to, I think, to live through the opportunity in front of us, right, as a world in front of us right now to create a very new and much better future, I think is This is not the moment. Yeah. I mean, is like the warm up to the moment. The steepness of the curve that we're on and what we'll be able to deliver in the coming years, I think, is going to be truly remarkable.
Unknown: I mean, maybe I'm diving on this question because at emerging markets, we do believe that things are a bit secondary to us, right? A lot of the tech happens in California and San Francisco. And there's a bunch of maybe as a kind of opportunity around you know, where does it lie really? Is it towards building the, you know, the large language models? Is it around moving forward, building a lot of the datasets that would kind of leverage a lot of those opportunities? So I'll give you an example. AI OpenAI has obviously led the way. You guys have opened a bunch of tech already on GitHub, Whisper, Jukebox, GPT2, DALI, you name it. And obviously a lot of cool tooling around eval, which has been phenomenal really. Obviously, our very own Ripplet has launched RippletLM. And those guys have done like 3,000,000,000 parameters, think, and the whole model is like five gigs. Falcon, our neighbors in Abu Dhabi as well have launched the 40B. And obviously, they've made it royalty free, I think, a couple of days ago. And obviously, with what you're seeing, Sam, is like the advancement of open source tech and people adopting this has really accelerated stuff.
Sam Altman: so much of our mission is how we get the world the benefit of AI. I really do think that figuring out how to take these models and use them in different contexts for different services and go build whatever you can imagine on top of it. Like we view our job is to build the tool and then we think it's everybody else's job to like unleash all of human creativity on top of it. We will keep making the models better and better and the API more and more powerful. And I think what people can do around the world has been amazing. all around the world want us to do, are afraid of us doing, you know, would like us to build, are upset with us about. And then the other is just to like learn about what people are building. And they've both been great, but the learning what people are building has been amazing to see. And, We try to make a decision based off of like all the different factors pushing on us at any given time. But you can expect much more of both from us in the future. Amazing.
Unknown: places in the entire Middle East, North Africa region. We're talking about 400,000,000 people. And Jordan actually maybe the smallest or the smaller ones actually producing the bulk of that content. So we built multimillion dollar companies in Jordan towards public content like modua.com, Atibi for medical and health related, Tajama has been doing a lot of work around very domain specific translation and transcription. Abhub, a lot on the educational side. And with all of that, we're still like, I'd say, around 3% to 5%, maybe 5% actually of the entire Internet. So the main, main question is if data is kind of a leverage or an advantage.
Sam Altman: I think everyone feels a little confused about this right now. There's uncertainty about whether people want these models to be databases or reasoning engines. If it's a database, it is certainly the world's worst, most expensive, slowest, least accurate, bad database. But if it's a reasoning engine, it's certainly the best reasoning engine besides human brains that we have so far. And my personal belief is that people will realize that what they really want out of these models as they get more powerful, as we get to the GPT five, six, whatever era, people will say, okay, these can be great reasoning engines that are then going to go off and access a bunch of data for different stuff. and maybe we won't even want them to train on all the data. The model will be good at being smart. The model will be a cognitive capacity. And then it'll go off and access this data or that data or whatever data you need and there can be different business models around that. So I think data will be an asset in the future, but not in the way people think where it's just like cramming every possible token.
Unknown: actually a lot of the we've been following all of your tour and we definitely got kind of to hear a lot about that. So if if you were to give us some advice of what's a future proof strategy
Sam Altman: And one of the points I would make, which this just like triggered an old memory in me, is don't think about like how you're gonna build a startup. If are people in here doing startups? Some people? Yeah. Okay. Awesome. That's great. Don't think about how you're like gonna go do a startup for your region or your market or whatever. Like go take on the world. You can definitely do it. Don't like limit yourself to we're gonna do this thing here and we can't compete with The US companies. Many of the best companies we ever funded at YC were people that came to us saying, We're gonna like do something for our country or our city or whatever. And we convinced like, Why don't you do this for the world? You can do definitely as good of a job as anybody in Silicon Valley. And I think that's even more true today than ever before with this reset. Like the emerging economy, I think, should just have an unbelievable step forward here. So, like, please don't limit yourselves to we're gonna do this country or this region, just like take on the world. That's
Unknown: I I think our entire existence in this emerging economy is actually trying to change everyone's mindset. You know, you can build whatever you want. You can shift to any country you want. Just aim big and, you know, hopefully, you get it there. Absolutely on this. Okay. So so I think, you know, there's this So, you know, a lot of the questions we've been thinking about is how can we, like, reinvent the workforce of the future for those emerging economies? So if you were to help us kind of think, especially because there's a lot of folks from the government as well, you know, how can we just, you know, just leapfrog the initial one and just jump into AI native workforces that can kind of really do a lot around it?
Sam Altman: Number one, the systems of today are much better at doing tasks than jobs. So and I think this is gonna stay true for a while, not forever, but a while, where they make you a lot more productive if you're doing your thing. But if you're kind of trying to, you know, have a system be a whole computer programmer rather than do some of your tasks as a computer programmer, that's pretty hard. But what happens is people can do their job like say three times more efficiently. They can do three times more work. That's great. And there's so much excess demand in the world for a lot of areas. I think, And you see this with every technological revolution where people try to like hold on to the old jobs or not let jobs evolve at all. And that's basically guaranteed to be a mistake. And then number three, I don't know what the jobs of the future will be. I think like if we went back a hundred years trying to imagine AI programmer would have been like, you would have sounded very crazy to think about that as a job. The jobs that we do in a hundred years will probably sound very crazy from here. But they will be there, like human desire to create, human creativity itself is like limitless. People will find new ways to get the sort of fulfillment status and make these things to make each other happy. And all the predictions have just kind of been wrong, and I think they'll continue to be wrong. But what I would say is lean into it, find the new jobs that weren't possible before. Don't worry about jobs changing a lot. I think we are gonna be in a period where the rate of change in the world is just higher than any of us have ever lived through in terms of what what jobs look like.
Unknown: maybe a bit something that's been recently kind of coming up. I mean, from someone like me, leveraging GPT has been like a 10x easily, actually 100x maybe benefit to my productivity. Zoom out a bit, that's 100x productivity on the economy. I think we can do much more. And that's like, I think, the most exciting thing to your point, Sam. But I think we are kind of missing somewhat around the danger of AI. Right? So I personally I'm sure a lot of the crowd as well watched the Senate hearing. And to all of our surprises, Sam actually took the first step to regulate. statement that you signed just five days ago maybe. Mitigating the risk of extinction from AI should be a global priority alongside other societal scales such as pandemics and nuclear war.
Sam Altman: not a super dangerous piece of technology. We put some limits on it. You know, we do I think some things. We do a lot of work. We do some things that are maybe even too much to make sure that it behaves in a way that we think is safe. But GPT-four is not going to destroy the world. And so people look at that and say, well, why are you talking about this? And then the few years after that we do it once more. And along the way we figure out the ideas that these systems need not only to kind of generate responses that are like what they've seen before, but to be able to cure all human disease or to create a worse disease than any of us have ever seen before. They have the ability to, you know, solve our energy problems, but they also have the ability to create atomic weapons at a scale that none of us have seen before. They have the ability to teach us anything, but they also have the ability to like really emotionally manipulate us and make us all hate each other and, you know, fight a lot. That's the world that we're talking about when we talk about the need for regulation. It is not about the current systems. It's what happens if we stay on this curve. People are terrible at intuiting exponential growth. This is like been a long fascination of mine about why it's so bad, but something about our evolutionary biology just didn't need this. reasonable to proceed with caution and assume we might be on that curve. And if we are, then I think now is the time to start taking it really seriously and figure out as a globe what we are going to do to make sure we don't face calamity. We've come together a few times before with technologies that have this much benefit but also this much risk. when we started this trip three weeks ago, I was very pessimistic about getting this done, and I now think the world will come together and get this done.
Unknown: not against, like, getting this regulated early, but maybe a lot of the conversations that's been happening, Sam, is, you know, if you regulate a bit too early, don't you just inherently
Sam Altman: slow down innovation? Yeah. And again, I'm not advocating. We're not advocating for regulation of the current models. We're not advocating to go regulate open source models. We're not advocating to go like stop small companies from developing this. I think that would be a huge mistake. What we are saying is if someone, us, somebody else, but probably us, makes a model that is, like, as smart as all of human civilization, has the power of all human civilization,
Unknown: you've written like a very nice blog post. The days are long. The decades are short. I think it resonated with so many different people across our industry. It's kind of the top things that he kind of or the the the deduction of the of that ten years and, you know, what lessons he learned during those ten years. If you allow me, I'm just going to mention four that really resonated for me specifically. So on family, put your friends and family first and significant others, of course. Never put them a low priority, of course. On work, I think I can't even agree more with this. You know, it's difficult to do great work great great job, sorry, on work you don't care about. You know, beautiful, beautiful one. Get out of your way to be around smart, interesting, ambitious people, and I think that's the only way to to move forward, I guess. Don't change sorry. Chase status. Status without substance doesn't work for long. And one of my personal favorites, you know, go out of your way to help others. I think that's great. Those are like really So I think in that lens,
Sam Altman: fusion is probably the most exciting technological development in the world. And we are finally very close. So, we'll do a demonstration next year. the kind of like the first boss is get the physics to work. The second boss is to get the engineering to work. And then the third boss is we have to build two machines, two five hundred megawatt machines every day for ten years. And the scale of doing that, the manufacturing, building this machine that can just be like throwing these off the end of an assembly line is unbelievably challenging. But the physics milestone will still be a great one to celebrate and then we'll get to work on the next. And you know, the thing in 2028 is not a demo plant. That is a plant that will be running and supplying continuous real power to the grid. And that is a tremendous moment. The thing about fusion that I think is so exciting other than the fact that it's great for the climate is the cost of energy and the scale with which we can produce it. This is like baseload always on solid energy. I think And if you want quality of life to go up, if you want to like lift people's standard of living as high as you can, you should drive the cost of those two things And that will transform the world. Both of them help each other. So the Helion uses AI tools to do their work. OpenAI needs tremendous amounts of very dense energy to build the data centers that we want to have. So we plan to use those systems too. One of the things about OpenAI is we've always tried to stay extremely small as a company. And small focused, very talent dense teams. Access to capital, do think is about to get super democratized. I think there will be like AI asset capital asset allocators that are way better than any people. I think people are already trying to do this around in all these different ways. But I think what you can do with these tools is just fundamentally different. It breaks the normal economic model. I think, you know, there was this famous example in Silicon Valley lore, which is WhatsApp. I'm going get the numbers kind of wrong, but they had like 40 people at the time they were acquired for 20,000,000,000. I think there will be a 10 person $20,000,000,000 Because you'll just have like AI doing so much of the work in ways that are difficult to imagine today. So I think it is a just it's a super different world now. And this is like super counterintuitive, but it is true of like most of the most successful startups I've known, and that's another advantage. We didn't quite expect it to be this impactful, but the serious impact that individual students are having by learning on their own or teachers are having by putting this into their classrooms in different ways, it's really like we're proud of that. It's an awesome thing to watch. We will do a lot of things to improve that. One is we've been talking about what sort of like kids safe versions of this we can make. Another is increasing the robustness and the accuracy. But, But the downside here is pretty big and I think we feel that weight every day. Honestly, I think if we're going to regret something, it may be that we already pushed the button. Like we've already launched this revolution. It's somewhat out of our hands. I think it's going to be great. But like I think there's many short term things that we will get wrong now or in the future. But what we would really regret is that we somehow made the world worse off than it otherwise had been. There's the extreme downside cases where, you know, we do something that really destroys some significant part of humanity and the things we value. But there's also like more subtle ways this could go wrong. And, you know, we kind of just make everybody a little bit less happy. I think the last technology revolution of social media has not gone as well as its creators hoped for. So hopefully we've learned a lesson and that we spend a lot more time stressing out about it than people did before. After we finished training GPT-four, we spent almost eight months trying to make it as safe and aligned as we could before releasing it. But this is like a complex, very dynamic system of technology and society coevolving together. And you can't see exactly where it's going to go. You can just do your best and have a very tight feedback loop at every step. either really regret not being tight enough on that feedback loop and, you know, not correcting in time because I think it's unreasonable to expect us to foresee everything. Or, and I don't think this is true and I hope it's not, you know, we regret doing it at all. And then on the policy side, I think the whole trick here is on the one hand, the world desperately needs this technology. We need productivity gains. We need a much wealthier world. We need to cure diseases. We need to get the energy transition done. We need to provide everybody an earth an education. I truly believe we are going to look back in a hundred years at our quality of life today and the way the world worked and think it was barbaric. Like we're not going to believe how bad it was and that this was something that we tolerated. And we need that. We deserve that. Like humans, On the other hand, to get there, we have to stare risk in the face and not normal risk, but like risk that we destroy the entire world. And getting the policy right to put enough checks and balances on the kind of leading edge, which is difficult to predict, you can't do in advance, you've got to adapt, that we don't make a really big irreversible mistake, but that we still get this enormous benefit. That's what policies got to do. I don't think you can write a policy for that. It's too dynamic. I think all you can do is create a national or international agency with very smart researchers that are continuing to set the rules and adapt them and and make the tests. ways to encode data to go tell us how to do what you just said. But I don't think we're that far away. The thing that I am and I really want to see that happen. I think we're going to get there pretty soon. The thing that the single thing I'm most excited to see these models do personally, they'll do a lot of other great things. But when the models can advance human scientific understanding, if we imagine a year in which we make more scientific progress of discovery of new knowledge than we made in all previous years of humanity, that will be pretty awesome. And I think the models are totally capable of doing this. We need to make them smarter. We need to give them some modest new capabilities, you know, the ability to test a hypothesis, come up with a hypothesis, refine it just with thinking and then test it in the real world and get data back. But this is totally a doable process. And what you said will work with a few additions to the model and a few turns of the model capacity crank. you run enough data. And also like what's the point after you've read 10,000,000,000,000 web pages? Do you really want to read one more? What you would really like, and this is the way humans learn, is to come up with better ideas and then train on them yourselves. So if you think about Newton, for example, there was a time in Newton's life where the right thing to do was to read every math textbook he could find, then read every paper, then talk to every smart colleague, then talk to every smart professor. And at that point, he had basically consumed all of the math that was going to help him make progress. Reading more textbooks was never going to help him invent or discover calculus. And to do that, what you want to do is start generating data, discriminate over it to find out what's best, and then go train on that. And that process is the same as a bunch of generated data out there where the model can pick the best things. And each time you generate a bunch of data, decide what's a good step forward, put that into your training set, you can then see a little further down the road. And then you do it again in a little further and a little further. And that fundamentally, I think, is gonna be part of how we push beyond the knowledge in the world today. And so it's great. So this idea that we're gonna get good at training on model generated data is critical.