Unknown: So when will we all get our WorldCoin?
Sam Altman: you know, think whatever you want about crypto and the ups and downs, but the fact that The US is the worst country in the world to have a crypto company in or you just can't offer it at all is sort of a big statement,
Unknown: like, historically big statement. Yes. Yes. It is user.
Sam Altman: I don't know how I would still keep I wouldn't still keep up with email and Slack without it.
Unknown: obviously, it seems very plausible that we're on a trend of super what do you think kind of ex post
Sam Altman: limits us in a way that is not obvious today. So, like, you know, maybe we can never get the systems to be very robust, and thus we can never get them to, like, reliably stay on track and reason and understand when they're making mistakes or, you know, And thus, they can't really, like, figure out new knowledge very well at scale. But I don't have any reason to believe that's the case. I I I think you just touched on it. Like, as as long as you can get to, like, over the synthetic data We we will need new techniques for sure. I don't wanna, like, pretend otherwise in any way. But, like, naive plan of just, like, scale up a transformer with pretraining tokens from the Internet, that will run out, but, like, that's not the plan. Mhmm. I think we are getting to the phase where you really do want smart experts giving the feedback in certain areas to get the model to be as generally smart as possible. and we got lucky. You know, the, like, amount of energy needed at least for a long time was, like, huge and sort of required the power of nations. there to increase probability of a good outcome is worth doing. Classification of nuclear secrets probably helps. However, I think nuclear materials and AI supercomputers do have some similarities, and this is a place where we can draw more than usual parallels and inspiration. But I would caution people to to overlearn lessons of the last thing. I think something like an IAEA for AI, like and I and I realize how naive this sounds and how difficult it is to do, but getting a global regulatory agency that everybody everybody signs up for for extremely powerful I think, should submit to audits full visibility to that organization, be required to pass certain safety evals before releasing systems. strong statements about what China will or won't do that have, like, never been to China, never spoken to, and someone who has worked on diplomacy with China in the past really kind of know nothing about complex high stakes international relations. I think it is obviously super hard, but also I think no one wants to destroy the whole world, and there is reason to at least try here. So And I think that's good because we get more time to figure out how to deal with some of the scarier things.
Unknown: David Luan made the case to me that, like, the the set of economically useful activities is it well, is it purely a subset of, you know, all possible activities and that pretty good models might be sufficient to address most of that first set. And so maybe the super large models will be very scientifically interesting, and maybe you'll need them to do things like generate further AI progress or something. But for most of, like, practical day to day cases, maybe an open source model will be sufficient. How likely do you think that future is? I think for many super economically valuable things, yes, these smaller open source model will be sufficient. But you actually just touched on the one thing I would say, which is, like, help us invent superintelligence.
Sam Altman: That's a pretty economically valuable activity. So it's, like, cure all cancer or discover new physics or whatever else. And that will happen with the the biggest models first.
Unknown: should they adopt a strategy of open sourcing their foundation models slash LLMs or just Lama in particular?
Sam Altman: I think Facebook's AI strategy has been, like, confused at best for some time, but I think they're now getting really serious, and they have extremely competent people. And I expect a more cohesive strategy from them soon. I think they'll be a surprising most of the new work between here and superintelligence will move that probability up or down. But what you really want is to understand what's happening in the internals of the models and be able to align that, you know, say, like, exactly here is the circuit or the set of artificial neurons where something is happening and and tweak that in a way that then gives a robust change to the performance of the model. And if we can get The that the mechanistic interpretability stuff. Yeah. Well, that and then beyond. Like, there there's a whole bunch of things beyond that, but but that direction. If we can get that to reliably work, I think everybody's would go down a lot.
Unknown: And do you think sufficient interpretability work is happening? No.
Sam Altman: are people who are worried about very worried about AI safety and doing great technical work there, but we need a lot more of them. We're we're certainly shifting a lot more effort inside a lot more, like, technical people inside OpenAI to work on that. But what the world needs is not more Twitter and write long philosophical diatribes. It needs more people who are, like, going to do the technical work to make these systems safe and reliably aligned. And I think that's happening. It'll be a combination of people that have that good ML researchers shifting their focus and new people coming into the field. One strategy that I think has not happened enough is grants, like grants to single people or small groups of people that are very technical, that wanna push forward a technical solution and are, you know, maybe in grad school or just out or in undergrad or whatever, I I think that is well worth trying. They need access to fairly powerful models and open eyes trying to, like, figure out programs to support independent alignment researchers. But I think giving those people financial support is, like, a very good step. I think if you have a smart person who has learned to do good research and has the right sort of mindset, it only takes about six months to make them, you know, take a smart physics researcher and make them into a productive AI researcher. So
Unknown: agents that you can converse with in very natural form, low latency, full duplex, can interrupt them, like, the whole thing. And, obviously, we're already seeing with things like character and replica that, you know, even nascent products in this direction are getting, you know, pretty remarkable traction. It seems to me that these are likely to be a huge deal, and maybe we're we're we're substantially underestimating it. Again, especially once you can converse through voice. Yeah. Anything that's right? And then b, if that's right, you know, what what do you what do you think the likely consequences are?
Sam Altman: And I don't know what the consequences are going to be. I one thing that I think is important people people seem to have a hard time kind of differentiating their head. Even with the these very early weak systems like, you know, Replica that you mentioned, it's whatever the circuits in our brain are that crave social interaction seems satisfiable with, like for some people, in some cases, with an AI friend.
Unknown: of upgrades to the replica models because
Sam Altman: What I think we're heading to is is a like, I think what most people assume that we're heading to is a society with one sort of supreme being super intelligence, They're still useful. They still interact with it. It's kind of, like, cute and person like, although you you you know it's not a person. And in that world where we just have, like, a lot of AIs that are contributing to the societal infrastructure we all build up together, that feels manageable and and less scary to me than the sort of single big superintelligence. Yeah. Yeah.
Unknown: push real interest rates up or down because, which cancer curing factories or, you know, pharma companies we should build
Sam Altman: Mhmm. And spend, like, $500,000,000
Unknown: But, you know, with respect to commercialization, is it more important to be a consumer company or an infrastructure company?
Sam Altman: I am a believer as a business strategy and platform plus killer app. I think that's, like, worked for a bunch of businesses over time for good reason. I think the fact that we're doing a consumer product is helping us make our platform much better. app much better too. So I think it's, like, a good cohesive strategy to do them to do them together. But as you pointed out, really what we're about, we'd like to be the best research org in the world, and that is more important to us than any productization. And building the org that can I think that was a kind of thing that that has been transformative and an important contribution back to the world and comes from the sort of work, like, the multiple kinds of work that OpenAI is is good at combining. they have had, like, quite a lot of focus and intensity recently and are really trying to figure out how to how they can move to really remake a lot of the company for this this new technology. So I've been I've been I've been impressed. Are I suspect that they mean search is going to change in some big ways, but not not a threat to the existence of search. It's a good question. It sort of depends on how important synthetic data turns out to be. I guess, if forced to choose, I would choose inference efficiency. There's a lot of things we're working on that I think will be g p t two like moments if they come together, but nothing there's nothing like release that I could point to yet and with high confidence say this is the g p t two of 2023. view of the world, but I would like a Copilot like product that controls my entire computer. Mhmm. So they can, like, look at my Slack and my email and Zoom and iMessages and my, like, massive to do list documents
Unknown: Is there an obvious application of these techniques and technologies to science that, again, you think we have worked with having capabilities for that you don't people see people obviously pursuing today?
Sam Altman: There's a boring one and an exciting one. The boring answer is that if you can just make really good tools like that one I just mentioned and accelerate individual scientists each by a factor of three or five or 10 or whatever, that probably increases the rate of scientific discovery by a lot even though it's, like, not directly doing science itself. The more exciting one is I do think that same a similar system could go off and start to read all of the literature, think of new ideas, do some limited tests in simulation, email a scientist and say, hey. Can you run this for me in the wet lab?
Unknown: you imagine apple scientifically useful application of these models will come more from the first category where we're kinda creating
Sam Altman: I I'm willing to, like, kind of give some rough opinion. In this one, I mean, I guess I would say if if if we can figure out someday how to build models that are really great at reasoning,
Unknown: Are weird capital structures underrated?
Sam Altman: I suspect it's, like, a horrible thing to innovate on. Like, you should innovate on, like, products and science and not corporate structures. Our like, the shape of our problem is just so weird that despite our best efforts, we had to do something strange. But it's been, like, it's been a unpleasant experience on TimeSuck on the whole. And if, like, you know, the other efforts I'm involved in have always had normal capital structures, and I think that's better.
Unknown: the extent to which capital is a bottleneck, the bottleneck on unrealized innovation? Like, is that some kind of, you know, common theme running through the various efforts you're involved with? I
Sam Altman: OpenAI and Helion are the things I spend the most time on and then also Retro and Worldcoin. minimum nine digits before there's a lot of value in being willing to do stuff like this, and it fell out of favor in Silicon Valley at some point. And I understand why. Like, it's also great for companies that, like, only ever have to raise a few 100,000 or million dollars and get to profitability. collectively how to, like, do the high risk, high reward, hugely capital and time intensive bets, and those are also valuable. We we should be able to support both. I'm happy he exists in the world, of course,
Unknown: I suspect there's something in the culture on both the founder and the capital side, the kinds of companies the founders want to create and then the disposition. And for the most part, a particular sociology, any of that's evolved over time. Like, venture capital was itself an investment. PE in its modern form was was essentially an invention. And and so,
Sam Altman: people who became tech billionaires in the last cycle are pretty no. Most are pretty interested in putting serious capital into long term projects. And the availability of capital for significant blocks of capital upfront for high risk, high reward, long term, long duration projects that rely on fundamental, like, science and innovation is going to or already has dramatically changed. So I think there's, like, gonna be a lot more capital available for this. You still need, like, the Elon, like, to to do it. And like, one project I've always been tempted to do is say, okay. We're gonna identify the, let's say, 100 most talented people we can find that want to work on these sort of projects. Let them go off and without the kind of pressure that most people feel, have the certainty to go off and explore for a long period of time and, like, you you know, not feel the, like, very understandable pressure to make a ton of money first put them together with great mentors and a sort of a great peer group. And then the financial model would be, like, if you start a company. If not, that's fine. Like, it'll be a writer, politician, think, whatever. If you start a company, the vehicle gets to invest, like, on predefined terms. Yeah.
Unknown: So, Silvana, you know, I'd I'd known this person for, again, a really extended period. you didn't,
Sam Altman: But I derive, like, great pleasure from work having, like, working relationships with people over decades through multiple projects. And, like, it's a lot of fun to, like, feel like you're building together towards something over that has a very long arc.
Unknown: Which which company that is not thought of as an AI company will benefit the most from AI over the next five years?
Sam Altman: I think some sort of investing vehicle is going to figure out how to use AI to be, like, an unbelievable investor and just have a crazy outperformance.
Unknown: we will come to realize that GPT-four is somehow significantly overfit on the problems,
Sam Altman: I think the base model is not significantly overfit, but there's we don't understand the RLHF process as well, and we may be doing more, like, brain damage to the model in that than we than we even realize. I think it's a very imprecise notion, but there's clearly something real that it's getting at in humans and for models as well. So I think we probably, like, over there's, like, way too many significant figures when people try to talk about it, but, you know, it it's definitely my experience that very smart people can learn, model intelligence will also be somewhat fungible. I mean, I would like to not have another synthetic pathogen cause a global pandemic. I think we can all agree that wasn't a great experience. Wasn't that bad compared to what it could have been,
Unknown: wastewater sequencing, biology attacks. And the fact that we don't have a giant correlational dataset of the, you know, pathogens that people are infected with and then sort of longitudinal, both treatments and vaccines than we do and than we have. And so I think the particular thing like, if it is true that COVID was engineered, I think, you know, instances of that set of slight modifications to already existing infectious diseases, we can probably significantly improve our protections too. for for, you know, novel vaccines and, hopefully, you know, mRNA platforms and similar make, you know, it easier to have general purpose manufacturing capabilities there. But as you know, the the limiting step Yeah. But I guess I guess your your your investment in trial spark is is consistent with that observation. So Ezra Klein and Derek Thompson are are writing a book about of the left of of the liberal sensibility is about etcetera. public writings thus far, but but, you know, for the purpose of this book, the argument that actually for for society as equal and prosperous and environmentally friendly and, you know, so forth to, you know, actually realize many of these values we care about, we'll need just, like, a lot more stuff in many, many different domains, more more kind of the Henry Adams curve realized. And they frequently observed that permitting in the broadest sense, all sorts of, you know, well intentioned but self imposed restrictions are are the, you know, rate limiting factor in making this happen. Maybe most obviously with the energy transition. restrictions and strictures is is, you know, the the relevant variable in the progress that actually ensues?
Sam Altman: And I don't think it's quite that simple either. I do think that the current system so I totally agree that we need much more abundance. And, you know, my personal beliefs are abundant energy and abundant intelligence are gonna be two super important factors there, but there's many others. Certainly, with as we start to, like, get closer on being able to deliver a lot of fusion to the world, understanding just how painful the process to, like, go get these things out is, like, disheartening to say the least. And it's pushing us to look at all sorts of, like, very strange things that we can do sooner rather than, like, wait for all of the permitting processes that will need to happen to connect these to the grid. I think it is a real problem, and I think we don't have that much societal will to fix it, which makes it even worse. Like, societal collective belief we can actually make the future better. Every every, like, additional sort of, like,
Unknown: whatever it was, fifteen or so years ago, Mark Zuckerberg was preeminent in the technology industry and in his twenties.
Sam Altman: Yeah. It's not good. It's it's something has really gone wrong, and there's a lot of there's a lot of discussion about what this is, but, like, where are the great founders in their in their twenties? It's not so obvious. But maybe something's really gone wrong in our educational system or our society or just, like, how we think about companies and what people do aspire to. But I think it is it is worth significant concern and study.