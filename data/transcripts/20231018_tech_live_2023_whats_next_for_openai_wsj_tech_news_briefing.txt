Unknown: Welcome to Tech News Briefing. It's Wednesday, October 18. I'm Julie Chang for The Wall Street Journal. These days, you're probably hearing generative AI this, generative AI that, and naturally, that's leading to a lot of questions and concerns. OpenAI is probably the most well known generative AI company at the moment because of its popular tools ChatGPT and Dolly. Our senior personal tech columnist, Joanna Stern, sat down with OpenAI CEO, Sam Altman, and CTO, Mira Moradi, at this year's TechLive. Here are highlights from their conversation. By the way, you're going to hear them talk about AGI. That stands for artificial general intelligence, and that means a system in which computers have human level cognitive abilities.
Sam Altman: They produce a lot of productivity and economic value.
Unknown: Mira, how's GBT5 going?
Sam Altman: is known for betting on scaling, you know, throwing a ton of compute and data on these, neural networks and seeing how they get better and better at predicting the next token. But it's not that we really care about the prediction of the next token. We care about the tasks in the real world to which this correlates to. And so that's actually what we started seeing once we put out research in the real world, and we build out products through the API, eventually through Charge GPT as well. So now we actually have real world examples. We can see how our customers do in specific domains, how it moves the needle for specific businesses. And, of course, with GPT-four, we saw that it did really well in exams like SAT and LSAT and so on. So, it kind of goes to our earlier point that we're continually our definition of what it means for these models to be more capable. But, you know, as we increase the the capability vector, what we really look for is reliability and safety. And, you know, as we build the next model, the next set of technologies, we're both betting, continuing to bet on scaling, but we're also looking at, you know, this other element of multimodality because we want these models to kind of perceive the world in a similar way to how we do. And, you know, we perceive the world not just in text, but images and sounds and so on. Will It could be that continuing in this path of reinforcement learning with human feedback, we can get all the way to really reliable outputs, and we're also adding other elements like retrieval and search so you have the ability to provide more factual answers or to get more factual outputs from the model. So there's a combination of technologies that we're putting together to kind of reduce the hallucination issue.
Unknown: Sam, I'll ask you about the data, the training data. Obviously there's been, you know, maybe some people in this audience who may not be thrilled about some of the data that you guys have used to train some of your models not too far from here in Hollywood, people have not been thrilled. When you're considering now as walking through and going to work towards these next models,
Unknown: Thanks for listening.