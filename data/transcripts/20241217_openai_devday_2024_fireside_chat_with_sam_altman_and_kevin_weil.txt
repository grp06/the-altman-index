Unknown: I have the good fortune of getting to turn the amazing research that our research teams do into the products that you all use every day and the APIs that you all build on every day. I thought we'd start with some audience engagement here. So on the count of three, I wanna count to three, and I want you all to say, of of all the things that you saw launched here today, what's the first thing you're gonna integrate? It's the thing you're most excited to build on. Alright? You gotta do it. Alright? One two, three. Rebuild our new logo. okay. So
Sam Altman: It's obviously harder to say now, and so we we're trying to, like, stop real quickly, we use one for chatbots, two for reasoners, three for agents, four for innovators, and five for organizations, like, roughly. it, you know, very agent like, The the leap from that to something that can really increase the rate of new scientific discovery, which for me is like a very important part of having an AGI, you know, in this like kind of most people looking back in history won't agree when that milestone was hit, and will just realize it was a silly thing. Even the Turing test, which I thought always was this very clear milestone. You know, there was this fuzzy period. It kind of went whooshing by, and no one cared. But I I think the right framework is it's just this one exponential. That said, if we can make an AI system that is, like, materially better at all of open AI than doing at doing AI research, You know? Like, we want to we have this mission. We wanna, like, build safe AGI, figure out how share the benefits. If the answer is like, rack up GPUs, we'll do that. And right now, the answer is, again, really push on research. And I think you see this with o one. Like, that is a giant research breakthrough that we were attacking from many vectors over a long period of time that came together in this really powerful way. We have many more giant research breakthroughs to come. But the thing that I think is most special about OpenAI is that we really deeply care about research and we understand how to I think it's easy to copy something you know works. And, you know, I actually don't even mean that as a bad thing. Like, when people copy OpenAI, I'm like, great. The world gets more AI? That's wonderful. But to do something new for the first time, to like really do research in the true sense of it, which is not like, you know, let's barely get soda at this thing or like, let's tweak this. But like, let's go find the new paradigm and the one after that and the one after that, that is what motivates us. And I think the thing that is special about us as an org, besides the fact that we, you know, marry product and research and all of this other stuff together, is that we know how to run that kind of a culture that can go
Unknown: of how critical research is to OpenAI is that building product at OpenAI is fundamentally different than any other place that I have ever done it before. You know, normally, you have you have some sense of your your tech stack. You have some sense of what you have to work with, what capabilities computers have, and and then you're trying to build the best product. Right? You're figuring out who your users are and what problems they have and how you can help solve those problems for them. There is that at OpenAI, but also the state of, like, what computers can do just evolves every two months, three months, and suddenly computers have a new capability that they've never had in the history of the world, and we're trying to figure out how to build a great product and expose that for developers and our APIs and so on. And the you know, you you can't totally tell what's coming. They're coming through it's coming through the mist a little bit at you and gradually taking shape. It's fundamentally different than any other company I've ever worked at, and it's think Is that is that the thing that has most surprised you? Yes. Yeah. And it's interesting how even internally, we don't always have a sense. So you have like, okay. I think this capability is coming, but is it going to be, you know, 90% accurate or 99% sixty days in advance when you're gonna launch something. so be thinking. But next thing. Is so many in the alignment community are genuinely concerned that OpenAI is now only paying lip service to the to alignment. Can you reassure us? Yeah.
Sam Altman: I think it's true we have a different take on alignment than like maybe what people write about on whatever that like Internet form is. But we really do care a lot about building safe systems. We have an approach to do it that has been informed by our experience so far. capable models that get safer and safer over time. And you know, a couple of years ago, we didn't think the whole strawberry or the o one paradigm was gonna work in the way that it has worked, and that brought a whole new set of safety challenges, but also safety opportunities. And rather than kind of like plan from a theoretical once, as safe and robust to be able to put them in the world. And when we started OpenAI, if you asked me for the techniques that would have worked for us to be able to now deploy our current systems as generally accepted to be safe and robust, they would not have been the ones that think worrying about the sci fi
Unknown: When I was at Twitter back, I don't know, a hundred years ago now, Ev said something that stuck with me, which is no matter how many smart people you have inside your walls, there are way more smart people outside your walls. And so when we try and get our you know, it it it'd be one thing if we just said we're gonna try and figure out everything that could possibly go wrong within our walls, and it would be just us and the the red teamers that we can hire and so on. And we do that. We work really hard at that. But also launching iteratively and launching carefully and learning from the ways that that folks like you all use it, what can go right, what can go wrong, I think is a big way that we get these things right. I also
Sam Altman: think that as we head into this world of agents off doing things in the world, that is gonna become really, really important. There the as these systems get more complex and are acting over longer horizons, the pressure testing from the whole outside world, I really believe will be critical. Yeah. So we'll go actually
Unknown: set of models, o one in particular, and all of its successors are going to be what makes this possible because you finally have the ability to reason, to take hard problems, break them into simpler problems, and act on them. I mean, I think 2025 is gonna be the year that this really goes big.
Sam Altman: when you can ask, like, ChatGPT or some agent something, and it's not just like you get a kind of quick response or even you get fifteen seconds of thinking and o one gives you a nice piece of code back or whatever, But you can really give something a multi turn interaction with environments or other people or whatever and think for the equivalent of multiple days of human effort a really smart, really capable human and have stuff happen. We all say that. We're all like, oh, yeah. Agents are the next thing. This is coming. This is gonna be another thing. And we just talk about it like, okay. You know, it's like the next model in the evolution.
Unknown: Yeah. It's amazing. Somebody was talking about getting used to new capabilities and AI models and how quickly actually actually, think it was about Waymo. But they were talking about how the in the first You know? It's amazing how much your your sort of internal firmware updates developer platform great too because, you know, we'll experiment and we'll build some agentic things, of course. And, like, we've already got I I think just like we're we're just pushing the boundaries of what's possible today with you've got groups like Cognition doing amazing things and coding, like Harvey and CaseText. You've got Speak doing cool things with language translation. Like, we're beginning to see this stuff work, and I think it's really gonna start working as we as we continue to iterate these models. One of the very fun things for us about having this developer platform is just getting to, like, watch the unbelievable speed and creativity of people that are building these experiences. Like, developers
Sam Altman: and just many of us came from building on platforms. But the Safety and alignment. Like, if you are really going to give an agent the ability to start clicking around your computer, which you will, you you are going to have a very high bar for the robustness and the reliability and the alignment of that system. But this sort of agent safety and trust framework, But if we were fully OLO, didn't care about, like, safety and alignment at all, And and so starting on the conservative side, And that's like part of our approach to safety.
Unknown: Totally agree. What's the next big challenge for a startup that's using AI as a core feature? is trying to find the kind of the frontier. You you wanna be building these AI models are evolving so rapidly. And if you're building for something that the AI model does well today, it'll work well today, but it's gonna feel it's gonna feel old tomorrow. that use case that just barely didn't work, you're gonna be you're gonna be the first to do it, and it's gonna be amazing. But figuring out that boundary is really hard.
Sam Altman: makes a startup, and that is almost never true. No matter how cool a new technology or a new sort of like tech tidal wave is, it doesn't or accumulated advantage over time. And we hear from a lot of startups, And I think a mistake is that in the unbelievable excitement and updraft of AI, people are very tempted to forget that.
Unknown: This is a this is an interesting one. The mode of voice is like tapping directly into the human API. How do you ensure ethical use of such a powerful tool with obvious abilities of manipulation? Manipulation?
Sam Altman: by an AI in that when I was playing with the first beta of it, like, I still say, like, please to chat GBT, but in voice mode, I, like, couldn't not kind of use the normal niceties. I was so convinced, oh, it might be a real per like, which is as these systems become more and more capable and as we try to make them as natural as possible to interact with, like I think vaguely socially manipulative stuff we could do. But then there's these other things that are just not nearly as clear cut.
Unknown: Alright. Back to brass tacks. Sam, when's o one gonna support function tools? complete thing that is, you know, in line with that that has all the abilities that every other model that we've launched has.
Sam Altman: The model is gonna get so much better so fast. Like, we are so early.
Unknown: They have these sort of sonorant voices. Did you guys see somebody on Twitter was saying, like, the cool thing to do is take your LinkedIn and put it you know, PDF it and give it to these give it to NotebookLM, I'll say mine is I think Anthropic did a really good job on projects. Yeah. It's kind of a a different take on what we did with GPTs. GPTs are a little bit more long lived. It's something you build and can use over and over again. Projects are kind of the same idea, but, like, more temporary, meant to be kind of stood up, used for a while, and then you can move on. And that that the different mental model makes a difference. Alright. We're getting close to audience questions, so be thinking of what you wanna ask. But it's a real balance too as we as we, you know, we we support over 200,000,000 people every week on ChatGPT. You also can't say, no. It's cool. Like, deal with this bug for three months or this issue. We've got something really cool coming. You've gotta solve for the needs of today. And there are some really interesting product problems. I mean, you think about I'm I'm speaking to a group of people who know AI really well. Think of all the people in the world who have never used any of these products, and that is the vast majority of the world still. You're basically giving them a text interface, And on the other side of the text interface is this, like, alien intelligence that's constantly evolving that they've never seen or interacted with, and you're trying to teach them all of the crazy things that you can actually do with, all the ways it can help, can integrate into your life, can solve problems for you. And so it's a real challenge figuring out how you I mean, we all have a 100 different ways that we use ChatGPT and AI tools in general. But teaching people what those can be and then bringing them along as the model changes month by month by month and suddenly gains these capabilities way faster than we as humans gain new capabilities, it's it's a really interesting set of problems. And I I know it's one that you all solve in in different ways as well.
Sam Altman: So one of the challenges that we face is, like, we know how to go do this thing that we think will be, like, at least probably smarter than all of us in, like, a a broad array of tasks. And yet we have to, like, still, like, fix the bugs and do the hey, how are you problem. It has been definitely a evolution for us to not just be entirely research focused and learn that we do have to fix all those bugs and make this super usable. And I think we've gotten better at balancing that. But still,
Unknown: Yeah. And I think it's a core part of the philosophy, and you do a good job pushing us to always well, basically incorporate the frontier of intelligence into our products, both in the APIs and into our first party products Because it's it's easy to kinda stick to the thing you know, the thing that works well, but you're always pushing us to, like, get the frontier in even if it only kinda works because it's gonna work really well soon. So I always find that a really helpful push. Cool. Let's go to audience questions. I don't know who's got the mic. Alright. We got a mic.
Sam Altman: people use them for whatever they can and try to sort of like build new ways to the way we have figured out every step along our way of how to to push on next, what we can productize, what what what like, what the models are really good at is by internal dogfooding.
Unknown: that that do a ton above answering external questions and fielding internal people's questions on Slack and so on. And our customer success our customer service team is probably, I don't know, 20% the size it might otherwise need to be because of it. Very I know Matt Knight and our security team has talked extensively about all the different ways we use models internally for to automate a bunch of security things and, you know, take what used to be a manual process where you might not have the number of humans to even, like, look at everything incoming and have models taking you know, separating signal from noise and highlighting to humans what they need to go look at, things like that. So I think internally, there are tons of examples, and people maybe underestimate the you all probably will not be surprised by this, but a lot of folks that I talk to are. Extent to which it's not just using a model in a place, it's actually about using, like, chains of models that are good at doing different things and connecting them all together to get one end to end process that is very good at the thing you're doing, even if the individual models have, you know, flaws and make mistakes. Yeah. I think I actually think you don't wanna wait until AGI. You wanna start now. Right? Because there's a learning process, and there's a lot of good that we can do with our current model. So we've we've announced a handful of partnerships with government agencies. Some states, I think Minnesota and some others, Pennsylvania. Also, with organizations like USAID. It's actually a huge priority of ours to be able to help governments around the world get acclimated, get benefit from the technology. I mean, of all places, government feels like somewhere where you can automate a bunch of workflows and make things more efficient, reduce drudgery, and so on. So I think there's a huge amount of good we can do now. And if we do that now, it just accrues over the long run as the models get better and we get closer to AGI.
Sam Altman: served. I do hope we do something at some point, but we wanna find something that we feel like if we don't do it, the world will just be missing this thing, not make, like, another thing that's, like, a tiny bit better on benchmarks
Unknown: It actually, it's a there are things obviously that we can't have it sing. Right? You can't have it sing copyrighted songs. We don't have the licenses, etcetera. And then there are things that it can sing, and you could have it sing happy birthday, and that would be just fine. Right? And we want that too. It's a matter of once you basically, it's easier with finite time to say no and then build it in, but it's nuanced to get it right. And we you know, there are penalties to getting these kinds of things wrong. So it's really just where we are now. We really want the models to sing too.
Sam Altman: That obviously takes some research breakthroughs,
Unknown: I I'll give you an example. I was in Seoul and and Tokyo a few weeks ago, and I was in a number of conversations with folks that with whom I didn't have a common language and we didn't have a translator around. Before, we would not have been able and it was amazing. And you think about the impact that that can have, not just for business, but think about travel and tourism and people's willingness to go places where they might not have a word of the language. You can have these really amazing impacts. But inside ChatGPT, that was still a thing that I had to like, ChatGPT is not optimized for that. Right? Like, you want this sort of digital, you know, universal translator in your pocket that just knows that what you want it to do is translate. But I think there's we struggle with the with trying to build an application that can do lots of things for lots of people. And that that keeps up, like we've been talking about a few times, it keeps up with the the pace of change and with the capabilities, you know, agentic capabilities and so on. I think there's also a huge opportunity for the creativity of an audience like this to come in and, like, solve problems that we're not thinking of, that we don't have the expertise to do. And, ultimately, the world is a much better place if we get more AI to more people, and it's why we are so proud to serve all of you.