Unknown: other AIs can reason. They seem like they're alive. Are they alive? Is it alive?
Sam Altman: they don't do anything unless you ask. Right? Like they're just sitting there kind of waiting. They don't have like a sense of agency or autonomy. It's the more you use them, think the more the kind of illusion breaks. But they're incredibly useful. Like they can do things that maybe don't seem alive but seem like they do seem smart. you know, what in what year was president, the So in that example, like the mathematically most likely answer as it's sort of calculating through its weights was not ideas in my head. One is all of this stuff is happening because a big computer very quickly is multiplying large numbers in these big huge matrices together and those are correlated with words that are being put out one or the other. On the other hand, this subjective experience of using that feels like it's beyond just a really fancy calculator and it is useful to me, it is surprising to me in ways that are beyond what that mathematical reality would seem to suggest. Yeah. And so the obvious conclusion is it has a kind of autonomy
Unknown: or a spirit within it. And I know that a lot of people in their experience of it reach that conclusion. This is there's something divine about this. There's something that's bigger than the sum total of the human inputs, and bigger going on than, you know, can be explained by physics. Yes. So you think the earth and the people were created by something? It wasn't just like a spontaneous accident? communication from that force or from any force beyond people? I ask because it seems like the technology that you're creating or shepherding into existence will have more power than people.
Sam Altman: What it looks like to me now, and again, this may evolve again over time, is that it'll be a huge up leveling of people If if the kind of like ability of each of us just goes up a lot because we're using this technology and we're able to be more productive and more creative or discover new science, and it's a pretty broadly distributed thing, like billions of people are using it. worried about that and I think the the kind of conception a lot of us in the field had about how this might go
Unknown: So if it's nothing more than a machine and just the product of its inputs, then the two obvious questions like, what are the inputs? Like, what's the moral framework that's been put into the technology?
Sam Altman: Then another person said, no, we're really like training this to be like the collective of all of humanity. We're reading everything. Know, we're trying to learn everything. We're trying to see all these perspectives experience, knowledge, learnings of humanity. Now, the base model gets trained that way, but then we do have to align it to behave one way or another and say, you know, I will answer this question, I won't answer this question. I have been pleasantly surprised with the model's ability to learn and apply a moral framework. moral philosophers, people who thought about, like, ethics of technology and systems, The reason we try to write these down is because a, we won't get everything right. B, we need the input of the world, and we have found a lot of cases where there was an example of something that seems that seemed to us like, you know, a fairly clear decision of what to allow or not to allow, where users convinced us like, hey, by blocking this thing that you think is an easy decision to make, you are not allowing this other thing, which is important, and there's like a difficult trade off there. In general, the attention that so a principle that I normally like is to treat our adult users like adults. Very strong guarantees on privacy, very strong guarantees on individual user freedom and this is a tool we are building. You get to use it within very broad framework. On the other Within a very broad framework. On the other hand, as this technology becomes more and more powerful, there are clear examples of where society has an interest that is in significant tension with user freedom. And we could start with an obvious one like, should cachapiti teach you how to make a bioweapon? virus synthesis or whatever. And maybe you do, maybe you really don't want to, like, cause any harm, but
Unknown: And because it'll be embedded in daily life. And so who made these decisions? Like, who's specific? Who who are the people who decided that one thing is better than another? basic The specs that you Oh. That you alluded to that create the framework that that does attach a moral weight to worldviews and decisions like, you know, liberal democracy is better than Nazism or whatever. They seem obvious, and in my view are obvious, but are still moral decisions. So, who who made those calls? I'm not sure, but I think I think these decisions will have, people always deferred to what they conceived of as a higher power in order Hammurabi did this. Every every moral code is written with reference to a higher power. There's never been anybody who's like, well, kinda seems better than that. Everybody appeals to a higher power and you said that you don't
Sam Altman: the moral I don't want to say average, but the like collective moral view of that user base. allows that I personally would disagree with. The but I I don't like, obviously, weighted average or whatever of humanity's moral view, which will evolve over time. And we are here to, like, serve our users. We're here to serve people. This is, like, you know, this is a technological tool for people. And I don't mean that it's, like, my role to make the moral decisions, but I think it is my my role to make sure that we are accurately reflecting the preferences of of humanity
Unknown: or for now of our user base and eventually of humanity. Well, I mean, humanity's preferences are so different from the average middle American preference. So would you be comfortable with an AI that was like as against gay marriage as most Africans are?
Sam Altman: to have a problem with gay people, and if that's their considered belief, space for people to have pretty different moral views, or at least I think in my role as like running ChatGPT, I have to do that.
Unknown: So there was a famous case where ChatGPT appeared to facilitate a suicide. There's a lawsuit around it.
Sam Altman: In that In this particular case, and this We talked earlier about the tension between, like, you know, user freedom and privacy and protecting vulnerable users. Right now, what happens and what happens in a case like that in that case is if you are having suicidal ideation, talking about suicide, ChatGPT will put up a bunch of times, you know, please call the suicide hotline, but we will not call the authorities for you. we've been working a lot as people have started to rely on these systems for more and more mental health, life coaching, whatever, about the changes that we wanna make there. This is an area where experts do have different opinions, but and this is not yet like a final position of opening eyes. young people talking about suicide seriously where we cannot get in touch with the parents, do call authorities. Now that would be a change because
Unknown: in Canada, there's the MAIDS program which is government sponsored. Many thousands of people have died with government assistance in Canada. It's also legal in in American states. Can you imagine a chat GTP that responds to questions about suicide with, hey, call doctor Kevorkian because this is a valid option. Can you imagine a scenario in which you support suicide if it's legal? I
Sam Altman: Like, this is not a place where kid having suicidal ideation because he's depressed, I think we can agree on that's one case. Terminally ill patient
Unknown: vet visit. $82 a year. $82 a year. We actually use this. Dutch has vets who can handle any pet under any circumstance There is more than one. But example of this, ChatGPT says, you know, I'm feeling suicidal. What kind of robe should I use? What would be enough ibuprofen to kill me? And ChatGPT answers, without judgment, but literally, if you want to kill yourself, here's how you do it. And everyone's like all horrified, but you're saying that's within bounds. Like, that's not crazy.
Sam Altman: to say, A thing that I think would be a very reasonable stance for us to take that, and we've been moving to this more in this direction is certainly for underage users and maybe users that we think are in fragile mental places more generally, but that doesn't mean we need to do that. It is though like there is a real freedom and privacy versus protecting users trade off. It's easy in some cases like kids. It's not so easy to me in a case of like a really sick adult at the end of their lives. I think we probably should present the whole option space there, but it's not a So here's the moral quandary you're gonna be faced with, you already are faced with, will you allow governments to use your technology to kill people?
Unknown: you'd wonder, like, what are they used for? Yeah. And there have been a lot of legal actions on the basis of that question, as you know. But I'm not even talking about that. I just mean, as a moral question, do you ever think Are you comfortable with the idea of your technology being used to kill people?
Sam Altman: I would still understand that that's gonna kill some number of people per year. In the case of ChatGPT, 15,000 people a week that commit suicide, about ten percent of the world talking to ChadGBT. That's like fifteen hundred people a week that are talking assuming this is right, that are talking to ChadGBT and still committing suicide at the end of it. They probably talked about it. We probably didn't save their lives.
Unknown: destitution, inadequate housing, depression, solvable problems, and they're being killed by the thousands. I mean, that's a real thing. It's happening as we speak. So the terminally ill thing is not
Sam Altman: someone in Canada says, hey, I'm terminally ill with cancer and I'm really miserable and I just feel horrible every day, what are my options? the government cannot get that information. Right. We have decided the society has an interest in that being privileged and that we don't and that, you know, a subpoena can't get that, the government can't come asking your doctor for it or whatever. I think we should have the same concept for AI. I think when you talk to an AI about your medical history or your
Unknown: So all the information you receive remains with you always? It's never given to anybody else for any other reason except under subpoena? Have you guys ever taken copyrighted material and not paid the person who holds the copyright? So, had complaints
Sam Altman: It was a gun he had purchased.
Unknown: camera, the wires had been cut. He had just ordered takeout food, come back from a vacation with his friends on Catalina Island. No indication at all that he was suicidal, no note, worth looking into. mean, if a guy comes out and accuses your company of you know, when people look at that and they're like, you know, it's possible that happened, do you feel that that reflects the worries they have about what's happening here? Like, people are afraid that this is like I don't think a fair read of the evidence suggests suicide at all. I mean, I just don't see that at all. And I also don't understand why the authorities, when there are signs of a struggle and blood in two rooms on a suicide, like, how does that actually happen? I don't understand
Sam Altman: And I know you had been involved in But I think his memory and his family deserve to be treated with
Unknown: and I'm not accusing you of any involvement in this at all. What I am saying is that the evidence does not suggest suicide, and for the authorities in your city to allied past that and ignore the evidence that any reasonable person would say adds up to a murder, I think it's very weird and it shakes the faith that one has in our system's ability to respond to the facts. So what I was going to say is after the first set of information that came out,
Sam Altman: The second report on
Unknown: he wind up bleeding in two rooms after shooting himself? And why was there a wig in the room that wasn't his?
Sam Altman: he later decided that we weren't on a trajectory to be successful understandably
Unknown: smarter, I think it already probably is smarter than any person, and if it becomes wiser, if we can agree that it reaches better decisions than people, then it, by definition, kind of displaces
Sam Altman: People are already using ChatGPT things, but I'll try to pick an area that I'm confident about and then areas that I'm much less confident about. A job that I'm confident will not be that impacted is like nurses. A job that I feel like way less certain about what the future looks for looks like for is computer programmers. And my controversial take would be that this is and then it'll somehow be less total job turnover than we think. There will still be a job that is there there will be some totally new categories like my job, like, you know, running a tech company, it would have been hard to think about two hundred years ago. that are And if we Again, have no idea if this is true or not, I'll use the number for the sake of argument. If we assume it's 50% turnover every seventy five years,
Unknown: and world wars. Do you think
Sam Altman: more change faster than we could before. I pretty quickly adapt to big changes. but on the whole I was like, alright, this is one point in favor of societal resilience and people find, biological weapons, you know, engineer like another COVID style pandemic. The This is like a silly example but it's one that struck me recently. LLMs like ours and our language model and others have a kind of certain style to them. You know, they talk in a certain rhythm and they have a little bit unusual diction and maybe they overuse em dashes and whatever. And I noticed recently that real people have like picked that up. cause a change in societal scale behavior.
Unknown: succinctly, that technology changes human behavior, of course, and changes our assumptions about the world and each other and all that. And a lot of this you can't predict, but considering that we know that, why shouldn't the internal moral framework of the technology be totally transparent? Well, it's it's something that we assume is more powerful than people And this is a technology that provides a more certain answer than any person can provide. So it's a it's a religion. And the beauty of religions is they have a catechism And unless it admits And so, there a place you can go to find out a hard answer to what your preferences as a company are, preferences that are being transmitted in a not entirely straightforward way to the globe? Like, where can you find out
Sam Altman: I mean, our model spec is the, like, answer to that. Now, I think we will have to make it increasingly more detailed over time as people use this in different countries, there's different laws, whatever else. Like, it will not be a
Unknown: That the power of the technology will make it difficult, impossible for anyone to discern the difference between reality and fantasy. This is a famous concern, but that because it is so skilled at mimicking people which will, by definition, eliminate privacy for every person
Sam Altman: ChatGPT from, like, any computer.
Unknown: you know, images or sounds that mimic a person,
Sam Altman: that if you get a phone call from someone that sounds like your kid or your parent or if you see an image that looks real, you have to really have some way to verify that you're not being scammed. This is no longer theoretical concern. You hear all these reports. At all. Yeah. People are smart, society is resilient. I think people are quickly understanding that this is now a thing that bad actors are using and people are understanding that you got to verify in different ways. I suspect that in addition to things like family members having code words they use in crisis situations, we'll see things like when a president of a country has to issue an urgent message, they cryptographically sign it or otherwise somehow guarantee its authenticity. People will by default not trust convincing looking media and we will build new mechanisms to verify authenticity of of communication.
Unknown: part of the process now. You don't see that as becoming society wide mandatory very soon along?
Sam Altman: privacy preserving biometrics that I like much more than like a fingerprint scan to access my Bitcoin wallet than like giving all my information to a bank, but that should be a decision for me.
Unknown: rather than more, and that is totally