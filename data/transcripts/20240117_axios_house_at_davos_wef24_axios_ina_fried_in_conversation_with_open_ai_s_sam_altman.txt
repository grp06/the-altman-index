Unknown: does 2024 Sam Altman know that 2023
Sam Altman: And so I think one piece of knowledge is that this technology, even with all of its current limitations, is far more useful than we thought and can integrate into our lives in a much more valuable way than we thought. And so now that we know that, as we think about launching the next much better models, and urgent problems and not letting the important
Unknown: And, indeed, do you think you're going to behave differently this year as a result of what you learned? You mentioned the technology. Technology clearly is making you off faster. I've been covering Silicon Valley in tech for twenty five years. I've never seen a technology that has advanced as quickly as AI is advancing. Usually, even the dawn of the internet, e commerce, the smartphone, those took years. You had early adopters, then you had mid adopters. This, And you said yesterday that even you can really only concretely know what's gonna happen a few steps ahead. But let's talk about those few steps. Talk about that bit that you can see. What can we expect AI to do this year that it couldn't do last year?
Sam Altman: So GPT-two The thing that or whatever we call it and the thing that matters most is not that it can have this new modality or it can solve this new problem. It is the generalized intelligence keeps increasing. And we find new ways to put that into a product. We find new ways to use it. But that is the higher order bit. I think that dominates everything else in the importance, is that the overall capability of the model, its overall intelligence, its ability to do longer, more complex problems, more accurately, more of them, that is increasing across the board. And that, to me, is one of the few things that make this totally different from any previous technology. Obviously, it'll be the multiplicative factor of both. But if history is a guide for us, it is the more advanced model that is the most important step forward. So I think I would expect that to be the biggest gain again. But as it does get integrated into people's workflows in all these new and different ways, the productization is critical. We started off as a research company. Now we understand that we have to treat both research and product as both critical. And it's the fact that we can do both of those things that I think makes us a special company.
Unknown: And what do you think concretely we'll be able to do that we haven't been able to do? What are some of the limitations that you think this will be the year we overcome these? Not just you, Sam Altman, and OpenAI, but kind of the industry. What are some of the things that are on the cusp of being solved, whether it's hallucinations because of better grounding, whether it's merging
Sam Altman: AI with company data or specific data sets? So that's a good one. Think access to specific data and the ability to use specific data the way you use the computers to talk to it. The operating system of a computer, in some sense, is close to this idea that you're working inside of a chat experience or an AI experience. And you get to your computer, and rather than go open a browser and type in Gmail and look through your emails or whatever, you might just say, what were my most important emails today? Can you respond to all of those? I'll see these. Go find this thing in there and send it there. So we're heading towards this new way to do knowledge work. I think with every great technological revolution, we do get an opportunity to use a computer in a new way. And we won't get all the way there this year, but I do think we'll see people do more and more of their workflow
Unknown: inside of a language model, for lack of a better. I was going to say, do you think and I imagine this seems reasonably likely to me. Last year at Davos, everyone was playing around with ChatGPT. All the CEOs realized it could create a buzzword laden speech just as well as they can. This year, they're all trying to figure out how they do it with their business. But one thing, it's still an app that people open some of the time. By the end of the year, do you think people will be spending hours a day within some sort of AI assistant? beyond the robots taking over science fiction stuff, what are some of the things that absolutely will come that we'll want but are more than a year away?
Sam Altman: make new scientific discoveries increasingly autonomously.
Unknown: And I want to talk some about human creation and the human creations that have gone into training these systems. Obviously, a lot of discussion around copyright and intellectual property. You've signed a bunch of deals, OpenAI, with publishers like the AP, Axel Springer. If what you've done to date of training on the open web is fine,
Sam Altman: why do you even need to sign these kinds of deals to license content? What we're interested in is not data for training, which we could talk about later. There's some value to that. But what we really want is when people are using ChatGPT and ask what happened today at Davos, train on your content. But New York Times content has been copied and inappropriately So to be able to ensure good neighbor, one of the things that we think is important to happen is no matter what we train on and again, we'll try to respect it as much as we can, but the internet is a weird place. No matter what we train on, we don't want to regurgitate someone's copyrighted content. no one in this room has read 2,000 biology textbooks. What you want is a small amount of super high quality data and to think really hard. So huge amounts of data are going to continue to be important to us. There's lots of good ways we can get that from clearly open domain data. And then increasingly, I think the models are going to think harder about a smaller amount of known high quality data.
Unknown: And if people don't want us to train on their data, no problem. Do you have a model in the labs that's trained only on stuff that you know you have a right to? We'll move on to another easy topic, democracy. OpenAI announced a variety of efforts just in this past week about securing democracy, working with other groups to help secure democracy, your own efforts. With so many elections around the world this year, including, of course, the US presidential election, how confident are you that OpenAI's technology
Sam Altman: But we really just want to have a very tight feedback loop, careful monitoring, be willing to make changes quickly if we notice anything, and work with the broad ecosystem of partners to do the best that we can. But I'm nervous about this, and I think it's good that we're nervous about this. And still, there's only a handful of people whose job at OpenAI
Unknown: is really dedicated to election stuff. Meta, TikTok, they have hundreds of people. They probably have more people
Sam Altman: There were parts of the Department of Defense that had, I think, super legitimate, super good use cases for our models and a blanket saying, anyone whose address ends in dot mil can't use this, I think is bad. I'm a very proud citizen of The US. I'm a huge supporter of liberal democracy continuing to do well. We don't want our models being used to make kill decisions, of course. But there's a lot of other stuff that the military does that's quite important.
Unknown: And you've got some great use cases that you talked about, helping prevent suicide by veterans. Obviously, if someone giving a speech at West Point wants to translate it into Swedish, that's probably not a high risk use. Then you have stuff at the other end, developing a nuclear weapon clearly against your policies, but there's so much in the middle. There's so much that is not building a bomb. It's not destroying property, which is another one you have that's allowed that's not allowed rather, but that could be really harmful. I mean, these AI engines are incredibly capable persuasion engines. How do you draw the line of what a military can and can't do? And do you think that's the right place? One of the things that we believe
Sam Altman: We believe in iterative deployment a lot for the obvious reason, which is that people need time to gradually update and think and figure out what the rules should be. But there's another part, which is the institutions and the world and society shift and reshape in response to this. So there will be a lot of things that we'll have to start slowly on and iterate as we go. And there will be a lot of middle cases. But we do want to support the US government and other governments, too. And
Unknown: One of the interesting things about this technology I was having a conversation in the Congress Hall with one of your fellow pioneers in the field is the idea you know, when it we've had past platforms. didn't really come with a built in set of values. The smartphone didn't really come with a set of values. Inherent in these large language models and other generative AI systems, expand on? What questions will I say, Sorry, I can't answer that? One of the interesting things is right now, we have different systems in The US and China, but we kind of have the idea, and I think OpenAI's Do you think we'll be able to have one GPT, add your number to it, that really satisfies that or when you look at a country like one of the countries in The Middle East, are they going to be comfortable with the kind of system you've built?
Sam Altman: their value, preferences, relative trade offs, the nuance of that, and then doing something that actually represents all of the people that want to use this model. permissions possibilities are. What can you get a system to say? What can it never say? How much room do you have to customize it for yourself? And we'll see this at many levels. So there will be versions by countries, different cultures, individual people. And I think the answer there is going to be to allow quite a lot of individual customization,
Unknown: And does that mean OpenAI is comfortable to go into their human rights, but there's a lot of countries that don't, for example, respect LGBTQ rights. If country x said, in order to operate in our country, you have to change the way OpenAI's models answer questions about that, is that something you're willing to do? I
Sam Altman: again, in this idea of a broad, what the absolute constraints are, if the country said all gay people should be killed on-site, then no. We would say this is like, I hope anything that the the people of the world would come to as a principle would say, that is well out of bounds. But there are probably other things that I don't personally agree with that a different culture might about gay people that the model should still be able to say. And I think it
Unknown: models might answer a question differently in different countries based on their values. I would say more than that, it'll be for different users
Sam Altman: with different values, which
Unknown: Will you it's come before. Google was that there's all this stuff that OpenAI is doing. Why are you off raising money for startups, building other things? Why aren't you spending 100% of your time on these big issues that are confronting OpenAI? Why are you continuing to raise money for things that aren't OpenAI and invest?
Sam Altman: They are open AI. I think there was this misrepresentation, not hard to guess by who, but that I was off in The Middle East raising money for this chip effort, and then it was somehow like a SAM project. It was an open AI project that the board had decided was a clear strategic priority, and not a separate thing. well, one's now gotten I wouldn't do another round there because that's gotten way too close to OpenAI. But in general, if there's a startup that I supported and they're raising more money, I try to continue to support. But
Unknown: that these models did arrive when they did because, again, the rate of change is so fast if we don't start getting our heads around it. That was our thought. That
Sam Altman: is the whole reason we have the strategy of iterative deployment, and I
Unknown: Another question that is totally on the minds of everyone I'm talking to here. So again, last year the CEOs were like, Oh my god, ChatGPT. This year, they're much more, How am I going to incorporate generative AI into what I do, into everything I do? Where do I start? What are some of the things you tell
Sam Altman: both the companies that work with open AI, what would your advice be to the C suite folks who are here trying to get their heads around AI? One thing that I think gets missed a lot, so I'll try to say the less obvious thing, is using this for internal productivity at a company is a huge deal. Everyone's focused on how do I integrate this into my products and services, and that's all good. But I think, how can I make my internal workflow more efficient? How can I let my software developers get access to a fine tuned model of GPT-four on our own code base? It requires a new way of thinking, but I think that's easy, easy winnings for everybody.
Unknown: Lastly, what aren't we talking enough about? What do you wish
Sam Altman: I think the infrastructure investments that the world is going to have to make to deliver AI at the scale that people want it.
Unknown: I'm going to try and end our livestream.