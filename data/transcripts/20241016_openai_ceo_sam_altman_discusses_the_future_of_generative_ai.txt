Unknown: especially Teresa Lopez for making this happen. There's a lot that goes into this, and your team is fantastic. And then here at the university, Mike Drake and Emily Dickman from engineering and Ali Levine from the investments office, along with a bunch of other people, did a lot to make today happen. meet with exceptional people and try to find ways to collaborate and to see where it goes basically. And the other part of why I left my job is exactly this, which is to find ways to bring those people to the university and see if there are things that can come back the other direction and And I had a speed round at the end and I'm just gonna do one of the speed round questions right now.
Sam Altman: can we use this thing that we've created, and on top of it, can we teach models to reason? it would be a very significant step forward and in some sense is, you know, was the next And level two, which is about reasoning. I think this is the first time we've gotten there. It'll get rapidly better from here,
Unknown: it really caught fire quickly. And I think it maybe caught you a little bit by surprise at how what the uptake was. So I'm just trying to connect a couple dots here in terms of where we are with with this launch and we'll see where it goes. And you you know that it's a big deal or you believe it's a big deal. a comment is, well, how could you not have known that two was a big deal? It there's magic. And so is there something about when you're doing work on something that you you're you're focused on kind of metrics and development that takes you away from seeing the impact?
Sam Altman: put out ChatGPT with 3.5 11/30/2022, and we had finished training GPT four August 2, I believe, of 2022.
Unknown: And then just sort of bouncing back to strawberry, what what are the thing specific things that you see that can be done with this that are maybe most notable or most important in your mind?
Sam Altman: you know, been staring at this every day for the last year
Unknown: you know, whether it's recursive self improvement or open endedness or agentic AI, you know, there's ways of kind of getting there. Is this
Sam Altman: it's within grasp. Yeah.
Unknown: What does this mean for reinforcement learning and human input? So RHLF
Sam Altman: o one really is like all about reinforcement learning.
Unknown: Maybe we could just go back a little bit. What does what does AGI mean?
Sam Altman: and some people mean that it's like the legitimate recursively self improving super intelligence. I would love to banish the word because I think it's become so overloaded with different meanings. most people would say, absolutely not. There's no way. Can't keep going like this. and every year from 2019 to a long time in the future is gonna look like just breathtaking forward progress.
Unknown: you know, And you've moved to, in this description, as an evolutionary process towards something that is, you know, defined by kind of functionality in important ways like reasoning and ability to take steps and so forth. the the the thing that I keep stumbling on or coming to is this concept of abstraction. So LLMs are based on language which are abstractions of something, you know, the real world. a way of thinking of of AGI, I think, could be, well, if you're able to do this this magic without having it having it work on an abstraction but do the abstraction itself, is there something that you could envision where you say this could be an event? awarded that was based on something generated by an AI? as we look at technological developments and as their
Sam Altman: sort of the story of human history is that we build better tools and then people do even more amazing stuff with them and they themselves,
Unknown: So in getting ready for today, I went back and watched some older videos or interviews that you did. You did one last year with Patrick Collison, cofounder of Stripe. And one of the things you expressed frustration in was that there is a dearth now of 20 year old founders. And is is this the unlock that now we'll start seeing the 20 year old super founders? I think so. sticking on the, you know, the topic of people and getting people to do highly ambitious projects or encouraging or facilitating highly ambitious projects. How does that work? So you were you led Y Combinator, which is the world's best foremost incubator not incubator, but But these really big ideas and these transformative technologies don't come along on a schedule. And how do you think about I don't know if it's stockpiling people, granting young people tenure before, you know, preeminent or or something so that these these exceptional people
Sam Altman: The thing that eventually it's gonna take a long time. It's can you get enough really talented people together and excited and like committed to work super hard and kind of push in the same direction. you know the like two thousandth copy of the same idea, that's like less exciting. And so I think it's worth keeping in mind that although the activation energy is maybe slightly harder to go after something really ambitious, doing a startup is gonna be super hard and miserable no matter what, and you may as well take the tailwind of the kind of quest that people wanna join and work on for a long time.
Unknown: And it can be lonely. Right? Because as you said, the things well, the things you said are most worthwhile to work on are things that
Sam Altman: we released Chateappity, everybody cared. But for those first four years when no one cared, we all just felt like we were the sane ones and the rest of the world was crazy.
Unknown: I don't want to spend too much time on this next topic because because you said too many people tweet about it and not enough people do work on it, is around safety. I'm more reminded of an Elvis Presley line from 1968. a thing that is also hard about what you've done with OpenAI, and I think with other projects as well, and this relates to regulation or governance by governing bodies, is that, I think you said, a research organization might do too little. A private enterprise might do too much. And the government might do too little and then too much. But they all, you know, sort of exist
Sam Altman: and what it's gonna mean to like let your autonomous agent be off like clicking around the web with all of your passwords and access to all your stuff and what you're gonna need to trust that system, it's not like separable from the development of the technology anymore and also it is going to be just like a limiter on how we can deploy these systems even though it's not about like AI safety in the traditional sense that many researchers who say they work on it might. Like, this is systems this is like safety systems engineering or something like that. policy and like an industry that does reasonable things, regulators that do reasonable things, people that use these systems in reasonable ways.
Unknown: first get trust, whether it's UCM Altman, OpenAI, or, you know, where where how how do you think about generating trust, especially as things scale?
Sam Altman: And when we first released the model, we were like, this is like pretty dangerous. It says these like clearly crazy things sometimes. It means users not gonna trust it at all or they're gonna trust it too much and I think a reminder here or like this is an example of the fact that humans
Unknown: wanna come back a little bit to just how and this does relate to trust because it's what's in the machine, what's in the black box. they're on the path to do more with less data. And a thing that's missing though is that there are low context languages. my family's Hungarian, so not a lot of Hungarian content out there. Kurdish, you know, which are not really incorporated. that are really not included in these language models. So is that important?
Sam Altman: We have a lot of partnerships with people to help us get low resource language or data that is not yet digitized into these models and we're enthusiastic to do a lot more,
Unknown: sort of feed into you took one of my speed round questions already. So
Sam Altman: That this really is just gonna be everywhere and part of everything. You all are the last generation that will grow up without expecting every product and service you use to be really smart. Like smarter than you in some sort of cognitive
Unknown: So these are from Retro, which is an aging company or anti aging or aging reversal company, This technology works. So we have a microphone in a non random way, and this is important. It's really important to me as a signal or an indication of who you are. There are a lot of people who signed up for tickets who didn't get a ticket. One of the students sent you an email and said, I have a question. And you said, it's a good question. And emailed me and said, can you get Maria Cecilia a seat? And so I think it's a good question. So I think I'd love for Maria Cecilia to be the first one to ask a question, but why it's important to to me and why I think it should be important to all of you is that that kind of accessibility and curiosity is just remarkable. You have a pretty busy day job.
Sam Altman: I think fusion will work and be the cheapest form of energy on earth. It's very dangerous, I think, for our country not to invest very heavily in And I think The US if The US committed to a strategy of we are going to lead the world in abundant intelligence and abundant energy, that would be a wonderful thing to do. And I think what can happen over the next decade there is quite remarkable, and this is an area that governments can play a huge leadership role. There's a lot that's gotta happen. Like, the grid is atrocious. The permitting process in The US is, like, quite difficult. As you mentioned, other places can build energy much faster, but we should do a lot of it. we were doing research. You know, it was very unclear what to work on. We were trying to like pick these random things. We were just like stumbling in the forest and people would get this is very early on. People would get demotivated. People would like fight over very silly things, and it was just like, what are we doing here? Like, maybe we were too optimistic. and people are just kind of like off, get it drifting and getting demotivated, and you kinda like gotta get people feeling like reasonably optimistic and doing something. that was that was better. But that was a surprisingly hard thing to get through. handful of areas that I'm most excited about. I'd say like number one thing I'm excited about is what AI will do for scientific progress, but number two, tied for number two at least, is what I think this can do for education. We hear amazing stories all the time from students and from teachers who use this to sort of really change the way that they learn already I think it's really it is already changing how people learn and also how people like access and use information, and my hope is that like anybody starting school now gets a better education than the best education anyone got graduating today. Like, really think it is that level of the transformation, and it's amazing to watch what people are already doing with it. we do all sorts of pre launch testing which we kind of knew we would do in red teaming and safety systems that we build, but for a lot of things and building a really great monitoring system was something that I think I underestimated the need for at the time of launch and that was a very painful experience to go through, GPT three was like the best model in the world something that is in the way of people getting tremendous amount of value out of it for most use cases. There are still some areas where you would definitely still be quite foolish to rely on AI because of the hallucination problem, but it'll keep getting better, and also I think as we talked about earlier, people have really good taste and they understand limitations of tools and when to use it and when not to use it. there's definitely a lot we'll do to improve this in the coming months and years, but I think already it is Like, I I am a big believer that if you wanna, like, get good at something, you get good at it by just doing the thing. I think this is like a surprisingly underrated piece of life advice. You know, if you're, like, trying to do thing x, you go build up skills like a, b, and c so that like you think they'll apply to x later. But you should have just been like working on x as quickly as you could and like learning that and that's certainly what I would say for this. the similar to what a programmer does today, then like obviously you're in for a bad time. But if you think that the world is gonna continue to have near limitless demand for software what it should be and how to like work with a much higher level of programming than we do than we use today, but it will be really it will be really different. I remember hearing stories about like how when more advanced programming languages came out, all of the like OG programmers at the time would be like, oh, there's gonna be no jobs left because this new thing is just too easy and everybody's gonna be doing it. It didn't quite happen and I don't think it'll quite happen this time either, but what a programmer is capable of and the expectations of a programmer will be extremely different and the job will look very different than what it means to write code today. People learn a huge amount with a relatively small amount of training data, so I have no doubt we'll find way more data efficient methods, and I used to worry about this a lot and now I don't. Like I think The the issue that concerns me the most is just like I believe that society can adapt to almost any amount of change given a reasonable amount of time, but the tools that we and others are putting out into the world if things keep going like we think they're going to will require society to adapt at a rate that is more challenging and it's that it's the ethical implications of the rate of change that we're about to launch through that trouble me the most and but I would love to stop seeing the Terminator robots in the news articles. Many other things too.
Unknown: Well, Sam, it's it it really just means a lot that you're here today. I know that the the group here appreciates it quite a bit.