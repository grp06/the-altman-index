Sam Altman: lots of people have found ways to get value out of them, and also to understand their limitations. that's kinda okay. I think, you know, in some sense, the hardest part is when it's right 99.999 of the time and you let your guard down. I what it means to verify or understand what's going on is gonna be a little bit different than people think right now. I actually can't look in your brain and look at the 100,000,000,000,000 synapses and try to understand what's happening in each one and say, okay, I really understand the steps from conclude from a to b, and we can decide whether we think those are good steps. but we're still, like, very focused on each other. And I think we will do things with better tools. And I admit, it does feel different this time. General purpose cognition feels so close to what we all treasure about humanity that it does feel different. So of course, you know, there'll be kind of the human roles where you want another human. But even without that, I think, like, when I think about my job, I'm certainly not a great AI researcher. My my my role is to, like, you know, figure out what we're gonna do, think about that, and then, like, work with other people to coordinate and make it happen. And I think everyone's job will look a little bit more like that. We will all operate at a little bit higher of a level of abstraction. We will all have access to a lot more capability. And
Unknown: kind of showed up and every government technology minister from every country was amazing actually. I've never really seen anything like it. But everyone's there because we realize we are at this threshold moment, but we're not totally there yet. but we don't trust it quite yet. So we have to cross trust. We have to also turn to those regulators and human beings. It's really at a point where we're augmenting them. So I would probably not be surprised
Unknown: Right? So when my investors asked me, well, you know, when are you going to break the difference between people and technology? I'm saying I've been doing that every year. I literally serve clients and promise that every year I'm gonna find 10% more productivity before Gen AI. This is not new. Right? This is more powerful than prior versions of technology. It's more accessible. And you didn't hear things like responsible PC. Okay? That wasn't a concept, right? So because it's more powerful, we have to think differently. now. We introduced technology training for everyone whether you worked in the mail room, we still have one, in HR or with our clients. And they had to learn basic and past assessments, AI, cloud, data. You know, today, this in the next six months, we'll train 250,000 people on Gen AI and responsibility. This is basic digital literacy to run a company and to be good. And by the way, public service, massively going to improve social services by bringing this powerful technology. So it is first and foremost, we have to learn what it is so we can talk about it in a balanced way. And then absolutely, there are capabilities that don't exist today in most companies like responsible AI where if someone uses AI at Accenture, it's automatically routed, it's assessed for risk and then mitigations are pointed in and I can call someone and I know exactly where AI is used. That will be ubiquitous in twelve to twenty four months across responsible companies.
Unknown: because this is at such an emerging stage. You can the responses you get, which is often not justified. But I think, look, we can all do tremendously well out of AI. The UK is already doing well. London is the second largest hub for AI after San Francisco, and The UK has just become the world's third largest tech economy, trillion dollar tech economy after The United States and China. And if AI can shrink the time it takes to get that vaccine to to a month, then that is a massive step forward for humanity. But we need to do it in a light touch way because we've just got to be a bit humble. There's so much that we don't know and we need to understand the potential where this is going to lead us
Sam Altman: And, has been made to be safe and also how the different stakeholders in society have handled their negotiations about what safe means and what safe enough is. But I I have a lot of empathy for the the general nervousness and discomfort of the world towards companies like us and, you know, our our the other people doing similar things, which is like, what why is our future in their hands? I I mean, I believe and I think the world now believes that the the benefit here is so tremendous that we should go do this. But I think it is on us to figure out a way to get the input from society about how we're gonna make these decisions, not only about, you know, what what the values of the system are, but what the safety thresholds are and what kind of global coordination we need to ensure that stuff that happens in one country does not super negatively impact another to to show that picture. So not feeling the gravity of what the potential stakes are would be very bad. So I I like that people are nervous about it. We have our own nervousness, but we believe that we can manage through it. And the only way to do that is to put the technology in the hands of people, let society and the technology co evolve and sort of step by step with a very tight feedback loop and course correction,
Unknown: predictive and generative transactions this week. We're partnered with Sam and it's very exciting. It has a trust layer that lets our customers feel comfortable using their product. And I said to them, what do you really want? And I'm not sure what they want. Are they looking to replace people? Are they looking to now a test that's been going on six, nine months. It's amazing. And something incredible happened. badly wanted. Even the WAF, this app that you're all using is running on Einstein. So those predictions that you're getting, hey, because you like this AI panel, you should try that AI panel and you may look over here. That is our Einstein platform giving you those ideas. So this is really the power.
Sam Altman: any one particular training source that doesn't move the needle for us that much. What we want to do with the content owners like the New York Times and like deals that we have done with many other publishers and we'll do more over time is when a user says, hey, ChatGPT, what happened to Davos today? We would like to display content, link out, show brands of places like the New York Times or the Wall Street Journal or any other great publication and say, here's what happened today. Here's this real time information is these models will be able to take smaller amounts of higher quality data during their training process and think harder about it and learn more. we won't need the same massive amounts of training data. I'd love to find new models for you to get paid based off the success of that. So I think there's a great need for new economic models. I think the current conversation is focused a little bit at the wrong level. And I think what it means to train these models is in
Unknown: the gist of what I was trying to say. I think that when it comes to setting global AI standards, it's very important that they reflect liberal democratic values. But I think it is really important that we talk to countries like China because in the end I mean, think one of the most interesting things you know, we are incredibly lucky that people like Sam are helping to transform humanity's prospects for the future. I don't think anyone in this room thinks the world will be a better place if there wasn't AI. But we have choices now, and the choice we need to make is how to harness it so that it is a force for good. I actually think that means talking to countries like China because one of the ways it would be a force for bad is if it just became a tool in a new geostrategic superpower race with much of the energy put into weapons rather than things that could actually transform our daily lives. And those are choices we make. And one of the ways that you avoid that happening is by having a dialogue with countries like China over common ground. But I think we should, whilst being humble about not being able to predict the future, remember that we do have control over the laws, the regulations. We have the ability to shape this journey. And I think we should also look at history and say, you know, look at the industrial revolution, the computer revolution. Where those revolutions succeeded was where the benefits were spread evenly throughout society and not concentrated in small groups.
Unknown: sense of humility around this, make sure we're talking to each other. That's why Davos is so important. It's why the work we just did together with KPMG and PwC and the WEF on trust and digital trust and learning and reading.
Sam Altman: more strange things and having a higher level of preparation, more resilience, more time spent thinking about all of the strange ways things can go wrong. That's really important. The the the best thing I learned throughout this by far was about the strength of our team. But but I did also know, and I had seen it from watching the executive team and really the whole company do do stuff in that period of time. Like,