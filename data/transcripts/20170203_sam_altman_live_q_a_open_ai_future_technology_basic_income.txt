Sam Altman: but startup to us does not mean a software company. Startup means and so what we think about is we wanna fund any company that has some plausible shot at being a 10 plus billion dollar company. And that is such a strict rule that we don't allow ourselves any other rules, or we'd have nothing to fund. And so, we have to be willing to look at companies in any area. And if we're not an expert in that area, but we think it might be super valuable, then either one of the partners has to go become an expert or we have to hire a new partner. And I think this is not the only model, but it's a model that's worked really well for us. We don't we don't constrain ourselves to And through this process, we have decided to really pay attention to some new areas. Biotech, energy, and AI are are three that I have spent a lot of time focusing on. EdTech has been another area of expansion. More and more companies selling to government. Our first choice is always to support something by funding a start up. But if there is technology that we think is really important be done inside of a for profit company, then we do it this other way. And so, you know, on the should not side, we get something like AI. AI in particular, is something that I probably, like many people in this room, have been interested in since I was a little kid. I think, you know, many people that learn to program a computer for the first time realize that, you know, someday this is going to be really smart and and maybe be smarter than a human. And And at that time, it was sort of depressing because we all had fervent conviction that AI was gonna be a big deal and nothing was working. four years or three years, it's just been incredibly exciting to watch, and it has been absolutely transformative. We started a group called OpenAI. Elon Musk and me and the former CTO of Stripe and the former a guy from Google Brain. That group now has about 25 people. It is a nonprofit. The goal is to build general super AI for the benefit of humanity and but a widely distributed AI where each human has an agent that becomes part of them to some degree, and and we sort of try to just distribute this power and make all the humans better. And it's it's super exciting to work on. I think that will certainly be one area where everyone will have a superhuman personal assistant, where you can speak something in But, I think things are about about to get pretty crazy. We're going to we are not that far from a world where computers get better than humans at most non creative tasks. And the creative tasks, you know, painting, writing novels, I I think even that will come someday. I think we saw the first types of doctors become less good at computers with AI radiologists. You know, Foxconn now has robots that are so good that for better or for worse, I think for better, they just eliminated a bunch, a huge number of low skill, menial labor. And so, you can see a world where we have basically, effectively infinite resources and wealth. This was actually another mission statement considered for Y Combinator, which was to create infinite wealth. I believe we'll figure this out. I think humans have limitless demand and they will figure out new types of social structure and new ways to get status and fulfillment and happiness and new jobs to do. So I think this is an important question. I don't pretend to have the answer. We're doing a study also in YC research where we're going to try giving about a thousand people a basic income for five years, and we'll say, we're gonna fast forward to this world, let's imagine it, where we don't need everyone to work and we have enough resources where we can give everyone money and you can do what you want, and how will people spend their time, and how will they find happiness and fulfillment and social status and everything else that people care about? And I think it's gonna be really different. I think it's important to start studying this now because even if the jobs don't really change for ten or twenty or thirty years, human society does not adapt very quickly. And the sooner we can start seeing what happens and how people adapt, I think the better off we'll be. And we can hopefully learn how to make a future where people are are excited and engaged and happy. So it'll be interesting to see what goes on there, but I think because the jobs that it will eliminate first will be the worst jobs. But if it does that, it will do it because it can do it much less expensively than humans, and so the cost of the quality of a great life will come down. And we'll be in a world where we can choose, we'll have to choose, but we can choose to just be much better than we are today about redistributing wealth, one approach that some people have to AI safety is to say, hey, multiple AI agents will fight with each other and will, you know, have a lot of conflict, and that's very dangerous. And that the safe approach is to have a single AI that rules the world as a benevolent dictator and stops all other AI projects and, you know, makes makes this utopia for humans. And there is an argument that you can articulate that that is a good path. The thing I have never been able to be comfortable with on that approach is let's say we are successful in creating this single AI that is a billion times smarter than the next most intelligent agent in the universe, the smartest human, And we think that we built in some controls, and we think we built it to like humans. But we somehow put a bug in there, or there was something that we didn't understand, and it decides to go the other direction. And then you have this massively powerful agent, that is a billion times more intelligent than the next most powerful agent. On also, you know, there will presumably be some group of people in the world that kind of control the AI, and if that group of people decides, I think the the quote is absolute power corrupts absolutely, If they decide something the other seven whatever billion of us don't like, that seems bad. So I'm definitely afraid of a world that has a single concentrated AI. I like better a world with a lot of AIs, and in the same way that there are occasional bad humans, then then they will be able to stop an occasional bad AI. There's another problem, that we're starting to think about now, which is if you have humans and AI, and they're separate, and, they want the same thing, which is to sort of groups that want the same thing and only one of them can have it, like being the number one or the dominant species or in control, you you have some amount of conflict. And and so, you know, the world where we have that conflict and either we're trying to enslave AI, the AI is trying to enslave us, those both seem bad. So I think, Elon thinks too, some people on the team have different opinions, that some version of a merge, and this can range from the simplest, you know, chat interface where everyone has, like, an AI, companion, that works together with the human, and and the humans do what the humans are good at, the AI does AI is good at, and they kind of become this merged sense of self. Or, you know, Elon's version of this is that we just need full on cybernetics and brain implants. Other people think we should go the other way and upload ourselves into the computer. But whatever it is, some sort of merge, so it's not us versus the AI, but us and the AI is sort of one combined entity, And so for me, there's this question about like, a lot of people talk about the regulation question of a timing question. You know? Well, maybe we should regulate AI, but it's too far away. And I actually agree. It probably is too far away, but it's not that far away, and no one knows how to regulate it. So I think we should start thinking about what to do there so that when we get closer to this, whether it takes five, ten, twenty five years, But if we can instead extend individual humans and make them better, the humans can still decide collectively what the common good is. Okay. The internet is a giant source of data. Many YC companies are also willing to contribute their data to OpenAI, but we don't have a problem there. Moreover, I don't three hundred million seconds per year times two bits per second. It's not do do you guys know the the Paul Erdich, the book, this analogy this idea that And and so our our some of our researchers believe that when we when we get the AI algorithms from the book, for building AI, when we discover those, domain? We are just now trying to figure out what the governance model will be. Today, it's just Elon and I on the board, you know, probably to something like seven other people, want to figure out a plan for how as we get closer and closer, this becomes something kind of democratically voted on by the world. We don't know what that structure is going to look like yet. We're beginning to talk about And then from technological safeguards, NYC Research. And so on the energy side, we have been able to fund the the two areas we've concentrated on generation are solar and nuclear. Solar, those companies are less hard, difficult technology and more new business models. So one company is called Bright that On the nuclear generation side, we have companies like Helion, in Seattle working on fusion, and Oclo working on very small, very inexpensive fission reactors in Mountain View. We also funded some companies on energy storage and energy transmission as well. On synthetic biology, we have funded dozens at this point, of companies doing work here, and that has been a really amazing field to watch. The same way that AI was sort of quiet for decades and then had amazing breakthroughs in a period of a few years, We've we've seen the same thing in in synthetic bio. In the last few years, you just see this explosion of companies, that are now able to create new organisms, like Ginkgo Bioworks, which was one of the first synthetic bio companies that we funded, to editing existing organisms and improving them, in different ways. So that, I think, will be a very important vector forward. arrive in time? So the first thing that we're doing with the basic income study is a pilot. This is a much smaller scale. It'll last close to a year, and it is to test our methods, how we're going to study, how much money to give, how to distribute it, how to track results. And so that is really kind of the design phase of the study. That will be with a 100 people But if it goes well, a year from now, we could be ready to start the full scale study. And, you know, the the numbers that most people throw around are something on the order of 18,000 per year. And, but the plan would be to roll that out, probably still in Oakland, but maybe in two different cities at the same time, next year. You know, we honestly don't know this is actually something we're doing research on, is who should regulate it and how. What I think would be really cool and just a cool sort of statement is if you can do something democratic on the Internet because the Internet is powerful at this point. The Internet can make consensus decisions. The Internet can force them to some degree. And so to see, you know, the community basically I think you want an organization of any sort, but certainly in one like this where you're putting the place you're putting into place an You know, religion is one way to get it to survive for a long period of time, but a deep seated belief about something that's really important for the future is another. I think to do that, it's very important to have diversity of backgrounds and life experiences on the team, but to have a deeply shared vision for the future. And so you want people that are engineers and philosophers but to share this deeply held high conviction belief about this version of the future that's absolutely critical. And if this group doesn't do it, it's not gonna get done right. And I think that's how you create these things that outlast incredible risks and incredible opportunities. there are a lot of bad things to combat and a lot of great things to build. Sometimes they're the same. So I think the energy stuff that we talked about earlier. If you could pick one thing to help the poorest half of the world a lot and all the rest of us, still a large amount, I think cheap, clean, safe energy would be the number one thing. Know, energy obviously wreaks havoc on the environment and health, but also it's a huge economic cost, and it's responsible for a ton of war and a lot of other things different problems in the world is how many of them reduce to energy. And so I think if that's one problem, if you could get that to work, you would solve a lot of problems that seem unrelated, you know, some of the crazy stuff happening right now on the Internet can also be addressed with better services, although I don't think that'll be enough. I think we also just need government action and regulation and policy. I think one of the worst things that has happened on the Internet has been the complete basic human decency that you see. There are things that people are willing to say, you know, from one computer screen to another that they would never ever say face to face, or most people wouldn't. You know, it seems like we have some deep seated evolutionary pressure where there is a it is socially unacceptable to be that rude or that crazy face to face. You know, there's probably some, like, And there's a question of can we build new technology to bring that back? So maybe, this is pure speculation, maybe in VR, if instead of typing back and forth, we we feel like we're standing in front of another human and we feel like we have the latency is low enough and the fidelity is high enough that it's not this uncanny valley, but it feels like we're standing face to face with another human, maybe we can, like, trick our brains and get that evolutionary pressure to be decent people back. And maybe we'll feel sort of, like, more connected, we won't say, well, we should blow up that group of people to the same degree. well, like sort of accepting China, the Internet does not have nation state boundaries. And so people choose the communities that they wanna be part of. You see this on Reddit where Reddit is, you know, nominally one community, but it's made up of tens of thousands of very the ability for local efforts to have nonlocal effects. You know, if China burns a gigantic amount of coal, it affects the whole world at some point. I think those two things together, if I had to guess, would lead to a weakening of the traditional nation state boundaries and more towards some interconnected world. But I'm not sure about that because there are other forces pushing very hard in the other direction. And I could see an alternate world where it goes hard in the other way. And, you know, to give The US example, you know, right now, we're mostly one country, but we have 50 states. And I could I could see a world where the 50 states become really powerful and The US becomes less powerful, and people kind of move and get increasingly in addition to OpenAI, another group that YC Research is sponsoring is they call themselves HARC, which is, I think, the Human Augmentation Research Center. And OpenAI is obviously the AI side of the equation. HARC is the IA, intelligence amplification side, where we just figure out how to use software or drugs or whatever to make humans better humans