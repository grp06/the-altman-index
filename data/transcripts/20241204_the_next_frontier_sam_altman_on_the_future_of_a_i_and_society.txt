Unknown: to the mainstream. He's fundamentally really altered how we work, communicate, innovate, and now think about what our future is even gonna be like. His company is now, worth about a $157,000,000,000. And I should say OpenAI didn't just, spark an arms race. It really redefined the possibilities of technology. And as he pushes towards, general or AI, I should say, artificial general intelligence, we're forced to grapple with some very big questions about the future of work, about the balance of power, about ethical questions, and so many other things, and we're gonna delve in to all of that with Sam. So thank you, the man at the center of it all. Thanks for having me. So here's where we'll start. Two years ago, almost to this week, basically, you launched ChatGPT. And I think it's fair to say that when you press the button, since then, all hell is broken loose. It has changed fundraising, priorities, the move of resources. Other technology companies have shifted the way, they're doing things. There have been lawsuits,
Sam Altman: So in the abstract, I mean, I have some theories, but why it happened then and not when we launched the g p t three and the API earlier or why it didn't happen until g p t four launched several months later. Like, why that exact moment? I think there is some, like, chanciness to when it actually catches fire. We had observed, though, with the API and g p t three that, you know, g p t three was a little bit early, and it didn't work for that many things. But in some sense, one of the killer use cases of it was developers in the playground, which is where you could, like, test ideas quickly before you implement the API. They loved just talking to the model. And Agents are the thing everyone is talking about, I think for good reason. You know, this idea that you can give an AI system a pretty complicated task, like a kind of task you give to a very smart human that takes a while to go off and do and use a bunch of tools and create something of value,
Unknown: is how much data and what it takes to actually continue to scale. How much of this is about just pure processing power and therefore capital, right, versus data where you get that data, this idea I think that there's some question embedded in that about
Sam Altman: which piece is gonna get there. So the three key inputs, and there are others too, but the three key ones are compute, data, and algorithms. And you can kinda you wanna push on all of those inputs at the same time. And at different times, there may be differential returns to one or the other, but I kinda think of all three. maybe you can double the size of a computer. Maybe over time with crazy amounts of capital, you can 10 x the size of a computer. Once in a while, these thousand x gains come along algorithmically. The transformer is, like, a good recent example of that. That's rare,
Unknown: but that is the biggest gain when it happens. So right now, though, there was a there's an arms race, it feels like, for processing power. Right?
Sam Altman: huge amounts of effort going into who can come up with the best algorithmic ideas, who can secure new data sources. So so I I think it is on all three fronts.
Unknown: in the best way possible. And then I was just reading Alatif, who wrote it's clear that Microsoft and OpenAI are disentangling.
Sam Altman: But on the whole, I think it's been a tremendously positive thing for both companies and excited to do, like, much, much more together. But long term,
Unknown: processing power that's yours as opposed to relying on somebody else?
Sam Altman: enough compute of the kind we want that we can rely on and all of that. And there may be reasons we have, like, some very crazy ideas about things we'd like to build that are, you know, like high risk, high reward, but we we certainly don't need to have, like, OpenAI get really good at building computer, like, massive scale data centers. In fact, one of the things open to us, you know,
Unknown: friend enemy frenemy situation, I imagine, where you have your product, but, you know, I I was actually using it to that's using your your product in Copilot. You now have Apple using your product, and then you have your own version of a sort of native product that you sell commercially yourself. At some point, do the interests no longer become aligned? And I say that because there's been some reporting, including in the New York Times, that suggested there has been frustrations about how much processing power and access you're getting, different
Sam Altman: many more in the world, so we need lots of compute, more than we projected, and that's just been like an unusual thing in the history of business to scale that quickly. There has been tension on that. I have not heard people like upset about using Microsoft services though. we have like things that we're really good at, Microsoft has things they're really good at. Again, there's not no tension, but on the whole, We've also said that our intention And a lot of the safety concerns that we and others expressed actually don't come at the AGI moment. It's like AGI can get built, the world goes on mostly the same way, the economy moves faster, things grow faster. But then there is a long continue continuation I expect the economic disruption
Unknown: you know Do you have any faith that the government or somebody is gonna figure out how to avoid that?
Sam Altman: nature, but I assume that they're gonna figure that out. And, we're working super hard. Others are working super hard. not magic. We have this incredible piece of science called deep learning that can help us solve these very hard problems. I assume we'll get that right. that can do a bunch of jobs and create a lot of economic value, but, like, true superintelligence, Even if we can make that technically safe, which I assume we'll figure out, to a degree that
Unknown: I assume will rise to the occasion, but seems challenging. Okay. So here's a safety question, and we've all read the headlines. You've been in the headlines. Over the past year or two years, there have been so many people both inside OpenAI who've either left or spoken out or other things where they say, these guys are not focused on safety enough. Just speak to it so we understand. When people say that there's not enough focus on safety, you think what? What is that? What is not happening that is supposed to be happening? Well,
Sam Altman: as something that we did not know how we were going to align very well, and it is now generally considered by most of society to be acceptably safe and acceptably robust. Safety, that's always like a contract negotiated by a whole bunch of stakeholders. It's maybe hard to, like, exactly define what it means for child GPT to be safe. But the reason I ask is when when we hear, you know,
Unknown: different people who have left the organization and they've gone public, they they take to Twitter, and they say, these folks are not focused on safety. Is that about resources on safety? Is that about processing power? Is that about your attention? There are definitely people who think that
Sam Altman: and also there are people who would say, like, putting out a system like this at all is unsafe because OpenAI accelerated a race in the world, and that gives us less time to work on safety. And so the like, we believe, and, you know, this is an opinionated stance, that this idea of iterative deployment is really important. We gotta put these systems out into the world. Society and the technology have to co evolve. You have to start while the stakes are lower. You have to understand how people are gonna use this and what it doesn't work for, what it does. There are other people who say, you know,
Unknown: Elon Musk is building his own processing, you know, these these huge processing power labs effectively to to power x AI. And one of the reasons I was asking whether you needed your own is because it seems like everybody is getting their own. We were just talking before to to Ken about Elon Musk. Elon Musk has a sort of unusual relationship in your life How much do you see x AI as a competitor? We talk about Google, obviously, all the time, and we talk about Anthropic
Sam Altman: Everybody has their analogy for what AI is like. You know? that a few companies discovered first that transformed our society, There will be shockingly capable models widely available, used for everything, And they won't all call themselves AI companies or AI products. And in that sense, in some sense, And that's why we're focused on building things like CHAJIBT.
Unknown: And he, as everybody knows, if you read the papers, is suing you over this and many other things.
Sam Altman: not thinking very ambitiously, he pushed a lot of people, me included, to think much more ambitiously. and decided to go his own way, and that's fine too, but I think of Elon as a builder, and someone who, like, you know, known thing about Elon, he really cares about being the guy, but I think of him as someone that if he's not, that just competes in the market, and in technology, and whatever else, and doesn't resort to lawfare, and you know, whatever the stated complaint is, what I believe is he's just like,
Unknown: folks like yourself were worried about his influence, not just his influence in the technology area, but given his close relationship now with the president-elect?
Sam Altman: political power to the degree that Elon has it, to hurt your competitors and advantage your own businesses. And, I
Unknown: very dear to himself that I'm not that worried about it. Okay. One last related question on that, and and then I actually wanna talk a different different tech question about the company, which is one of the things that he alleged is that he thinks that you guys are now so big that there's not competition and that you're trying to prevent competition from happening by preventing potential funders of, for example, x AI or arguably others from both funding you and funding them at the same time. Incorrect.
Sam Altman: All we knew that we wanted to do was do some AI research, and that we thought AGI and superintelligence eventually would be this important thing to the world, and we wanted to, like, somehow do something that would be good. At the time we were working on, like, writing papers, new RL algorithms, new theories, and it was not clear that there would ever be a product or revenue stream at all. And, it wasn't clear that we were going to need one, because it wasn't clear we needed so much money. Right. It became clear after GPT one and some other work that we were going to need to scale, and we started and also, Elon decided to stop funding us as a nonprofit, that we needed to find a way to make a capped profit. Now we wanted to keep going with a lot of the things that we think are good about a nonprofit, and so we had this subsidiary capped profit that worked for a while, and in some senses still does kinda work, and in some other senses is like straining the theory of what a nonprofit controlled org can be, and the amount of capital we need at this next stage. So we are, and have been for a while, looking at some changes. Nothing is decided. It is, as you can imagine, like, very complicated to figure this out, in any configuration, like, the nonprofit doesn't go away. Like, one thing that the board has looked at, for example, is a PBC that owns a huge chunk of and then figures out how to use that amount of wealth for the the purpose of the nonprofit. There's other ideas too. Yeah.
Unknown: If the company does have one of these moments, there's an expectation you will get some equity?
Sam Altman: I am I have the most interesting, coolest job in the world. This is like my retirement dream way to spend my time after like, what was a pretty good career, and people can work on art projects and not get paid for that, and no one thinks it's weird or whatever. It I don't imagine I would work any harder or less hard. There would be, like, I think something clearer about the alignment I This is my childhood dream job. Like, not everyday, like not day to day, would rather not
Unknown: and Microsoft over training on content. And there's a lot of content creators and other folks in this room who make their living off of content. And
Sam Altman: deal, protocol, whatever you wanna call it, for how creators are going to get rewarded. I very much believe in the right to learn, or whatever you wanna call it. And, if an AI reads something, a physics textbook can learn physics, it can use that for other things like a human can. I think those parts of copyright law and fair use really need to keep applying, but I think there's additional things that we're starting to explore, and others are, where, you know, a particular passion of mine has always been, can we figure out how do micropayments where if you generate a story in the style of Andrew Ross Sorkin, you can opt into that for your name and likeness and style to be used and get paid for it. There's many other ideas too. I think the discussion on but but the part I really agree with is we need to find new economic models Right. Where creators can have new revenue streams.
Unknown: And for all parents out there and would be parents who are thinking about what we're supposed to do, how we're supposed to think about it, what it does to our own dignity. What do you think if it when you have your child and you're you're thinking and talking to that child, what do you think you're gonna be telling them
Sam Altman: I think that's like a specific lens on the Gemma phenomenon, which is we have been developing incredible new technology for a long time. And each time it's happened, people have had these conversations. You know, what does this mean? The industrial revolution comes along. Machines take all of our jobs, what does this mean? Computer revolution comes along, computers take a bunch of current jobs, what does it mean? And, the answer, and anything else that any technology can deliver. The the sort of the deep human drives are so powerful and have been here for so long, and evolution evolutionary drift is pretty slow that, you know, I think in some sense, my kids will grow up in a super different world, and in some other sense, it'll be exactly the same.