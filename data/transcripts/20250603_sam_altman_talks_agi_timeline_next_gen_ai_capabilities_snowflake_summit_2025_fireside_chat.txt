Unknown: He's led OpenAI from groundbreaking research to products now impacting billions, driving the evolution of AI on a truly global scale. Please join me in welcoming the founder and CEO of OpenAI, Sam Altman.
Unknown: Sam, Sreedhar, what advice would you have for enterprise leaders navigating the AI landscape in 2025?
Sam Altman: when things are changing quickly, the companies that have the quickest iteration speed and sort of make the cost of making mistakes the lowest and the learning rate the highest win. And certainly what we're seeing with enterprises and AI is the people that are making the early bets and iterating very quickly are doing much better than the people that are waiting to see how it's all gonna shake out.
Unknown: is the most overlooked thing and I think it's fine to make mistakes. You need to figure out situations in which it doesn't matter that much, and there are lots of situations like that. But the technology is also rapidly maturing. You know, you can use ChatGPT now for getting information about the latest events because it knows when to use web search to provide that. And so there are lots of applications like chatbots, whether it's structured or unstructured data. The technology is mature. You can adopt it. Yes. You can always push the boundary on what else you can do with it. There are edgier, agentic applications,
Sam Altman: I would have say like I I would say like, you know, you can experiment a little bit, but this is maybe not totally ready for production use in most cases. And that has really changed. Our enterprise business has gone like this, and we talk to big companies who are now, like, really using us for a lot of stuff and say, like, what's so different? And and and we're like, did it just take you a while to figure it out? And they say, that was part of it, but it just works so much more reliably. It works you know, it can do all these things that I just didn't think were gonna be possible. And it does it does seem like sometime over the last year, we hit a real inflection point for the usability of these models. Now, interesting question is what will we say differently next year? And I think we'll be at the point next year where you cannot only use a system to sort of automate some business processes or build these new products and services, But you can really say, I have this hugely important problem in my business. I will throw a ton of compute at it if you can solve it. And the models will be able to go figure out things that teams of people on their own can't do. And the companies that are have gotten experience with these models are well positioned for a world where they can say, okay, you know, AI system whatever, go, you know, like, redo my most critical project and here 's a ton of compute, think really hard, just figure out the answer. People who are ready for that, I think will have another big step change next year.
Unknown: I I think, you know, given reasoning and applying more compute to hard problems and you know, the introduction of agents into some workflows,
Sam Altman: watch your meetings if you want and look at your Slack and read all your internal documents, and it's just doing incredibly impressive stuff. And, you know, maybe today it is like a sort of intern that can work for a couple of hours, but at some point it'll be like an experienced software engineer that can work for days. And then we'll see this for many other categories of work. And so you see you hear from companies that are building agents to automate most of their customer support or their outbound sales or any number of other things, and you hear people that talk about their job now is to assign work to a bunch of agents, And that's here. It's not evenly distributed yet, but that's happening. I would bet next year that in some limited cases, least in some small ways, we start to see agents that can help us discover new knowledge or can figure out solutions to business problems that are kind of very nontrivial. Right now, it's it's very much in the category of, okay, if you've got some, like, repetitive cognitive work, we can automate it at a kind of a low level on a short time horizon. And as that expands to longer time horizons and higher and higher levels, you know, at some point you get an AI scientist, an AI agent that can go discover new science, and that will be kind of a significant moment in the world. think if you could go back to most people, if you could travel back in time, just five years, and show someone And, you know, so we're great at adjusting our expectations, I think mostly the question of what AGI is doesn't matter. It is a term that people define differently. The same person often will define it differently. The the thing that matters is the rate of progress that we have seen year over year over the last five years should continue for at least the next five, probably well beyond that, but hard to say. And whether you declare the AGI victory in '24 or '26 or '28, and whether you declare the superintelligence victory in '28 or '30 or '32, is way less important than this one long, beautiful, shockingly smooth exponential. All of that said, to me, a system that can either autonomously discover new science or be such an incredible tool to people that our rate of scientific discovery in the world, like, quadruples or something, that would that would satisfy any test I could imagine for an AGI. Some other people would say it's gotta be a system capable of self improvement. Plenty of people would say like chat GBT with memory today, very AGI like. Mhmm. Certainly across some of our early tests like Turing tests that people used to say was the was the target.
Unknown: Okay. Scrolling back to 2020,
Unknown: but already you could see greatness. For me, when you saw this problem called abstractive summarization
Unknown: a former Neva person as well and part of my premise was like, everything is search or search plus in this era. When did you have that thought? It's about setting context. Once And do you agree with Sam that it's really just being on this exponential capability curve, or is there a definition of AGI that matters to you or matters to customers?
Unknown: And so I see these models as having incredible capabilities that we will like, any person looking at what things are going to be like in 2030
Unknown: I have a hunch personally that when people ask about AGI I think they're really asking about consciousness, I have to ask you because we have you, You're training more models, know, you see the next capabilities before anybody else does. What emergent behaviors are you seeing in the next set of models that change you know, how you operate, what you want to build from a product perspective, how you're running OpenAI?
Sam Altman: models over the next year or two years are are gonna be quite breathtaking. Really, And like we have seen in the previous big jumps, you know, from g p t three to g p t four, businesses can just do things that totally were impossible with the previous generation of models. And and so what an enterprise will be able to do we talked about this a little bit, but just, like, give it your hardest problem. If you're a chip design company, say, go design me a better chip than I could have possibly had before. If you're a biotech company trying to cure some disease, say just go work on this for me. Like that's not so far away. And these models' ability to understand all the context you want to possibly give them, connect to every tool, every system, whatever, and then go think really hard, like really brilliant reasoning and come back with an answer and have enough robustness that you can trust them to go off and do some work autonomously.
Unknown: Is there any intuition you can give everyone here
Sam Altman: is a very tiny model that has superhuman reasoning capabilities. It can run ridiculously fast and 1,000,000,000,000 tokens of context and access to every tool you can possibly imagine. But the amazing thing is they can reason, and if you think of it as this reasoning engine that we can then throw all of the possible context of a business or a person's life into and any tool that they need for that physics simulator or whatever else, that's like quite amazing what people can do and I think, you know, directionally we're headed there.
Unknown: Amazing. I want to ask both of you for a more like conjecture question. If you had a thousand times more compute, the original thought was infinite but that gets silly, a thousand times more compute, what would you do with it?
Sam Altman: we see all of these cases now inside of ChatGPT or inside of enterprises that are using our latest models where there are real returns to test time compute. If you let the model reason more, if you try more times on a hard problem, can get much better answers already, and a business that just said I'm going to throw a thousand times more compute at every problem would get some amazing results. Now, you're not literally gonna do that and you don't have a thousand x compute, but the fact that that's now possible I think does point to an interesting thing people could do today which is say, okay, I'm gonna like really treat this as a power law and be willing to try a lot more compute for my hardest problems or most valuable things.