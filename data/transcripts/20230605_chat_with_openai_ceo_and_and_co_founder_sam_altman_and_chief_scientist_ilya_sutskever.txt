Unknown: I moved to the University of Toronto where I spent ten years, and I got my bachelor, master's, and PhD degrees. to contribute to important advances in deep learning. And I was a very curious event. And that was the first original dinner with Elon Musk and Greg Brockman where we decided to start OpenAI.
Sam Altman: timeline. Dropped out. Did startups. Became a startup investor for a while. Really got excited about what was happening with AI after the advances that Ilya mentioned. Sent him that email, here we are. And then we have a a culture of rigor and repeatable innovation, and to have both of those in one culture is difficult and rare. Yeah.
Unknown: progress in AI is a game of faith. The more faith you have, the more progress you can make. And so if you have a very, very large amount of faith, has less compute and generally does not have an engineering culture. And yet, academia can make very dramatic and significant contributions to AI, just not to the most cutting edge capabilities. The place that academia can contribute to, there are so many mysteries about the neural networks that we are training. We are producing these objects of miraculous and unimaginable complexity. What deep learning is is a process of alchemy. We take the raw materials of data plus the energy source of compute, and we get this intelligence. but the important thing is to think about the most important problems. have written papers studying their models, their properties, their biases. And I think there'll be a few more ideas, by the way. I'd be happy to hear them.
Sam Altman: were published by OpenAI. and scientific
Unknown: like, we we have full human level AI, full AGI, people will still have economic activity to do. I don't know whether that's the case. But in either event, we will need to have something that will allow for a soft softened blow to allow for a smoother transition either to the totally new profession that will exist, question, the hackers, yeah, that's a tricky one. Indeed, AI will be powerful, and it could be used in powerful ways by bad actors. We will need to apply similar frameworks similar to the one we apply with other very powerful and dangerous tools. Now mind you, we are not talking about the AIs of today. We are talking about as time goes by and the capability keeps increasing, Much more worse than anything that existed before. That'd be bad. So we will need to have structures in place that will control the use of the corporate technology that's powerful. You know, Sam has proposed them To the last question, the super intelligent AI that's out of control. Yeah. That'd be pretty bad.
Sam Altman: dramatic productivity growth, and we're gonna find out that if you can make programmers two times as productive, In the longer term, I think these systems will do more and more complex buckets of stuff and categories of jobs, some of them will go away, but some others will turn out to, like, really need humans and human like, people really want humans in these roles in ways that are not very obvious. One example is that one of the first times the world saw AI was when Deep Blue beat Kasparov, and everyone said, you know, chess is totally over. No one is ever gonna play chess again because it's not interesting. And and that was just consensus that everybody agreed with. Chess has never been more popular than it is right now. Humans have gotten better at chess. The expectation has gone up. We can learn better with these tools, but people still really wanna play, and humans seem to still really care about what other humans do. Know, Dolly can make great art, but people still care about the human behind the art that they wanna buy and that sort of we all think is special and valuable. On the chess example, like, people watch humans play chess more than ever before too, but not very many people, like, watch two AIs play each other. So I I think there are just gonna be all of these things that are difficult to predict. The human desire to differentiate, to create new things, to sort of gain status, I think that's not gonna go anywhere, but it will somehow look really different, and I would bet that the jobs of a hundred years from now look almost nothing like the jobs of today, many of them. Some things will turn out to be weirdly similar. really agree with what Ilya was saying that no matter what's gonna happen, we're gonna need some sort of different socioeconomic contract as as automation reaches these, like, heretofore unimagined heights. I really want to emphasize what we're talking about here is not the systems of today, not small start ups training models, not open source not the open source community. I And so one idea that we've contributed, and I hope that there's far better ones out there, is if we could get a global organization that at the very highest end, at the frontier of compute power and techniques, could have a framework to license models, to audit the safety of them, to propose tests that are required to be passed, that would help. That would be one way to treat this as a very serious risk. We do do the same thing for nuclear, for example. huge economic benefits, huge health care benefits. But the fact that AI can help us do scientific discovery that we currently aren't capable of, I I really believe that scientific and technical progress is the only sustainable way that lives get better, that the world gets better. And if we can go unlock a gigantic amount of new science, new technological progress,
Unknown: If you can accelerate the scientific progress, which is something that a powerful AI could do, we could get to a very advanced carbon capture much faster. We could get to a very cheap power much faster. You could get to cheaper manufacturing much faster. Now combine those three, cheap power, cheap manufacturing, advanced carbon capture. Now you build lots of them. it becomes very straightforward.
Sam Altman: You know, if you think about a system where you can say, tell me how to make a lot of clean energy cheaply, tell me how to efficiently capture carbon, and then tell me how to build a factory to do this at planetary scale.
Unknown: I'm just the thing which has given me me personally an endless amount of joy is when my parents told me that their friends use ChatGPT in their daily lives.
Sam Altman: There's something that I find personally quite gratifying and wonderful to see about people was a guy that spends two hours every night with his kid collaborating to make up bedtime stories. odd at us again. I hope that, you know, people had an update with ChatGPT, but from here on, it is one continuous smooth curve of progress. At every stage, we're confronting the risks successfully. It always feels, you know, like it's doing what you want and it's safe to use, but every year, your expectations go up and we deliver on them, and it feels like this gradual acceleration of technology, but in a way that very much is a tool that serves you.
Unknown: black and white terms where, like, there is a secret source that will never be rediscovered. So there will always be a gap between the open source models and the private models. And this gap may even be increasing this time. The amount of effort and engineering and research that it takes to produce one such neural net keeps increasing. researchers and engineers, and it will only be the providence of a company, a big company.
Sam Altman: We we we definitely realize that in the process of doing RLHF on the models, it loses important capability. We're studying how we can preserve as much of that as possible. what their concerns are, you know, how they're thinking about regulation, how they're thinking about how they want this to be integrated in society. But the other is to talk to people that are building on top of our at the creativity, the scale of the businesses being built, the, you know, one, two, or three people that are, like, building something that has now gotten to real scale and a product that people really love, and how that is happening in every industry. You know, when we do these developer roundtables, almost never are two people working on the same kind of sector even. It's the diversity that is the coolest thing. I think any vertical you wanna pick, AI is gonna impact somehow, and and this is probably the most magical period since the launch of the iPhone, at least, for a technological tidal wave to go do incredible things. So I think the most exciting part of this is it's not one or two sectors. It's just find some place that you're passionate about and go do it. and good question, and the most troublesome part of our jobs is that we we have to balance this, like, incredible promise and this technology that I think humans really need, Why to build it? Number one, I do think that when we look back at the standard of living and what we tolerate for people today, it will look even worse than when we look back at how people lived five hundred or a thousand years ago, And again, the upside there is is tremendous. I also think this is, like, unstoppable. Like, this is the progress of technology. It won't it won't work to stop it, and so we have to figure out how to manage the risk. We were formed as a company in large part because of this risk and the need to address it. We have an unusual structure. We have a capped profit. I believe that incentives are superpowers, and if you design the incentives right, you usually get the behavior you want. So, you know, rate like, we're gonna all do fine. We're not gonna make any more or less money if we, like, make the numbers go a little further up to the right. We don't have the incentive structure that a company like Facebook had, and I think there were very well meaning people at Facebook. They were just in in an incentive structure that had some challenges. So we tried to take AGI.
Unknown: As we keep building AIs of increasingly greater capabilities, there'll be a larger gap, a longer testing period, a longer and then expand it gradually. So for example, right now, GPT four has vision recognition abilities, which we have not rolled out yet because the finishing touches weren't quite there, but soon we will. So maybe
Sam Altman: aside from the fact that we have, like, a gigantic number of users and people that, like, have formed some sort of relationship with us and our products, is what OpenAI is special about is figuring out what comes next.
Unknown: And just for context, not everyone may not everyone in the audience may understand what we mean by superintelligence. Right? What do we mean? One day, when like, it will be possible to build a computer, a computer cluster, GPU farm, that is just smarter than any person, that can do science and engineering much, much faster than even a large team of really experienced scientists and engineers. And that is crazy. That is going to be unbelievably extremely impactful. It could engineer the next version of the system, like AI built in AI. But it's just crazy. So our stance is that superintelligence is profound. It it can be incredibly unbelievably positive, but also very dangerous. And also, is a lot of research that we will need to do to contain the power of the superintelligence to align them so that their power and their capability will be used to our benefit, to the benefit of people. So that's our stance on superintelligence. It is the ultimate challenge of humanity, superintelligence.
Sam Altman: but they will be able to go off and access different data, and they will also need people who help teach them how to reason correctly. And we we are exploring a lot of ideas about how those people get aligned rewards with the success of the model, and also how if you're, you know, an artist and people are generating art in your style or inspired by you or whatever, you get economic benefit from that. So I think it's super important to figure out, of talented people that you can get clustered into areas. And then the second is just the sort of, like, relentlessness drive ambition level of Israeli entrepreneurs. Again, we had, like, incredible success in all of the YC efforts we made. But those two things together, I think, are ought to lead to incredible prosperity both in terms of AI research and AI applications. engineer to help us build these systems, or it could just mean, like, be really helpful to other people and contribute that way. Definitely a belief in superintelligence and a feeling the weight of the importance of getting this right in terms of getting the benefits but managing the risks. I don't know what else. Oh,
Unknown: for you to have a conversation about the subject matter. So that makes for a much more efficient learning experience. It will apply to math. It will apply to everything else. Eventually, we will be moving or rather eventually, we already are moving to a world where every student has a dedicated private tutor. Not there yet. It's not quite good enough, but it will be.
Sam Altman: I'm actually not sure if it's a black swan event in employment. In almost every conversation I've had these last few weeks on the road, every government has been very thoughtful about this. They have different ideas about how best to solve it, but it is maybe the top of mind issue, at least the top three issue, valuable for its own sake even if you're the job of a computer programmer looks very different than it looks today. The main skill I think to learn is how to learn, So again, there's no question in our minds that jobs are gonna change, the nature of work is gonna change, but also I cannot imagine a world where people don't do something with their time to create value for other people and all of the benefits that come with that. and things are possible that most people can't quite imagine. And the the opportunity to build value every entrepreneur is a summer child right now, and it's a super cool time. Hello? you know, I was I'm an investor and I kind of like helped put the company together, but I'm not involved day to day at all. I think it's very exciting. I think experimenting with new ways to differentiate between like like to prove humanity in a privacy preserving way and to think about things like global UBI and ways to fairly democratize access is a super great area to explore,