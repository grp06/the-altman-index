Unknown: What's the weirdest thing that's changed in your life in the last four or five years running OpenAI? What's the most unusual shift that's happened?
Sam Altman: anonymous in public is very, very strange. I
Unknown: Can you speak to why this is important?
Sam Altman: Because I think it's an incredible way to use a computer. This fact this I we've had voice the idea of voice controlled computers for a long time. You know, we had Siri and we had things before that. They've never, to me, felt natural to use, and this one, many different reasons. What it can do, the speed, adding in other modalities, the inflection, the naturalness, the fact that you can do things like, say, hey, talk faster or talk in this other voice, and that it's that that the but one surprising one is putting my phone on the table while I'm like really in the zone of working, and then without having to change windows or change what I'm doing, using it as another channel. So I'm working on something, I would normally stop what I'm doing, switch to another tab, Google something, click around or whatever. But while I'm still doing it, to just ask and get an instant response shift or more compute? I mean, was like all of the things that we've learned over the last several years. We've been working on audio models. We've been working on visual models. We've been working on tying them together. We've been working on more efficient ways to train our models. It's not like, okay, we unlocked this one maybe it would be hard to deal with network latency at some point. Like like the the the a thing that I've always thought would be super amazing is to put on someday a pair of AR goggles or whatever and just speak the world in real time and watch things change, and that might get a harder over network latency. But for this,
Unknown: You alluded recently to chat GPT
Sam Altman: but I don't think we figured out how to do the naming or branding for these things yet. It made sense to me from GPT one to GPT four at the launch. Now, obviously, GPT four has continued to get much better. We also have this idea that there's gonna be, like you know, maybe there's, like, one underlying kind of, like, virtual brain, and it can, like, think harder in some cases than others. Or maybe it's different models, but maybe users don't care if they're different or not. So I don't think we know the answer to how we're gonna product market all of this yet. Does that mean maybe that the
Unknown: needs of the compute to make incremental progress on models might be less than what it's been historically?
Sam Altman: I sort of think we'll always use as much compute as we get. Now we are finding incredible efficiency gains, and that's really important. One of the, you know, the cool the cool thing that we launched today is obviously the voice mode, but maybe the most important thing is we were able to make this so
Unknown: didn't actually change the world in and of itself, but maybe just changed people's expectations for the world? Yeah.
Sam Altman: Like, don't think you can find much evidence in the economic graph a couple of decades in the future, it'd be like, something changed. Yeah. Are there applications I would bet that it's the generalized model that's gonna matter. And what is the most important
Unknown: thing there as you think about, like, someone that's focused singularly on a dataset
Sam Altman: and all the integrations associated with something very narrow? If the model can do generalized reasoning, if it can figure
Unknown: humans and AI is in two years?
Sam Altman: humans and AIs can sort of use together,
Unknown: generally an interesting direction to push. You said recently something to the effect of the models might ultimately get commoditized over time, but the most important thing would likely be the personalization of the models to each individual first. Yeah. Do do I have that right? do you think it's just normal business UI and
Sam Altman: ease of use that ultimately wins for end users? Those are those will for sure be important. They they always are. You know, I can imagine other things where there's like a sort of marketplace or a network effect of some sort that matters Yeah. Where it's, you know, we want our agents to communicate. There's, yeah, different companies in an app store, but I I sort of think that the rules of business kind of generally apply, and whenever you have a new technology, you're tempted to say they don't, but that's always like fake news and not always, usually fake news. And all of the traditional ways that you create enduring value will will still matter here. When you see open source models like
Unknown: what's your reaction There's been press reports related to looking to raise major amounts of money. Wall Street Journal, I think, was a credible one to galvanize investment in fabs. Semi industry, TSMC, and NVIDIA have been ramping pretty aggressively to meet expectations of the need for AI infrastructure. You recently said that you think the world needs more AI infrastructure, and then you said a lot more AI infrastructure. I do see. side that would require way more AI infrastructure than what we're currently getting out of TSMC and NVIDIA? So first of all, I'm
Sam Altman: confident that we will figure out how to bring costs to deliver current systems way way down. I'm also confident that as we do that, demand will increase by a huge amount. And third, I'm confident that by building bigger and better systems, there will be even even more demand.
Unknown: physical device assistants, what do you think those have gotten wrong, or where do you think the adoption maybe hasn't met user desires
Sam Altman: I I have been an early adopter of many types of computing. I had and very much loved the Compaq TC 1,000. It's like when I was a freshman in college. and that was a long way from the iPhone, but we got there eventually.
Unknown: And, you know, these things feel like a very promising direction that's gonna take some iteration. You mentioned recently that a number of businesses that are building on top of GPT four will be steamrolled, I think was your term, by future GPT. I guess, can can you elaborate on that point? And second, like, what are the characteristics of AI first businesses that you think will survive GPT's advancement?
Sam Altman: The only framework that I have found that works for this is you you can either build a business that bets against the next model being really good or a model that bets on that happening and benefits from it happening. So if you're doing a lot of work to make one use case really work that was just beyond the capability of g p t four, g p t four zero, and then you get it to work, but then g p t five comes out and it does that and everything else really well, you're kind of sad about the effort you put into that one thing to get it to barely work. But if you had something that just of worked okay across the board and people were finding things to use for, but you didn't put in tons of work to make this one thing kinda possible. suggest is, like, you're not building an AI business in most cases. You're building a business, and AI is a technology that you use. In the early days of the App Store, I think there were a lot of things that, like, filled in some very obvious crack, And then there were, I think, things like Uber that were enabled by having smartphones, but really built a very defensible long term business,
Unknown: in some ways. Are there any, like, novel types of concepts that you sort of think is
Sam Altman: I would actually bet on the new companies for like many of these cases. A very common example people use is trying to build the AI doctor, the AI diagnostician.
Unknown: I would say bet
Sam Altman: that intelligence as a service gets better and cheaper every year, and it is necessary but not sufficient for you to win. So the big companies that take, you know, years to implement this, you can, like, beat them, but every other startup is paying attention is gonna do this too. And so you still have to figure out what's the long term defensibility of my business. Now, but you don't get a pass on the hard work of building enduring value, even though you can now do it in more ways. Is
Unknown: there a job title or a type of
Sam Altman: job responsibility that you could envision existing or being mainstream in five years because of AI that is maybe niche or nonexistent today? That's a great question, and I don't think I've ever gotten it before. People always ask, like, what job is gonna go away? The new one is a more interesting question. Let me think for a second. I mean, there's like a lot of things that I could talk about that I think are sort of less interesting or less huge. What I'm trying to do is like come up the areas of like,
Unknown: that will get OpenAI to be a trillion dollar company short of AGI?
Sam Altman: improving our technology at the rate we've been doing it and figuring out how to continue to make good products with it and revenue keeps growing like it's growing, I don't know about specific numbers, but I think we'll be fine.
Unknown: Is the the business monetization model today the one that you think creates the $1,000,000,000,000 equity value? AGI, whatever that term actually means, AGI what the monetization that that the
Sam Altman: all sorts of conversations and
Unknown: about preconceptions around AI, to your point on the monetization model and all that, is I think we've all yeah. I've heard you speak about it. Manual work, obviously, first, followed by Yeah. You know, white collar, followed by creative. Obviously, it's proven to be kind of the opposite in some ways. Are there other things that are counterintuitive labor, cognitive labor, creative labor. For those that haven't heard you make the point about AGI and why you dislike the term, can you elaborate
Sam Altman: and and particularly in a field that's like moving around as much as this one is. But my naive conception when we started is that we would get to a moment where we didn't have AGI, then we did. And it would be a real discontinuity. And I still think there's some chance of a real discontinuity, but on the whole, think it's gonna look much more like a continuous exponential curve where what matters is the pace of progress year over year over year, and you and I will probably not agree on the month or even the year that we're like, okay, now that's AGI. We can come up with other tests that we will agree with, but even that is harder than it sounds. And, yeah, GPT four is definitely not over a threshold that I think almost anyone would call an AGI, and I don't expect our next big model to be either. But I can imagine that we're, like, only maybe one or two or some small number of ideas away and a little bit scale from something that we're like, this is now kind of different. And I think it's important to where that that you think like, hey, when it crosses this threshold I think when it's capable of doing better research than like all of OpenAI put together, even one OpenAI researcher,
Unknown: that you see to reaching AGI?
Sam Altman: Internet software to AI which usually means it takes much longer. It doesn't work, but sometimes means it works tremendously faster than anyone could have predicted. What what is that? Can can you elaborate on that point that it's not as linear in progress? examples. I'm gonna get the numbers in the early nineteen hundreds. It was maybe first detected in the tens or twenties, happened in the forties. From not that there was even the idea of a thing like a neutron to being able to make an atomic bomb and just break all of our intuitions about physics, That's wildly quick. There are other examples that are sort of less pure science. There's the, like, do I understand, like, every what's happening at every mechanical layer through the network, and then there's can I look at the output and say there's a logical flaw here or whatever? I am excited about the work going on at OpenAI and elsewhere in this direction, and I think that interpretability
Unknown: going to be a requisite to mainstream AI adoption maybe within maybe a few things that I think you get asked questions about or accuse maybe accuse is too strong of a term, but that people are suspicious about, one of which is I think there's this needle threading that exists between being excited about AGI, but also feels like you have a personal kind of apprehension about you, Sam, OpenAI generally being the ones to harness it and unilaterally make decisions, which has led to some, you know, some body, some governmental structure where there's elected leaders instead of you
Sam Altman: is probably a good thing. Now, is some needle threading about where you set those thresholds and how you test for it, and it would be a real shame to sort of stop the tremendous upsides of this technology and letting people that wanna go train models in their basement be able to do that. That'd be really really bad. we have international rules for nuclear weapons,
Unknown: I think it's a good thing. The regulatory capture group, which I'm sure we can think of, which VCs fall into that bucket of accusatory around this regular regulation. see about the potential risks inherent in AI?
Sam Altman: some of the loudest voices about AI regulatory capture were, you know, totally decrying it as a possibility not that long ago. Not all. But I do have empathy for where they're coming from, which is like regulation has not been really bad for technology. Look what happened to the European technology industry. I get it. I really do. And yet, I think that there is a threshold
Unknown: but I could imagine one that could. I've heard you say that safety is kind of a false framing in some ways because it's more of a discussion about what we explicitly
Sam Altman: accept, like airlines. Yeah. It's more like Like, you are willing to get on airplanes because you think they're pretty safe even though you know they crash once in a while,
Unknown: around it. And then there's the implicit side of safety as well, like social media, right, or things that have negative association. Is there something that you could imagine seeing on the safety paradigm that would hours and talk. We went a bunch a bunch of different directions, but I'd be remiss as a as a friend of the pod to not ask a fast takeoff question. today is just a lack of AI infrastructure. Right? And I guess if there was some some researcher developed a modification to the current transformer architecture where suddenly the amount of data and hardware scale needed drastically reduced more like human brain or something like that, Is it possible we could see a fast takeoff scenario?
Sam Altman: Possible, of course, and it may even need a modification. It is still not what I believe is the most probable path, but I don't discount it, and I think it's important that we consider it in the space of what could happen. I think things will turn to be more continuous even if they're accelerating. I don't think we're likely to go to sleep one day with pretty good AI and wake up the next day with genuine super intelligence. But even if even if the takeoff happens over a year or a few years, that's still fast in some sense. There's another question about even if you got to this really powerful AGI, how much does that change society on the next day versus the next year versus the next decade? And my guess is in most ways
Unknown: they they have suspiciousness around I imagine the questions you don't love getting are Elon, equity, and November board structure. Those are probably the the three Well, I I guess I'm not gonna ask the the equity one specifically because I think you've answered that in more than enough ways. Although, it it is people still don't seem to like the the answer that enough What what do you feel like your motivations this pursuit of AGI, like, outside of the the equity? I think most people take solace in the fact that, like, oh, well, even if I have some higher mission, I still get paid for it in some ways. Like, what are your motiv visions now coming into work every day? Like, what's the most fulfillment derived from? Look, I tell Was there a single moment I guess we go back to the the the fame example of not being able to go out in your city or whatever, but has there been a single moment that was most surreal that, like, oh, jeez. I don't know.
Sam Altman: After all of that November stuff happened that you know, that day or the next day or whatever, I got, like, I don't know, ten, twenty texts from me like that from major world presidents, prime ministers of countries, whatever. The weird part was that happened, and I was, like, you know, kind of Energy levels, like, very high, very clear, very focused, but just, like, your body was, like, in some weird, like, adrenaline charged state for a long time. now it's the Wednesday before Thanksgiving, Ali and I drove up to Napa and stopped at this diner. Goth, it's very good. And on the drive up there, realized I hadn't eaten And go to Gott's, order four entrees, heavy, fried heavy entrees, one of them, president of this one country, texted again and just said, oh, I'm sorry. This all resolved. Great. Whatever. And then it hit me that, oh, yeah. All of these people had texted me, and it wasn't weird. And the weird part was realizing that that had happened in the middle of it, and that that should have been this very weird experience, and it wasn't. So that was one that sticks out. Yeah. That is interesting. My takeaway is human adaptability to almost anything is just much more remarkably strong than we realize, and you can get used to anything as the new normal, good or bad, pretty fast. And I kinda, like, over the last couple of years, have but I think it says something remarkable about like, genuinely, that's been my big surprising
Unknown: element. Like, what do you think remains uniquely human as models start doing more and more capabilities
Sam Altman: I think many many years from now humans are still gonna care about other other humans. I, you know, I bet we're I I think we're so wired to care long term about other humans in all sorts of big and small ways that that's gonna remain.
Unknown: at YC on Are there are there different types of people you hire for this business than you would have had you started a consumer Internet company within the executive ranks or b to b software company or something? bring in a different type of executive,
Sam Altman: that could reinforce a monoculture, and, you know, I think you wanna bring in some new very senior people.
Unknown: Is there a decision that you've made over the course of OpenAI
Sam Altman: a quite important there was a very small effort. It started with one person looking at We really believed in, like, general direction that became language models, let's say. And we did GPT one, we did GPT two, we started to study scaling laws, scaled GPT three, and and then we made a big bet this was what we were gonna do. And it was not it looks so all of these things look so obvious in retrospect. I really don't feel that way at the time. One other thing you brought up recently
Unknown: was the there's two approaches to AI, the replication of yourself and then the smartest employee. a fairly profound
Sam Altman: I think you wanna be clear of whether you're texting me or my AI assistant. And then if it's my AI assistant that's gonna separate and not that it's like, alright, the AI is truly just an extension of Sam. I don't know if I'm talking to Sam or Sam's AI ghost, but that's okay because it's the same thing. It's this merged entity.
Unknown: audio. We probably need some form of validation or some centralization that
Sam Altman: But it's not a single board, and I think that's a way we're all comfortable.
Unknown: of of letting individuals do their or whatever whatever some some group in the future, Are there changes specifically that you think should be made within the college educational system to prepare people for the
Sam Altman: future we have? The biggest one is I think people should not only be allowed but required to use the tools. There will be some cases where we want people to do something the old fashioned way because it helps with understanding. And so you need to understand it, but then you gotta be proficient using the calculator too. If you did math class and never got to use the calculator,
Unknown: We think it's likely the progress will continue from there, possibly sustaining the rate of progress we've seen over the past decade for a long period of time. Do you ever, personally stop and process or visualize, like, what the future will look like in that, or is it just too abstract
Sam Altman: one person can do the work of hundreds or thousands of well coordinated people, and what
Unknown: Sam Altman. If you enjoyed this conversation, really appreciate it if you like and subscribe and share with anyone else that you think might find interesting,