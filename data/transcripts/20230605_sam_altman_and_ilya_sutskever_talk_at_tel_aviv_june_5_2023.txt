Sam Altman: timeline. Dropped out, did startups, became a startup investor for a while. Really got excited about what was happening with AI after the advances that Ilya mentioned. And then we have a a culture of rigor and repeatable innovation,
Unknown: And yet, academia can make very dramatic and significant contributions to AI, just not to the most cutting edge capabilities. The place that academia can contribute to there are so many mysteries about the neural networks that we are trained.
Sam Altman: they have some usefulness, but they're quite primitive relative to the models we'll create. And I think most people would agree if you make a super powerful AGI that has wonderful upsides but existential downsides, We will open source some things. We will, over time, as we understand Safety, to figure out how to align it, had external monitors, red teamers, and scientific community engagement.
Unknown: There is an argument to be made that even when they have fully like, we we have full human level AI, full AGI, people will still have economic activity to do. I don't know whether that's the case. But in either event, and it could be used in powerful ways by bad actors.
Sam Altman: I think In the longer term, I think these systems will do more and more complex buckets of stuff and categories of jobs, some of them will go away. But some others will turn out to like really need humans and human like people really want humans in these roles in ways that are are not very obvious. was when Deep Blue beat Kasparov. On the chess example, people But I do really agree with what Ilya was saying, that no matter what's going to happen, we're going to need some sort of different socioeconomic contract as automation reaches these, like, heretofore unimagined heights. start ups training models, not open source, not the open source community. But if is not really well aligned. That that seems I think the world should treat that not as a, you know, never gonna come sci fi risk, is if we could get a global organization that at the very highest end, at the frontier of compute power and techniques could have a framework to license models, to audit the safety of them, to propose tests that are required to be passed, that would help. do scientific discovery that we currently aren't capable of, new technological progress, climate change is so serious and so hard of a problem. But I think once we have a really powerful superintelligence, There's something that I find personally quite gratifying and wonderful to see about At every stage, we're confronting the risks successfully. It always feels, your expectations go up and we deliver on them. And it feels like this gradual acceleration of technology but in a way that very much is a tool that serves you.
Unknown: And this gap may even be increasing this time. The amount of effort and engineering and research that it takes to produce one such neural net keeps increasing. And so even if there are open source models, they will never be they will be less and less produced by small groups of of dedicated researchers and engineers, and it will only be the providence of the company, the big company.
Sam Altman: The base model is, like, not that easy to use. But the other is to talk to people that are building on top of our at the creativity, AI is gonna impact somehow. And and this is probably the most magical period since the launch of the iPhone, at least for a technological tidal wave to