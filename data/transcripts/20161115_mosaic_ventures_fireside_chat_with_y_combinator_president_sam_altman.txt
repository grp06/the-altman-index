Unknown: you know, went to Stanford, dropped out, did a start up, raised and moved on to running YC which is the sort of preeminent on the West Coast. And as part of that leadership role, is taking the business in a number of new vectors, just relating to seed financing companies but many other interesting things that we'll talk about shortly, and necessary startup areas including energy and biosynthetic life forms and stuff that startups should be doing. So the purpose of this was really in a smaller group, a more intimate group, we're doing a larger session upstairs in the bigger theater with proto entrepreneurs later this afternoon. But for both the planet is currently going through and trying to look at those developments with a bigger picture. part of a sort of whistle stop European tour on this trip and how you see the role of YC not just as an important player in Silicon Valley but over time potentially
Sam Altman: We have been very fortunate to fund many companies from London. It's nice to see some familiar faces in the room. And I expect that that trend will keep going, and that we'll spend more time here. We'll have more companies from London come over and and spend a few months with us.
Unknown: And I suspect it's the widest pipeline or funnel of any investor on the planet? Yeah. founder's perspective, you know, there are lots of choices as to what kind of accelerator they should apply to or how they should kick off things. What's they should choose you over some of the other
Sam Altman: there's the good, which is how will this And we try to be the best at our stage at those. We don't have too much competition on from other accelerators, but we have a lot of competition from later stage investors convincing founders they don't need any accelerator at all. So our pitch is usually not why you should do y c instead of accelerator x, but it's why you should do y c even if you can go off and raise a series a today. a, we try to never harm companies. I think this one we're really good at. We we we try to always do the best in what's in the best interest of the founders. We try to really never hold up anything the founders want. And the way our model works is that when when companies work out, we invest at such an early stage, we make so much money and we do so well that we can afford to write off most of our other investments. So we never fight with founders over trying to get our money back or anything like that. We never stop if founders, if they wanna, you know, sell early. And I think this is actually don't don't fight in the mediocre outcomes. The the the long term brand damage you do and the damage you do to your network, and reputation is just not worth it. So we're really good about not caring about what happens in anything except the exceptionally good scenarios. You know, when we're fortunate enough to get into business with an Airbnb or Stripe or Reddit or Dropbox, of startups in the world. And I think at this point, we're we're well on our way to doing that. If you're a YC company, there are more than a thousand other YC companies that will do anything they can to help you. We really have built a community norm and cultural value of when you're in YC, you will get any help you possibly need from alumni companies, and then when you yourself become an alumni, you have to pay that forward. And look, I think we give pretty good advice. I think we have good events, but the community that we've built has been by far the most powerful thing that we've done. And that is what founders wanna join, and and that is what we I I think that is what explains our success. This is fundamentally a network, and so we have a network effect in our business,
Unknown: And from a sort of industry standpoint, you know, the numbers that often have been sort of put about are that, you know, if you're funding two fifty plus companies a year across two cohorts that perhaps, one in 100 or so will turn out to be one of these winners that
Sam Altman: we end up making
Unknown: the one in 80, say, that's still three companies a year that from inception pretty much you're Yes. You have good ownership in the cap table. I mean, there isn't a venture firm that is as prolific or if any other venture firm that has three new billion dollar outcomes a year, they're typically buying in at later stages and how do you sort of remain on the side of the founder as the company scale up and become more self sufficient in certain respects? We
Sam Altman: And that's how we try to act with our companies. We we never try to control them. We don't take board seats. We don't have any voting rights. We buy common stock, and we don't and as the company gets does better and better, we try to exert even less influence and even less control. You make all your money on the occasional, you know, 10 to a $100,000,000,000 company,
Unknown: does the role that you play
Sam Altman: But there were a lot of other companies we funded in the same, vein. Helion makes, fusion reactors. Rigetti Quantum Computing makes quantum computers, obviously. Ginkgo Bioworks makes, we looked at both of those two things together and thought, you know what? It would be really great for our ecosystem if we could be a friendly late stage investor, and we could support companies no one else will, and we could change the norms for what it means to be a founder friendly late stage investor in the same way we did that ten years ago for early stage investing. Our founders, in general, have not liked their late stage investors, And I think if we can shake up that ecosystem, And we have really been able to do that in the first six months. So it's been a new experience. It's run by a fairly separate team inside of Y Combinator, but I think we'll be able to support a lot of lot of really cool companies.
Unknown: sort of think about before, but how do you deal with the sort of signaling risk and those kinds of issues now that you're potentially an actor in any late stage financing of a sort of YC
Sam Altman: not make money. We would rather not support our companies that, you know, were already doing well than hurt companies that were struggling. And so we spent six months debating what a late stage fund might look like that did not violate the relationship we wanted to have with our founders. And we came up with two rules, both of which hurt our returns a little bit, but preserve the community, and in the long term, we'll, I hope, ensure that we we generate great returns. It's automatic. It doesn't matter how good or bad we think you are, we just do it. So there's no signal to look at. No investor can say, well, YC likes this company or doesn't because we do it every time. And and we just accept investing in the companies that we think are bad as a cost of doing business and maintaining our relationships and community. The second is that we set the threshold where we can make independent decisions above the number where signal still really plays. So we we we looked a lot at where our companies tend to raise money based off of really hard numbers, sort of growth capital, instead of just a pitch. And we found that in those, the signal didn't matter as much because people were really doing something much more mathematical. And so to leave ourselves a buffer, we said that $300,000,000 was the valuation above which we would make decisions to lead or not lead rounds. And at that stage, we're not, I don't think, viewed as a big provider of signal because most investors just don't think they know what we're doing when it comes to growth investing.
Unknown: so as Mosaic, you know, Mike and I, when we pitched our firm, firmly saw ourselves as the folks that would invest after someone had been through YC or being unless we felt that that would, know, you see yourselves as not just disrupting the later stages of the venture
Sam Altman: What we're not as good at and what takes a huge amount of work is where you you choose five to 10 companies and and work incredibly closely with those as a series a board member, and that is critical. If it were not for really good series a board members, I think YC's returns would be far, far lower. So I think we'd be doing our companies a huge disservice and we'd be bad at it to try to be a series a investor. you you know, the the men and women that get involved as truly hands on partners with these companies after YC spend far more time than we do with these companies and provide them just incredible services.
Unknown: If you sort of imagine a world three, five years from now, how many companies could YC be funding? And I'll give you more credit than saying you're spraying and praying because if out of a funnel of
Sam Altman: And then the startup ecosystem worldwide maybe grows at 20 to 30% a year. where we can, you know, in a much lighter touch way, reach 10,000 companies a year, something like that.
Unknown: they benefit from the network in the same degree as all the other participants that absent
Sam Altman: and we certainly haven't invented it yet. I think people think that we do a lot more really advanced planning and we have a lot more answers than maybe even before that, I'll say sort of how we think about new areas. We're not really a trends based investor, but start up to us does not mean a software company. Start up means a company that is designed to grow very quickly. It may fail, but that's at least the goal. and so what we think about is we wanna fund any company that has some plausible shot at being a 10 plus billion dollar company. And that is such a strict rule that we don't allow ourselves any other rules or we'd have nothing to fund. And so we have to be willing to look at companies in any area. And if we're not an expert in that area, but we think it might be super valuable, then either one of the partners has to go become an expert or we have to hire a new partner. not the only model, but it's a model that's worked really well for us. We don't we don't constrain ourselves to the thing that is working today or that worked last year because we don't believe that's necessarily thing that's going to work next year. And we don't let ourselves have the excuse to say, well, we don't know about that, so we're not going to invest. If we think it's important, we figure out how to get reasonably good at it. And through this process, we have decided to to really pay attention to some new areas. Hardware is something that other partners in the firm have done a lot with. Our first choice is always to support something by funding a start up. But if there is technology that we think is really important We have something called YC Research, which is a nonprofit research lab. But AI in particular, is something that I probably, like many people in this room, have been interested in since I was a little kid. be really smart and and maybe be smarter than a human. My adviser was Andrew Ng, who now runs AI at Baidu. And at that time, it was sort of depressing because we all had fervent conviction that AI was gonna be a big deal and nothing was working. four years or three years, it's just been incredibly exciting to watch, Elon Musk and me and the former CTO of Stripe and the former a guy from Google Brain. try to do that in a way where it is not a single for profit company with a single AI that controls the world and hopefully doesn't go off the rails, but a widely distributed AI where each human has an agent that becomes part of them to some degree, and and we sort of try to just distribute this power and make all the humans better. And it's it's super exciting to work on. I think that will certainly be one area where everyone will have a superhuman personal assistant where you can speak to something in things are about about to get pretty crazy. We're going to we are not that far from a world where computers get better than humans at most non creative tasks. And the creative tasks, you know, painting, writing novels, I I think even that will come someday. yeah, I think we saw the first types of doctors, become less good at computers with, AI radiologists. We'll see that, I think, in a lot of other areas. Certainly, self driving cars are now, I think, to a point where it is not a question of if but when they become far better than human drivers. And I think when is probably only a few years away. Know, Foxconn now has robots that are so good that for better or for worse, I think for better, they just eliminated a bunch, a huge number of low skill, menial labor. And so you can see a world where we have basically, effectively infinite resources and wealth. This was actually another, I believe we'll figure this out. I think humans have limitless demand and they will figure out new types of social structure and new ways to get status and fulfillment and happiness and new jobs to do. And I think today, it is So I think this is an important question. I don't pretend to have the answer. We're doing a study, also in YC research, where we're going to try giving about a thousand people a basic income for five years. And we'll say, we're gonna fast forward to this world, let's imagine it, where we don't need everyone to work, and we have enough resources where we can give everyone money, and you can do what you want. And how will people spend their time, and how will they find happiness and fulfillment and social status and everything else that people care about? And I think it's gonna be really different. I think it's important to start studying this now because even if the jobs don't really change for ten or twenty or thirty years, human society does not adapt very quickly. And the sooner we can start seeing what happens and how people adapt, I think the better off we'll be. And we can hopefully learn how to make a future where people are are excited and engaged and happy. So it'll be interesting to see what goes on there. But I think my view of this is, like, let's not be afraid of AI eliminating jobs, because the jobs that it will eliminate first will be the worst jobs. But if it does that, it will do it because it can do it much less expensively than humans, and so the cost of the quality of a great life will come down. And we'll be in a world where we can choose, we'll have to choose, but we can choose to just be much better than we are today about redistributing wealth, positive future. And and the reason that we're spending our time and money on this is that we believe, you know, in the next not too long of a time period, we have the opportunity to push it towards the positive future. And we really wanna try to do that. It it definitely is scary to me to think about the the single AI world. one approach that some people have to AI safety is to say, hey. Multiple AI agents will fight with each other and will, you know, have a lot of conflict, and that's very dangerous. And that the safe approach is to have a single AI that rules the world as a benevolent dictator and stops all other AI projects and, you know, makes makes this utopia for humans. And there is an argument that you can articulate that that is a good path. The thing I have never been able to be comfortable with on that approach is let's say we are successful in creating this single AI that is a billion times smarter than the next most intelligent agent in the universe, the smartest human, But we somehow put a bug in there, or there was something that we didn't understand, and it decides to go the other direction. that is a billion times more intelligent than the next most powerful agent. On also, you know, there will presumably be some group of people in the world that kind of control the AI, I think the the quote is absolute power corrupts absolutely, if they decide something the other seven whatever billion of us don't like, that seems bad. So I'm definitely afraid of a world that has a single concentrated AI. I like better a world with a lot of AIs, and in the same way that there are occasional bad humans, but we as the collective are able to overpower them because we're all of roughly the same skills, I think if we have a lot of AIs and most of them want what we want and want, then then they will be able to stop an occasional bad AI. So I think that is that's why we call open AI, open AI. We want this to be open technology made available to everyone. There's another problem that we're starting to think about now, which is if you have humans and AI and they're separate and, they want the same thing, which is to sort of you have inherent conflict. Whenever you have two groups that want the same thing and only one of them can have it, like being the number one or the dominant species or in control, you you have some amount of conflict. And and so, you know, the world where we have that conflict and either we're trying to enslave AI, AI is trying to enslave us, those both seem bad. So I think, Elon thinks too, some people on the team have different opinions, that some version of Emerge, and this can range from the simplest, you know, chat interface where everyone has, an AI companion that works together with the human, and and the humans do what the humans are good at, AI does what AI is good at, and they kind of become this merged sense of self. Or, you know, Elon's version of this is that we just need full on cybernetics and brain implants. Other people think we should go the other way and upload ourselves into the computer. But whatever it is, some sort of merge, so it's not us versus the AI, but us and the AI is sort of one combined entity, And so for me, there's this question about like, a lot of people talk about the regulation question of a timing question. You know? Well, maybe we should regulate AI, but it's too far away. And I actually agree. It probably is too far away, but about what to do there so that when we get closer to this, whether it takes five, ten, twenty five years, if we can instead extend individual humans and make them better, the humans can still decide collectively Many YC companies are also willing to contribute their data to OpenAI, I guess it's, like, three hundred million seconds per year times two bits per second. It's not do do you guys know the the Paul Erdrich, the book? This analogy this idea that, And and so our our some of our researchers believe that when we when we get the AI algorithms from the book, for building AI, when we discover those, And so I think the the advantage is overstated because I don't think it's going to be as hard as we think it is. I don't think it's gonna require as much data as we think it does. And public in the public want to figure out a plan for how as we get closer and closer, this becomes something kind of And and then from technological safeguards, we've just hired our first two safety researchers, I think a lot of the problem, it comes from investors. I think most investors, although they talk a huge game about being very long term oriented, are simply not at all. They need results to raise their second fund. They you know, the fund's life is maybe only ten years, But I think one of the things that YC has done really well is encourage our founders to take very long term views. We And we're happy to the way that this changes the most is investors deciding that they're willing to sign up for things that are gonna take a long time and and and pushing founders to take a long time. And certainly, you look at our most successful companies, they're on path to take a very long time. And I think I think investors can can push this through. I I didn't plan this, but I'm I'm happy I became an investor at a relatively young age. So I made my first investments when I was twenty four, twenty five, and I realized that, you know, if
Unknown: does that play into the filter that you take as YC in in terms of the three fifty companies that you admit into the program? Or do you skew it more towards folks that have, whether it's AI or other more long term ambitious?
Sam Altman: know, a Tracy of PlanGrid, a Brian of Airbnb, a Patrick of Stripe, the best way to look at that is evidence of doing extraordinary things so far, either in the beginning of that company, if it's already been running, or in those founders' lives before the company relative to whatever kind of luck they were born into or not born into. So, you know, we're as impressed by a founder who is born in rural Pakistan with nothing and makes it to The US to start a company as we are with someone that was born in The US with a little bit more luck and, you know, is able to start through business by the time they're 18. But as much as we can adjusting for circumstances, we look for evidence that founders have done, really extraordinary things. And I think that shows a level of creativity and determination, communication, intelligence, vision, you know. This one is a little bit more difficult to define, but ideas we haven't heard before,
Unknown: can you spend a few minutes talking about both energy and synthetic life? When we attended the demo day
Sam Altman: earlier this year, there was already some companies that were embarking on those areas. I know it's something you've taken a personal question. Yeah. So again, if we can do something as a for profit company, we would rather do that than do it in the in YC Research. And so on the energy side, we have been able to fund the the two areas we've concentrated on generation are solar and nuclear. Solar, those companies are less hard, difficult technology and more new business models. So one company is called Bright that On the nuclear generation side, we have companies like Helion in Seattle working on fusion, and Oclo working on very small, very inexpensive fission reactors in in Mountain View. We also funded some companies on energy storage and energy transmission as well. On synthetic biology, of companies doing work here, and that has been a really amazing field to watch in the same way that AI was sort of quiet for decades and then had amazing breakthroughs in a period of a few years. We've we've seen the same thing in in synthetic bio. In the last few years, you just see this explosion of companies that are now able to create new organisms, like Ginkgo Bioworks, which was one of the first synthetic bio companies that we funded, to editing existing organisms and improving them in different ways. So that, I think, the first thing that we're doing with the basic income study is a pilot. This is a much smaller scale. It'll last close to a year, and it is to test our methods, how we're going to study, how much money to give, how to distribute it, how to track results. And so that is really kind of the design phase of the study. That will be with a 100 people in Oakland, and we'll try different numbers. And our hope But if it goes well, a year from now, we could be ready to start the full scale study. And, you know, the the numbers that most people throw around are something on the order of $18,000 per year. but the plan would be to roll that out, probably still in Oakland, but maybe in two different cities at the same time, What I think would be really cool, and just a cool sort of statement, is if you could do something democratic on the Internet, because the Internet is powerful at this point. The Internet can make consensus decisions. The Internet can force them to some degree. And so to see, you know, the community basically volunteer to be self regulated and then have the Internet as a whole, and I don't I don't propose to know the specifics here. But to get input from people around the world that are part of this shared thing that is now, I think, more powerful than any single nation state, I think that would be a kind of a great moment in the history of technology. a a wide variety of backgrounds. I think you want an organization of any sort, but certainly in one like this where you're putting the place you're putting into place an You know, religion is one way to get it to survive for a long period of time, but a deep seated belief about something that's really important for the future is another. I think to do that, it's very important to have diversity of backgrounds and life experiences on the team, And so you want people that are engineers and philosophers and political thinkers and a lot of other things as well. And you want them to come together and bring all of these different viewpoints about the world and skill sets, but to share this deeply held high conviction belief about this version of the future that's absolutely critical. And if this group doesn't do it, it's not gonna get done right. any individual, even Trump. incredible risks and incredible opportunities. the energy stuff that we talked about earlier. If you could pick one thing to help the poorest half of the world I think cheap, clean, safe energy would be the number one thing. and a lot of other things that you could fix if you could just fix the energy problem. One of the things that I'm always struck by when I read about different problems in the world is how many of them reduce to energy. and and that would be really powerful. I think, you know, some of the crazy stuff happening right now on the Internet can also be addressed with better services, although I don't think that'll be enough. I think we also just need government action and regulation and policy. I think one of the worst things that has happened on the Internet has been the complete disregard for basic human decency that you see. There are things that people are willing to say, you know, from one computer screen to another, but they would never ever say face to face, or most people wouldn't. You know, it seems like we have some maybe, this is pure speculation, maybe in VR, if instead of typing back and forth, we we feel like we're standing in front of another human and we feel like we have the latency is low enough and the fidelity is high enough that it's not this uncanny valley, but it feels like we're standing face to face with another human, maybe we can, like, trick our brains and get that evolutionary pressure to be decent people back. And maybe we'll feel sort of, like, more connected, and we won't say, well, we should blow up that group of people to the same degree. mistake, a big danger zone here where you can get into this mindset and say, Well, I am trying to cure cancer, I don't have to, you know, build a product that works. get really wrong, And I think it is super important to remember that no matter what you're doing, giving themselves an excuse to not have to execute relentlessly. And it's very important not to fall in that trap. Yeah. I have been really interested in how to coordinate groups of people for a long time. But it's sort of an amazing thing that it's possible at all. And as YC gets bigger and bigger, and there's millions of employees at them. And and we want to be able to coordinate that whole group to some degree. Thinking about the technological tools that'll make that possible has been really interesting to us. And And so people choose the communities that they wanna be part of. You see this on Reddit where Reddit is, you know, not only one community, but it's made up of tens of thousands of very the ability for local efforts to have nonlocal effects. You know, if China burns a gigantic amount of coal, it affects the whole world at some point. I think those two things together, if I had to guess, would lead to a weakening of the traditional nation state boundaries and more towards some interconnected world. And I could see an alternate world where it goes hard in the other way. And, you know, to give The US example, you know, right now, we're mostly one country, but we have 50 states. And I could I could see a world where Certainly, work we're doing at YC, I think, will lead us towards more They always fill up last minute the day before, but I try to, like, leave a lot of time open to go work on whatever I think is is sort of the most important and interesting stuff. A lot of that is advising startups. That's probably the biggest single time block, and the second biggest is probably just running YC. So in addition to OpenAI, another group that YC Research is sponsoring is they call themselves HARC, which is, I think, the Human Augmentation Research Center. And open AI is obviously the AI side of the equation. HARC is the IA, intelligence amplification side, where we we just figure out how use software or drugs or whatever to make humans better humans