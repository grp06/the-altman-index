Unknown: And I wanna talk about the medium term because the short term is not as interesting to me. The long term, who knows? But like five, ten years out is what I'm most interested in talking about. And I kinda wanna try to pull out from you your best guess of a bunch of specific things. One of the places I wanted to start was in software. It seems like the most effective use cases so far, which I'm curious if you agree with, but seem to be
Sam Altman: AI workflows that are just way more productive. You'll start to see, like, they'll have these, like, virtual employees. But the thing that I think will be the most impactful on that five to ten year time frame is AI will actually discover new science. And this is a crazy claim to make, but I think it is true. And if it is correct, then The models can now do the kind of reasoning in a particular domain you'd expect a PhD in that field to be able to do. In some sense, we're like, oh, okay. The AIs are like a top competitive programmer in the world now, or AIs can get like a top score on the world's hardest math competitions, or AIs can like, do problems that I'd expect an expert PhD on my PhD in my field to do. happen happen the way you thought it would happen? Like often has happened in the history of open AI, but if a human scientist is three times as productive using o three, new physics and expect that to work. So I think it is currently copilot like. But I've heard like anecdotal reports from biologists where it's like, wow, it really did figure out an idea. Had to develop it a little bit more, but it made like a fundamental leap. Yeah. Will it be easier particle accelerator. Yeah. And say, you'd make the decisions. You look at the data, you tell us like, use AI to do market research
Unknown: But it's actually working. Yeah. So that'll climb the gradient. Yep. What about in the world of, like, physical stuff? Because, like, I get that I mean, it seems to me, you know, very clear that, like, software is just going this direction.
Sam Altman: just do self driving for standard cars way better than any current approach has worked. And that might not be quite what you meant by like No. Is. Humanoid robots. Yeah. But if our AI techniques can like really go drive a car, that's still pretty cool. Yeah. Humanoid robots are the dream, obviously. I really care about that. I think we will get there eventually. It's been like a hard mechanical engineering you can do you can do quite damaging things without physical stuff.
Unknown: if you're thinking about, you know, we're back here in ten years having another conversation and we're like, did AI
Sam Altman: there's a lot that we've gotta figure out. If something goes wrong, I would say, like, somehow it's that we build legitimate superintelligence, something like ChatGPT, and it's gonna be as smart as a PhD student in most areas, and we're gonna deploy it and, you know, But I think we are so deeply hardwired to care about other people, and
Unknown: that is gonna turn out to be pretty deep in biology. And if you know it's a robot, no matter how human like it seems in other ways, you're not gonna care that much. That's that's speculation. So reasoning was like one of the components of intelligence that like sort of got figured out. Is there like another thread going around like a topic of like agency or like some concept of like self directedness?
Sam Altman: Like is that a thing? The ability to work on a goal over a very long time with a lot of complicated steps along the way, I think is maybe what you're going for. Yeah. Same thing. And that is definitely something we're working on. Yeah. What about the future sort of technical path
Unknown: would you say is now inevitable? And what parts would you say you're still not sure which way it'll break? I think we will get to
Sam Altman: Capable of discovering important new ideas, capable of automating huge amounts of work. But then I feel totally confused about what society looks like if that happens. and then I somehow thought society would feel more different if we actually delivered on them than it does so far. But I don't even it's not even obvious that that's a bad thing. Well, one of the more obvious short term impacts will be potentially,
Unknown: or you'd think, would be like employment.
Sam Altman: a lot of jobs will go away. A lot of jobs will just change dramatically. But we have always been really good at figuring out
Unknown: in general so, like, going from a time when, like, everybody was a farmer and, like, nothing that we're currently doing makes any sense to, like, now you have all this stuff. Is it different this time if there's enough resources to go around? Like, at some point, are there enough resources to go around and, like, that's what creates the difference where now people just, like, don't make new jobs and this So Vinod was on the podcast last week. He We're gonna release this one first, so this won't be out by the time that this is said. But his point was that people will just consume a lot more leisure. So he kinda took the view of like, I think this time, like, there's just gonna be an abundance of resources. Everybody's gonna have the stuff that they need. We're gonna be able to build, you know, buildings and people can now just like enjoy their lives. Again, think like the relativistic framing matters here. To
Sam Altman: And
Unknown: Can you talk about like what's the potential complete apparatus or what's the apparatus at least in some period of time? Yeah. I think what what consumers want from us eventually
Sam Altman: is an AI companion, for lack of a better word, that lives in the ether, and that is helping them in all these ways through all these surfaces and all these products, and that gets to know you and your goals and what you wanna accomplish and your information. And sometimes you'll like type in it with chat inside of ChatGPT. Sometimes you'll be using a more like entertainment focused version. Sometimes you'll be using other services that will have like integrated with our platform. Sometimes you'll be using our new device. that will just be helping you get done whatever you wanna get done. Like, sometimes it's pushing stuff to you. Sometimes you're, like, asking questions. Sometimes it's just there, like, observing and getting better for the future. there have basically been two revolutions in computer form factors, interfaces, whatever you wanna call it, that I think it really mattered. Mean, was like stuff a long time ago, but neither you know I or we're paying attention. But in our lifetime, there's been like this kind of a computer, like a keyboard, a mouse, and a monitor, which is pretty awesome and pretty general purpose. And then there's been like touch devices that you carry around. And honestly, those are the big ones. Both of those had the constraints of not having AI. And so there's like things that you had to build or that you could run or not. If you have this incredible new technology, you can maybe get much closer to the kind of computer that exists it that exists in sci fi. That'll be the same intelligence, just in the new form factor which lets you use it differently. Yeah. But the form factor really matters. Because it's with you all the time. That could be one reason it really matters. If if it's like with you all the time and full of sensors and kind of just understands what's happening and, you know, is keep track keeping track of a lot of stuff. And also, if you trust that we're like, with a very small command, you can get something complex to happen and happen correctly, like,
Unknown: you can just imagine very different kinds of devices. What are the other components that you're thinking about right now? Like, so there's, like, you know, there there's obviously the way that, like, chat is getting used by consumers. There's the API that, you know, startups are using all over the place. There's this like device thing. Like, what are the other like big legs of the stool? I think the
Sam Altman: most important one that the world hasn't really thought about yet is what it means for this to be a platform that everything integrates into and that integrates everywhere. So that when you're using other when you're in your car or when you're using some other website or whatever, it's just perfect continuity. I think that will matter a lot. There are new kinds of things to build. Like, there are totally new kinds of ways to think about productivity, new kinds of ways to think about social entertainment,
Unknown: there's all these subcomponents to intelligence and like layers above the stack. You You've even talked about energy. You're obviously super involved in energy. There's a bunch of things in between there, and there's hardware and all this other stuff. Do you feel like it's important either for just OpenAI for the country? How important is this whole stack given all these implications?
Sam Altman: I think that the thing that has most correlated with improvements in quality of life over history is increasing abundance of energy. and, you know, I think it is rational for them to keep trying. Their current AI efforts have not worked as well as they've hoped, and I respect, like, being aggressive and continuing to try new things. And and I and again, given that I think this is, like, rational, I expect that if this one doesn't work out, they'll keep trying new ones after that. I remember once hearing Zuck talk about how, you know, Google in the early days of Facebook, it was rational for them to try social even though it was like clear to people at at Facebook that that was not gonna work, and I feel a little bit similar here. But they started making these like giant offers to, none of our best people have decided to take them up on that. I think that people sort of look at the two paths and say, alright, OpenAI's got a really good shot, a much better shot at actually delivering on superintelligence, and also may eventually be the more valuable company. But I think the strategy of a ton of upfront guaranteed comp, and that being the reason you tell someone to join, like, the degree to which they're focusing on that and not the work and not the mission, and, you know, I hope that we can be the best place in the world to do this kind of research. And it's I think it's incentive aligned with, like, mission first and then economic awards and everything else flowing from that. So I think that's good. There's many things I respect about Meta as a company, but I don't think they're a company that's, like, great at innovation. And I think the special thing about OpenAI is we've managed to build a culture that is good at repeatable innovation. And I think we understand a lot of things that they don't about what it takes to succeed at that. But
Unknown: that copying AI work to date is
Sam Altman: enough versus how much of the innovation is in front? I don't think it's enough. I think that there's a lot of people, and Meta will be a new one, that are saying we're just gonna try to, like, copy OpenAI. We're gonna, like I mean, if you look at how much a lot of these other companies' chat apps look like ChatGPT, even copying, like, the UI mistakes. deeply challenging than
Unknown: people realize once you're in that state. How do you do both? Because like to have like an extremely commercial company and an extremely research oriented company at the same time, there's just like not a lot of examples of it. And I get how you did it before you were really, you know, commercialized, but now you're both and it's still working. We're newer at product. We're newer. Like, I don't
Sam Altman: It's it's amazing amazing what people have done there. But Chatuchi B Tea launched 11/30/2023. that used to work at Meta said to me that like, you know, in the rest of the world, people think of ChatGPT as a Google replacement. like, doom scrolling on the Internet feels like it's making you worse. It may feel good in the moment, but it's making you feel worse. It's making you feel worse, a worse version of themselves. And I think that we're very proud of is when people talk about Chatuchi PT, they're like, actually like myself better. It's like helping me. It's like helping me accomplish my goals. I feel like it's like, this was actually one of the best nicest compliments I ever heard about OpenAI. Just someone said it's the only tech company that has ever not felt somewhat adversarial to me. You know, you have like Google trying to like show me worse and worse search results and show me ads. I love Google. I love all these I don't think this is like totally fair. You have like Meta trying to like hack my brain and get me to keep scrolling.
Unknown: that's kind of a nice thing. Is there a way to do social that has like the interpersonal component and this energy?
Sam Altman: but you could, like, kinda prompt it and say, like, hey, I'm trying to, like, get fit. Mhmm. Can you like show me stuff that is like helpful to that? Or I'm trying to like learn more about current events. Can you like show me stuff from a neutral perspective that is not gonna make me angry, but it's just like actually gonna do it? And that would clearly get less minutes spent than the algorithmic feed that's like outrage baiting. But I think that'd be like a very cool version of an aligned AI helping you with the social experience that that you actually want long term. I don't know. I feel like every morning like I wake up as this like recharged person that knows what I really want in life and that I have like such great intentions and I can like commit to stuff for the day and then like the day comes at me nonstop
Unknown: ten years ago. Yeah. And even then, I would say you were and you were like running YC at the time. And at the time, you were like, I would say very high agency, and you just did what you wanted, and there were no rules. But I think that since then, and especially recently, it's like there's really seems like there's no rules. Like, you know, the Stargate thing. There's bringing Fiji into the company. There's Johnny there's a lot of things, honestly. And I'm curious if there's any mental update or sort of if there's anything that you're able to put your finger on or share that is,
Sam Altman: But I do think there's something freeing about How do you like pick when you've got over choice like that? The degree to which I have no extra bandwidth to do anything else right now is like hard to overstate. So like and also I never wanted to run even one company, like let alone a lot of them. Yeah. I I mean, I thought I was just gonna be an investor. Yeah. Thought you were gonna be an investor too. do you overall really like it? Because it's like more than you bargained for. Mean, I feel very grateful and very like lucky for sure. And I have no doubt that like someday in the future when I'm like retired, I will miss it and like be like, oh man, I'm kinda bored now and that was so cool.
Unknown: Yeah. Aside from the liking it and aside from, you know, the number of hours, do you experience it as like heavy and important or like playful interesting puzzle?
Sam Altman: Very much both of those at the same time. Like, I feel like it is clearly from like a societal impact perspective or at least the potential. It is the most important work, the most impactful work I'll ever touch. I don't know. I don't wanna get like too much like drinking our own Kool Aid, but like, you know, maybe this will be like somewhat historic work. And and I feel that when I have time to like step back and think about it. But in the day to day, it's kind of like,
Unknown: given the current trajectory you think things are on, does it make you change what you think kids should be learning or what you'll teach your own kids? My kid did learn to roll over yesterday. That's pretty good. Yeah. I was very impressed. The head strength. Incredible. Yeah. Top top tier baby. Incredible.
Sam Altman: I don't think so. Like I
Unknown: That's good. Hopefully, that's how it plays. When you go back to YC after this experience,