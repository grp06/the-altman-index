Sam Altman: We said from the very beginning we were gonna go after AGI at a time when in the field you weren't allowed to say that because that just seemed impossibly major technological revolution, you've been able to do more than you could before. And I would expect the companies to be more amazing and impactful and everything else. So yeah, I think it's the best time yet. Big companies have the edge when things are moving slowly and not that dynamic. And then when something like this or mobile or the internet or semiconductor revolution happens or probably like back in the days of the industrial revolution, that was when upstarts had their had their edge.
Unknown: the essay, you actually say a really big thing which is ASI, super intelligence, is actually thousands of days away.
Sam Altman: But that's a very That is really big. I can see a path where the work we are doing just keeps compounding and the rate of progress we've made over the last three years continues for the next three or six or nine or whatever. Nine years would be like three thousand five hundred days or whatever. If we can keep this rate of improvement or even increase it, that system will be quite capable of doing a lot of things. I think already even a system like o one is capable of doing quite a lot of things. From just like a raw cognitive IQ on a closed end, well defined task in a certain area, I'm like, o one is like a very smart
Unknown: establishing a space colony, the discovery of all of physics, near limitless intelligence, and
Sam Altman: abundant energy. I do think all of those things and probably a lot more we can't even imagine are maybe not that far away. And one of and I think it's tremendously exciting that we can talk about this even semi seriously now. And one of the things that I always have loved most about YC is it encourages slightly implausible degrees of techno optimism and just a belief that like, Ah, you can figure this out. And in a world that I think is sort of consistently telling people, This is not going to work, you can't do this thing, you can't do that. I think the early PG spirit of just encouraging founders to think a little bit bigger is like it is a special thing in the world. The abundant energy thing seems like a pretty big deal.
Unknown: There's sort of path A and path B. If we do achieve abundant energy, it seems like this is a real unlock. Almost any work, not just
Sam Altman: I think these are the two the unlock that would happen if we could just get truly abundant intelligence, truly abundant energy, what we'd be able to make happen in the world? Like both come up with better ideas more quickly and then also make them happen in the physical world. To say nothing of it'd be nice to be able to run lots of AI and that takes energy too. I think that would be a huge unlock and the fact that it's I'm not sure whether to be surprised that it's all happening at the same time or if this is just the natural effect of an increasing rate of technological progress. But it's certainly a very exciting time to be alive and a
Unknown: great time to do a startup. Well, we sort of walked through this age of abundance. Maybe robots can actually manufacture, do anything. Almost all physical labor can then result in material progress, not just for the most wealthy but for everyone. You know, what happens if we don't unleash unlimited energy? If, you know, there's some physical law that prevents us from exactly that? Solar
Sam Altman: plus storage is on a good enough trajectory that even if we don't get a big nuclear breakthrough we would be like okay ish. But for sure it seems that driving the cost of energy down, the abundance of it up, has a very direct impact on quality of life. And eventually we'll solve every problem in physics. So we're gonna figure this out. It's just a question of when. And someday we'll be talking not about fusion or whatever but about the Dyson sphere and that'll be awesome too. This is a point in time whatever feels like abundant energy to us will feel like not nearly enough to our great grandchildren and
Unknown: there's a big universe out there with a lot of matter. Yeah. I wanted to switch gears a little bit to sort of earlier you were mentioning Paul Graham who brought us all together, really created Y Combinator. He likes to tell the story of how you got into YC was actually you were a Stanford freshman, and he said, you know what, this is the very first YC batch in 2005. And he said, you know what, you're a freshman and YC will still be here next time, you should just wait. And you said, I'm a sophomore and I'm coming. And you're widely known in our community as one of the most formidable people.
Sam Altman: memory of that is that I needed to reschedule an interview one day or something, a formidable person at all. In fact, I think there's a lot of ways in which I'm really not. I do have a little bit of a just like, the way they are and so I'm just gonna do this thing that from first principles seems like fine. And then I I remember one of the things that I thought was so great about YC and still that I care so much about YC about is it was like a collection of the weird people who are just like, I'm just gonna do my thing. The part of this that does resonate as a like accurate self identity thing is I do think you can just do stuff or try stuff a surprising amount of the time.
Unknown: And I think more of that is a good thing. And then I think one of the things that both of us found at YC was a bunch of people who all believed that you could just do stuff.
Sam Altman: For a long time, when I was trying to figure out what made YC so special, I thought that it was like, okay, you have this very amazing person telling you you can do stuff I believe in you. And as a young founder that felt so special and inspiring. Of course it is. But the thing that I didn't understand until much later was it was the peer group of other people doing that. And one of the biggest pieces of advice I would give to young people now is finding that peer group as early as you can was so important to me. And I didn't realize it was something that mattered. I kind of thought, I'll
Unknown: far greater return by dropping out. But that was a community that purportedly had a lot of these characteristics,
Sam Altman: was I did not feel surrounded by people that made me want to be better and more ambitious and whatever else. And to the degree I did, the thing you were competing with your peers on was who was gonna get the internship at which investment bank? Which I'm embarrassed to say, I fell on that trap. This is like how powerful peer groups are.
Unknown: And you sort of I mean I I remember you coming back to partner rooms and talking about some of the rooms that you were getting to sit in with like the Larry and Sergey's of the world. And that you know AI was some sort of at the tip of everyone's tongue because it felt so close and yet it was that was ten years ago. The thing I always
Sam Altman: thought would be the coolest retirement job was to get to run a research lab. And it was not specific to AI at that time. When we started talking about YC research, not only was it going to, it did end up funding a bunch of different efforts. And I wish I could tell the story of it was obvious that AI was gonna work and be the thing. But we tried a lot of bad things too. Around that time, I read a few books on like the history of And I just thought it would be so cool to do. And it was sort of similar to what YC does in that you're gonna allocate capital to smart people and sometimes it's gonna work and sometimes it's not going to. And I just wanted to try it. AI for sure was having a mini moment. This was like kind of late twenty fourteen, 2015, early twenty sixteen was like the superintelligence discussion, like the book Superintelligence was happening. Bostrom, yep. Yeah. The DeepMind had a few impressive results, but a little bit of a different direction.
Unknown: you know, YC Research and OpenAI?
Sam Altman: I mean, Greg Greg Brockman was early. In retrospect, it feels like this movie montage and there were like all of these, like you know at the beginning of like the Bank Heist movie when you're like driving around to find the people and whatever. he was really smart and then I watched some video of his and he's also he's extremely smart, like true true genuine genius and visionary, but also he has this incredible presence. And so I watched this video of his on YouTube or something. Was like, I gotta meet that guy. And I emailed him and didn't respond, so I just like went to some con conference he was speaking at and we met up. And then after that we started talking a bunch.
Unknown: And then like Greg, I had known a little bit from the early Stripe days. What was that conversation like though? It's like, I really like what your your idea is about AI and I wanna start a lab. Yes. And one of the things that worked really well in retrospect
Sam Altman: was we said from the very beginning we were gonna go after AGI at a time when in the field you weren't allowed to say that. Because that just seemed impossibly crazy and, borderline irresponsible to talk So that got his attention immediately. It got all of the good young people's attention and the derision, whatever that word is, of the mediocre old people. And I felt like somehow that was a really good sign and really powerful. And we were like this ragtag group of people. I mean I was the oldest by a decent amount. I guess I was 30 then. And so you had these people who were like, those are these irresponsible young kids who don't know anything by anything and they're saying these ridiculous things. And the people who that was really appealing to I guess were the same kind of people who would have said, I'm a sophomore and I'm cumming or whatever. They were like, let's just do this thing. Let's take a run at it. And so we kind of went around and met people one by one and then in different configurations of groups, and it kind of came together over the course of And one of my favorite memories of all of OpenAI was Ilya had some reason with Google or something that we couldn't start in We announced in December 2015, but we couldn't start until January 2016. So like January 3, something like that of 2016, very early in the month, people come back from the holidays and we go to Greg's apartment. Maybe there's 10 of us, something like that. And we sit around and it felt like we had done this monumental thing to get it started. But one of the things that I'm really amazingly impressed by, Ilya in particular, but really all of the early people about, is although it took a lot of twists and turns to get here, the big picture of the original ideas was just so incredibly right. And so they were like up on like one of those flip charts or whiteboards, don't remember which, in Greg's apartment. And then we went off and, you know, did some other things that worked or didn't work or whatever. And some of them did and eventually now we have this system. And it feels very crazy and very improbable looking backwards Yeah. Mean more specifically than that, like do a big unsupervised model and then solve RL was on that flip chart. One of the flip charts from a very this is before Greg's apartment, but from a very early off-site. I think this is right. I believe there were three goals for effort at the time. It was like figure out how to do unsupervised learning, solve RL, and never get more than 120 people.
Unknown: So deep learning, then the second big one sounded like scaling. Like the idea that you could scale. That was another heretical idea that people actually found even offensive. I remember a rash of criticism for you guys at that moment. When we started, yeah, the core beliefs were deep learning works and it gets better with scale.
Sam Altman: what took the word that keeps coming to mind is religious level of belief Everybody had some reason of, oh, it's not really learning. It's not really reasoning. It can't really do this. It's like a parlor trick. And these were the eminent leaders of the field. And more than just saying you're wrong, they were like you're wrong and this is a bad thing to believe or a bad thing to say. Was that you're gonna perpetuate an AI winter. You're gonna do this, you're gonna do that. We were just looking at these results and saying they keep getting better. Then we got the scaling results. It just kind of breaks my intuition even now. emergent phenomenon that was really important. And even if we didn't understand all of the details in practice yet, which obviously we didn't and still don't, that there was something really fundamental going on. It was PGism for this as we had discovered a new square in the periodic table. And so we really wanted to push on that. And we were far less resourced than DeepMind and others, and so we said, okay, they're gonna try a lot of things and we've just gotta pick one and really concentrate and that's how we can win here, which is totally the right startup takeaway. And so we said, well, we don't know what we don't know. We do know this one thing works, so we're gonna really concentrate on that. And I think some of the other efforts were trying to outsmart themselves in too many ways, and we just said we'll just the emergent properties of scale for everything, for startups, turns out for deep learning models, for a lot of other things. I think it's a very underappreciated property and thing to go after. I think it's, you know, when in doubt, if you have something that seems like it's getting better with scale, think you should scale it up. I think people want things to be less is more, but actually More is more. More is more. We believed in that. We wanted to push on it. I think one thing that is not maybe that well understood about OpenAI is we had just this even when we were pretty unknown, we had a crazy talented team of researchers.
Unknown: Yeah. And they're motivated. And or you created sort of one of the sole places in the world where they could do that. Like one of the stories I heard is just even getting access to compute resources, even today, is this crazy thing. And embedded in some of the criticism from maybe the elders of the industry at the moment was sort of that. You know, you're gonna waste a lot of resources and somehow that's gonna result in an AI winter. Like people won't give resources anymore. It's funny. People were never sure if we were going to waste resources
Sam Altman: or if we were doing something kind of vaguely immoral by putting in too much resources and you were supposed to spread it across lots of bets rather than conviction on one, most of the world still does not understand the value of a fairly extreme level of conviction on one bet. And so we said, okay, we have this evidence. We believe in this thing. We're gonna, at a time when the normal thing was we're gonna spread against this bet and that bet and that bet You're definite optimist. You're a definite optimist. And I think across many of the successful YC startups,
Unknown: you see a version of that again and again. Yeah. That sounds right. When the world gives you sort of pushback
Sam Altman: getting exposure to from the world of startups is how many times you see that again and again and again. And before, I think before YC I I really had this deep belief that somewhere in the world there were adults in charge, adults in the room, they knew what was going on. And someone had all the answers. If someone was pushing back on you they probably knew what was going on. And the degree to which I now understand that, you know, to pick up the earlier phrase, you can just do stuff. You can just try stuff. No one has all the answers. There are no adults in the room that are gonna magically tell you exactly what to do. And you just kind of have to iterate quickly and find your way. That was a big unlock in life for me to understand. There is a difference between being high conviction just for the sake of it and if you're wrong and you don't adapt and you don't try to be truth seeking, it still is really not that effective. The thing that we tried to do was really just believe whatever the results told us and really kind of try to go do the thing in front of us. And there were a lot of things that we were high conviction and wrong on. But as soon as we realized we were wrong we tried to fully embrace it. Conviction is great until the moment you have data one way or the other. And there are lot of people who hold on it past the moment of data. So it's iterative. It's not just they're wrong and I'm right. You have to go show your work. But there is a long moment where you have to be willing to operate without data.
Unknown: make a choice, and that choice had better you didn't have infinite choices. And so the prioritization itself
Sam Altman: was an exercise that made it much more likely for you to succeed. I wish I could go tell you, oh, we knew exactly what was gonna happen and we had this idea for language models from the beginning and we kind of went right to this. But obviously the story of OpenAI is that we did a lot of things that helped us develop some scientific understanding but were not on the short path. If we knew then what we know now, we could have speedrun this whole thing to like an incredible degree. It doesn't work that way. Like, you don't get to be right at every guess. And so we started off with a lot of assumptions both about the direction of technology but also what kind of company we were going to be and how we were gonna be structured and how AGI was gonna go and all of these things. And we have been like humbled and badly wrong many many many times. is the ability to get punched in the face and get back up and keep going. This happens for scientific bets, for being willing to be wrong about a bunch of other things. We thought about how the world was gonna work and what the sort of shape of the product was going to be. Again, we had no idea or I at least had no idea. Maybe Alec Radford did. I had no idea that language models were gonna be the thing. You know, we started working on robots and agents playing video games and all these other things. Then a few years later GPT three happened.
Unknown: positive or negative sentiment around
Sam Altman: I think the paper was called the unsupervised sentiment neuron. And I think Alec did it alone. By the way, Alec is this unbelievable outlier of a human. And so he did this incredible work which was just looking at he he noticed there was one neuron that was flipping positive or negative sentiment as it was doing these generative Amazon reviews, I think. Other researchers might have hyped it up more or made a bigger deal out of it or whatever, but you know, it was Alex. So it took people a while to, I think, fully internalize what a big deal it was. And he then did GPT one and somebody else scaled it up into GPT two. But it was off of this insight that there was something and at at the time unsupervised learning was just not really working. So he noticed this one really interesting property, which is there was a neuron that was flipping positive or negative with sentiment. And yeah, that led to the GPT series.
Unknown: And he described getting four as sort of the big moment revelation because 3.5 would still do I mean, would hallucinate more than he could use in a legal setting. And then with four, it reached the point where if he chopped the prompts down small enough into workflow, he could get it to do exactly what he wanted. And he built huge test cases around it, and then sold that company for $650,000,000. So I think of him as one of the first to commercialize GPT-four
Sam Altman: When we first started trying to sell GPT three to founders, they would be like, it's cool. It's doing something amazing. It's an incredible demo. But with the possible exception of copywriting, no great businesses were built on GPT three. And then 3.5 came along and people, startups, like YC startups in particular started to do interesting. It no longer felt like we were pushing a boulder uphill. It was like people actually wanted to buy the thing we were selling. Totally. very quickly after giving people access.
Unknown: model dropped itself and you got your hands on it, it was like, well this this is better. We were totally impressed then too. We had all of these tests
Sam Altman: that we did on it that were very looked great and it could just do these things that we were all super impressed by. Also, when we were all just playing around with it and getting samples back, was like, wow, it can do this now. And it can rhyme and it can tell a funny joke, slightly funny joke, and it can do this and that. So it felt really great, but you never really know if you have a hit product on your hands until you put it in customers' hands. Yeah. You're always too impressed with your own work. Yeah. And so we were all excited about it. Were like, oh, this is really quite good. But until the test happens,
Unknown: that moment happens. Yeah. I wanted to switch gears a little bit. So before you created obviously one of the craziest AI labs ever to be created, you started at 19 at YC with a company called Looped, which was basically Find My Friends geolocation probably, what, fifteen years before Apple ended up making it.
Sam Altman: in mobile phones and I wanted to do something that got to use mobile phones. This was when mobile was just starting. It was still three years or two years before the iPhone. But it was clear that carrying around computers still remember the first phone I got that had internet on it. And it was this horrible texting call. And I was hooked right then. I was like, this is not a phone. This is like a computer we can carry and we're stuck with a dial pad for this accident of history but this this is gonna be awesome. And
Unknown: And the idea that you would carry this little black mirror that was what I spent my Friday nights thinking about. And then one of the harder parts of it was we didn't have the App Store, the iPhone didn't exist.
Sam Altman: to go through a platform shift and how messy the beginning is and how much little things you do can shape the direction it all goes. But it was a super valuable experience to get to go through and sort of just see what how it happens and how quickly things change and how you adapt through it. What was that experience like? You ended up selling that company.
Unknown: That was probably the first time you were managing people and doing enterprise sales. All of these things were useful lessons from that first experience. I mean, it obviously was not a successful company.
Sam Altman: and so it a very painful thing to go through, but the rate of experience and education was incredible. Another thing that PG said or quoted somebody else saying but always stuck on me is your twenties are always an apprenticeship Mhmm. But you don't know for what and then you do your real work later. And I did learn quite a lot and I'm very grateful for it. It was like a difficult experience and we never found product market fit really. And we also never really found a way to get to escape velocity, which is just always hard to do. There is nothing that I have ever heard of that has a higher rate of generalized learning than doing a startup. So it was great in that Yeah. When you're 19 and 20,
Unknown: riding the wave of some other platform shift, this shift from you know, dumb cell phones to smartphones and mobile. And you know, here we are many years later and your next act was actually, mean I guess two acts later, literally spawning one of the major platform ships. We all get old. Yeah. a lot of the really great billion dollar company founders, And WhatsApp. So it's interesting. The platform shift is always built by the people who are young with no So there's this other aspect that's interesting in that I think you're you know, you and Elon and Bezos and a bunch of people out there, like they sort of start their journey as founders really whether it's looped or zip two or really in maybe pure software. It's just a different thing that they start, and then later they sort of get to level up. Is there a path that you recommend at this point? If people are thinking, want to work on the craziest hard tech thing first, should they just run towards that to the extent they can? Or is there value in solving the money problem first, being able to invest your own money very deeply into the next thing?
Sam Altman: that I could just write the early checks for OpenAI. And then Elon did it a lot at much higher scale, which I'm very grateful for. And then other people did after that. And there's other things that I've invested in that I'm really happy to have been able to support, and I don't think think it would have been hard to get other people to to do it. So that's great for sure. And I did, like we were talking about earlier, learn these extremely valuable lessons. But I also feel like I kind of like was wasting my time, for lack of a better phrase,
Unknown: Or what would you tell yourself from like now to in a time cap in like time travel capsule that would show up on your desk at Stanford when you were 19?
Sam Altman: help improve other people's lives. I actually think about this a lot. I think about the people that made that computer And I'll know them. Know, many of them probably long retired. But I am so grateful to them. Yeah. And some people worked super hard to make this thing at the limits of technology. And the lives of a lot of other people too.
Unknown: and how do you feel about some of the departures? I mean teams do evolve, but
Sam Altman: like medium sized or even kind of like pretty big sized tech company, Arc, that would normally take like a decade and two years. Like ChatGPT is less than two years old. Yeah. And and there's like a lot of painful stuff that comes with that. And there are, you know, any company as it scales goes through management teams at some rate. And you have to sort of the people who are really good at the zero to one phase are not necessarily people that are good at the one to 10 or the 10 to the 100 phase. We've also kind of like changed what we're gonna be, made plenty of mistakes along the way, done a few things really right, and that comes with a lot of emergent AGI or whatever, however you wanna think about it is like just keep making the best decisions we can at every stage. But it does lead to a lot of change. I hope that we are heading towards a period now of more calm, but I'm sure there will be other periods in the future where things are very dynamic again. So
Unknown: I guess how does OpenAI actually work right now? Mean the quality and the pace that you're pushing right now, think is beyond world class compared to
Sam Altman: a lot of the other really established software players who came before. This is the first time ever where I felt like we actually know what to do. Like I think from here to building an AGI will still take a huge amount of work. There are some known unknowns. But I think we basically know what to go what to go do. And it'll take a while. It'll be hard, but that's tremendously exciting. I also think on the product side there's more to figure out but roughly we know what to shoot at and what we want to optimize for. If you're willing to say we're gonna do these few things, we're gonna try to do them very well, and our research path is fairly clear, our infrastructure path is fairly clear, our product path is getting clearer, you can orient around that super well. We for a long time did not have that. We were a true research lab. And even when you know that, it's hard to act with the conviction on it because there's so many other good things you'd like to do. But the degree to which you can get everybody aligned and pointed at the same thing is a significant determinant in how fast you can move.
Unknown: I mean, sounds like we went from level one to level two very recently and that was really powerful. And then we actually just had our o one hackathon at YC. Yeah, that was so impressive. That was super fun. And then weirdly, one of the people who won, I think they came in third, was Camphor. And so CADCAM startup, know, did YC recently last year or two. And they were able to during the hackathon build something that would iteratively improve an airfoil from something that wouldn't fly to literally something that had Yeah, was awesome. A competitive amount of lift.
Sam Altman: that sort of sounds like level four, which is the innovator stage. It's very funny you say that. I I had been telling people for a while, I thought that the level two to level three jump was gonna happen. But then the level three to level four jump level two to level three was gonna happen quickly. And then the level three to level four jump was somehow gonna be much harder and require some medium sized or larger new ideas. And that demo and a few others have convinced me that you can get a huge amount of innovation just by using these current models in really creative ways. Well yeah, what's
Unknown: interesting is basically Camfur already built the underlying software for CADCAM, and then language is sort of the interface to the large language model, which then can use the software like tool use. And then if you combine that with the idea of code gen, that's kind of a scary crazy idea. Right? Like not only can the large language model code, but it can create tools for itself and then compose those tools similar to
Sam Altman: I wanted to be a physicist. I wasn't smart enough to be a good one. Had to contribute in this other way. But the fact that somebody else I really believe is now gonna go solve all of physics with this stuff, like, I'm so excited to be alive for that. Let's get to level so happy for whoever that person is. Yeah. Yeah. So we realized that AGI had become this badly overloaded word and people meant all kinds of things. And we tried to just say, okay, here's our best guess roughly of the order of things. You have these level one systems which are these chatbots. There'd be level two that would come which would be these reasoners. We think we got there earlier this year with the o one release. Three is agents' ability to go off and do these longer term tasks, know, maybe like multiple interactions with an environment, asking people for help when they need it, working together, all of that. I think we're gonna get there faster than people expect. Four is innovators. That's like a scientist and, you know, that's ability to go explore like a not well understood phenomena over like a long period of time and understand what's just kinda go just figure it out. And then level five, this is the sort of slightly amorphous like, do that but at the scale of a whole company or a whole organization or whatever.
Unknown: And that you have multiple agents that then self correct, that work together. I mean that kind of sounds like an organization to me, just at a very micro level. Do you think that we'll have I mean you famously talked about it, I think Jake talks about it. It's like you will have companies that make billions of dollars per year and have
Sam Altman: You know, it's like one person plus 10,000 GPUs. Pretty
Unknown: powerful. Sam, what advice do you have for people watching who either are about to start or just started their startup?
Sam Altman: Bet on this tech trend. Like bet on this trend. We are not near the saturation point. The models are going get so much better so quickly. What you can do as a startup founder with this versus what you could do without it is so wildly different. And the big companies, even the medium sized companies, even the startups that are a few years old, they're already on quarterly planning cycles. And Google is on a year or decade planning cycle. I don't know how they even do it anymore. But your advantage with speed and focus and conviction and the ability to react to how fast the technology is moving, that is the number one edge of a startup kind of ever but especially right now. So I would definitely like build something with AI and I would definitely like take advantage of the ability to see a new thing and build something that day rather than like put it into a quarterly planning cycle. I guess the other thing I would say is to say, well, because I'm doing some of the AI, the laws of business don't apply to me. I have this magic technology and so I don't have to build a moat or a competitive edge or a better product. It's because I'm doing AI and you're not, so that's all I need. And that's obviously not true. But what you can get are these short term explosions of growth by embracing a new technology more quickly than somebody else